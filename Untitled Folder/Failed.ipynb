{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy-Star Prediction using Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.04240</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18.66280</td>\n",
       "      <td>17.21449</td>\n",
       "      <td>16.67637</td>\n",
       "      <td>16.48922</td>\n",
       "      <td>16.39150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.38298</td>\n",
       "      <td>18.19169</td>\n",
       "      <td>17.47428</td>\n",
       "      <td>17.08732</td>\n",
       "      <td>16.80125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17.76536</td>\n",
       "      <td>16.60272</td>\n",
       "      <td>16.16116</td>\n",
       "      <td>15.98233</td>\n",
       "      <td>15.90438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.55025</td>\n",
       "      <td>16.26342</td>\n",
       "      <td>16.43869</td>\n",
       "      <td>16.55492</td>\n",
       "      <td>16.61326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>19.43133</td>\n",
       "      <td>18.46779</td>\n",
       "      <td>18.16451</td>\n",
       "      <td>18.01475</td>\n",
       "      <td>18.04155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>19.38322</td>\n",
       "      <td>17.88995</td>\n",
       "      <td>17.10537</td>\n",
       "      <td>16.66393</td>\n",
       "      <td>16.36955</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>18.97993</td>\n",
       "      <td>17.84496</td>\n",
       "      <td>17.38022</td>\n",
       "      <td>17.20673</td>\n",
       "      <td>17.07071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>17.90616</td>\n",
       "      <td>16.97172</td>\n",
       "      <td>16.67541</td>\n",
       "      <td>16.53776</td>\n",
       "      <td>16.47596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>18.67249</td>\n",
       "      <td>17.71375</td>\n",
       "      <td>17.49362</td>\n",
       "      <td>17.28284</td>\n",
       "      <td>17.22644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>19.29772</td>\n",
       "      <td>17.80227</td>\n",
       "      <td>17.18266</td>\n",
       "      <td>16.92335</td>\n",
       "      <td>16.79928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>18.83307</td>\n",
       "      <td>17.51785</td>\n",
       "      <td>16.94273</td>\n",
       "      <td>16.71418</td>\n",
       "      <td>16.60521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>19.56250</td>\n",
       "      <td>18.19113</td>\n",
       "      <td>17.65759</td>\n",
       "      <td>17.47573</td>\n",
       "      <td>17.39203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>19.57990</td>\n",
       "      <td>17.72815</td>\n",
       "      <td>16.98740</td>\n",
       "      <td>16.68076</td>\n",
       "      <td>16.50426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>19.25667</td>\n",
       "      <td>17.54869</td>\n",
       "      <td>16.63578</td>\n",
       "      <td>16.14922</td>\n",
       "      <td>15.76639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>19.05958</td>\n",
       "      <td>18.09512</td>\n",
       "      <td>17.92766</td>\n",
       "      <td>17.89270</td>\n",
       "      <td>17.90772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>19.04397</td>\n",
       "      <td>17.51106</td>\n",
       "      <td>16.87335</td>\n",
       "      <td>16.61114</td>\n",
       "      <td>16.48303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17.81661</td>\n",
       "      <td>16.86976</td>\n",
       "      <td>16.53884</td>\n",
       "      <td>16.19576</td>\n",
       "      <td>16.08668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19.39320</td>\n",
       "      <td>18.48274</td>\n",
       "      <td>18.16551</td>\n",
       "      <td>18.05122</td>\n",
       "      <td>18.04328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>17.51339</td>\n",
       "      <td>16.41793</td>\n",
       "      <td>16.06695</td>\n",
       "      <td>15.93751</td>\n",
       "      <td>15.89478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           u         g         r         i         z  class\n",
       "0   19.47406  17.04240  15.94699  15.50342  15.22531      0\n",
       "1   18.66280  17.21449  16.67637  16.48922  16.39150      0\n",
       "2   19.38298  18.19169  17.47428  17.08732  16.80125      1\n",
       "3   17.76536  16.60272  16.16116  15.98233  15.90438      0\n",
       "4   17.55025  16.26342  16.43869  16.55492  16.61326      0\n",
       "5   19.43133  18.46779  18.16451  18.01475  18.04155      0\n",
       "6   19.38322  17.88995  17.10537  16.66393  16.36955      1\n",
       "7   18.97993  17.84496  17.38022  17.20673  17.07071      0\n",
       "8   17.90616  16.97172  16.67541  16.53776  16.47596      0\n",
       "9   18.67249  17.71375  17.49362  17.28284  17.22644      1\n",
       "10  19.29772  17.80227  17.18266  16.92335  16.79928      0\n",
       "11  18.83307  17.51785  16.94273  16.71418  16.60521      0\n",
       "12  19.56250  18.19113  17.65759  17.47573  17.39203      0\n",
       "13  19.57990  17.72815  16.98740  16.68076  16.50426      0\n",
       "14  19.25667  17.54869  16.63578  16.14922  15.76639      1\n",
       "15  19.05958  18.09512  17.92766  17.89270  17.90772      0\n",
       "16  19.04397  17.51106  16.87335  16.61114  16.48303      0\n",
       "17  17.81661  16.86976  16.53884  16.19576  16.08668      1\n",
       "18  19.39320  18.48274  18.16551  18.05122  18.04328      0\n",
       "19  17.51339  16.41793  16.06695  15.93751  15.89478      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\admin\\\\Desktop\\\\Datasets\\\\DATADATADATA.csv\")\n",
    "#Classify Stars-0, Galaxy-1\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97185518, 0.56112195, 0.43198054, 0.25746008, 0.36884444],\n",
       "       [0.790138  , 0.59074937, 0.53554932, 0.34013971, 0.50666166],\n",
       "       [0.95145383, 0.75898645, 0.64884905, 0.39030271, 0.55508482],\n",
       "       ...,\n",
       "       [0.49958673, 0.45475487, 0.448834  , 0.2923536 , 0.4430208 ],\n",
       "       [0.36130194, 0.31795292, 0.33645866, 0.2285826 , 0.35679981],\n",
       "       [0.8873849 , 0.57145858, 0.44132243, 0.26238915, 0.36384554]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "dataset\n",
    "\n",
    "x = dataset[:,0:5]\n",
    "y = dataset[:,5]\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scale = min_max_scaler.fit_transform(x)\n",
    "x_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736, 5) (92, 5) (92, 5) (736,) (92,) (92,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(x_scale, y, test_size=0.2)\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=0.5)\n",
    "\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating A Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(32, activation='relu', input_shape=(5,)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(keras.layers.Dense(1, activation= 'sigmoid'))\n",
    "          \n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 736 samples, validate on 92 samples\n",
      "Epoch 1/1000\n",
      "736/736 [==============================] - 1s 951us/step - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6930 - val_accuracy: 0.4674\n",
      "Epoch 2/1000\n",
      "736/736 [==============================] - 0s 108us/step - loss: 0.6931 - accuracy: 0.5136 - val_loss: 0.6879 - val_accuracy: 0.7500\n",
      "Epoch 3/1000\n",
      "736/736 [==============================] - 0s 123us/step - loss: 0.6920 - accuracy: 0.5082 - val_loss: 0.6828 - val_accuracy: 0.6848\n",
      "Epoch 4/1000\n",
      "736/736 [==============================] - 0s 122us/step - loss: 0.6874 - accuracy: 0.5530 - val_loss: 0.6787 - val_accuracy: 0.6304\n",
      "Epoch 5/1000\n",
      "736/736 [==============================] - 0s 143us/step - loss: 0.6915 - accuracy: 0.5299 - val_loss: 0.6760 - val_accuracy: 0.6196\n",
      "Epoch 6/1000\n",
      "736/736 [==============================] - 0s 136us/step - loss: 0.6858 - accuracy: 0.5679 - val_loss: 0.6725 - val_accuracy: 0.6196\n",
      "Epoch 7/1000\n",
      "736/736 [==============================] - 0s 164us/step - loss: 0.6876 - accuracy: 0.5584 - val_loss: 0.6699 - val_accuracy: 0.6196\n",
      "Epoch 8/1000\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.6855 - accuracy: 0.5516 - val_loss: 0.6678 - val_accuracy: 0.6196\n",
      "Epoch 9/1000\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.6873 - accuracy: 0.5557 - val_loss: 0.6659 - val_accuracy: 0.6196\n",
      "Epoch 10/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.6856 - accuracy: 0.5584 - val_loss: 0.6645 - val_accuracy: 0.6196\n",
      "Epoch 11/1000\n",
      "736/736 [==============================] - 0s 74us/step - loss: 0.6787 - accuracy: 0.5883 - val_loss: 0.6626 - val_accuracy: 0.6196\n",
      "Epoch 12/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.6797 - accuracy: 0.5870 - val_loss: 0.6619 - val_accuracy: 0.6196\n",
      "Epoch 13/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.6804 - accuracy: 0.5910 - val_loss: 0.6614 - val_accuracy: 0.6196\n",
      "Epoch 14/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6782 - accuracy: 0.6087 - val_loss: 0.6614 - val_accuracy: 0.6739\n",
      "Epoch 15/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6767 - accuracy: 0.5802 - val_loss: 0.6610 - val_accuracy: 0.6957\n",
      "Epoch 16/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.6730 - accuracy: 0.6046 - val_loss: 0.6596 - val_accuracy: 0.6848\n",
      "Epoch 17/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.6717 - accuracy: 0.6155 - val_loss: 0.6585 - val_accuracy: 0.6848\n",
      "Epoch 18/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.6741 - accuracy: 0.5870 - val_loss: 0.6577 - val_accuracy: 0.6848\n",
      "Epoch 19/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6787 - accuracy: 0.5720 - val_loss: 0.6576 - val_accuracy: 0.7174\n",
      "Epoch 20/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.6717 - accuracy: 0.6060 - val_loss: 0.6566 - val_accuracy: 0.7065\n",
      "Epoch 21/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.6726 - accuracy: 0.6019 - val_loss: 0.6550 - val_accuracy: 0.6957\n",
      "Epoch 22/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.6701 - accuracy: 0.5910 - val_loss: 0.6545 - val_accuracy: 0.6957\n",
      "Epoch 23/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6734 - accuracy: 0.6168 - val_loss: 0.6535 - val_accuracy: 0.7065\n",
      "Epoch 24/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.6749 - accuracy: 0.5842 - val_loss: 0.6523 - val_accuracy: 0.6957\n",
      "Epoch 25/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.6741 - accuracy: 0.6128 - val_loss: 0.6516 - val_accuracy: 0.7065\n",
      "Epoch 26/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.6713 - accuracy: 0.5992 - val_loss: 0.6514 - val_accuracy: 0.7174\n",
      "Epoch 27/1000\n",
      "736/736 [==============================] - 0s 150us/step - loss: 0.6706 - accuracy: 0.6087 - val_loss: 0.6515 - val_accuracy: 0.7174\n",
      "Epoch 28/1000\n",
      "736/736 [==============================] - 0s 111us/step - loss: 0.6702 - accuracy: 0.6114 - val_loss: 0.6501 - val_accuracy: 0.7174\n",
      "Epoch 29/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.6699 - accuracy: 0.6155 - val_loss: 0.6491 - val_accuracy: 0.7174\n",
      "Epoch 30/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.6657 - accuracy: 0.6236 - val_loss: 0.6478 - val_accuracy: 0.7174\n",
      "Epoch 31/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.6694 - accuracy: 0.5951 - val_loss: 0.6468 - val_accuracy: 0.7174\n",
      "Epoch 32/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.6628 - accuracy: 0.6277 - val_loss: 0.6462 - val_accuracy: 0.7174\n",
      "Epoch 33/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.6638 - accuracy: 0.6209 - val_loss: 0.6447 - val_accuracy: 0.7174\n",
      "Epoch 34/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.6620 - accuracy: 0.6440 - val_loss: 0.6428 - val_accuracy: 0.7174\n",
      "Epoch 35/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.6654 - accuracy: 0.6155 - val_loss: 0.6423 - val_accuracy: 0.7174\n",
      "Epoch 36/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.6695 - accuracy: 0.6033 - val_loss: 0.6417 - val_accuracy: 0.7391\n",
      "Epoch 37/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.6578 - accuracy: 0.6386 - val_loss: 0.6407 - val_accuracy: 0.7391\n",
      "Epoch 38/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6612 - accuracy: 0.6345 - val_loss: 0.6397 - val_accuracy: 0.7391\n",
      "Epoch 39/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.6648 - accuracy: 0.6318 - val_loss: 0.6380 - val_accuracy: 0.7391\n",
      "Epoch 40/1000\n",
      "736/736 [==============================] - 0s 72us/step - loss: 0.6608 - accuracy: 0.6236 - val_loss: 0.6374 - val_accuracy: 0.7500\n",
      "Epoch 41/1000\n",
      "736/736 [==============================] - 0s 74us/step - loss: 0.6533 - accuracy: 0.6413 - val_loss: 0.6362 - val_accuracy: 0.7500\n",
      "Epoch 42/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.6589 - accuracy: 0.6359 - val_loss: 0.6352 - val_accuracy: 0.7500\n",
      "Epoch 43/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.6548 - accuracy: 0.6590 - val_loss: 0.6336 - val_accuracy: 0.7500\n",
      "Epoch 44/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.6586 - accuracy: 0.6549 - val_loss: 0.6325 - val_accuracy: 0.7500\n",
      "Epoch 45/1000\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.6524 - accuracy: 0.6454 - val_loss: 0.6319 - val_accuracy: 0.7500\n",
      "Epoch 46/1000\n",
      "736/736 [==============================] - 0s 132us/step - loss: 0.6461 - accuracy: 0.6413 - val_loss: 0.6312 - val_accuracy: 0.7500\n",
      "Epoch 47/1000\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.6496 - accuracy: 0.6576 - val_loss: 0.6309 - val_accuracy: 0.7826\n",
      "Epoch 48/1000\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.6531 - accuracy: 0.6413 - val_loss: 0.6296 - val_accuracy: 0.7609\n",
      "Epoch 49/1000\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.6539 - accuracy: 0.6535 - val_loss: 0.6284 - val_accuracy: 0.7500\n",
      "Epoch 50/1000\n",
      "736/736 [==============================] - 0s 74us/step - loss: 0.6534 - accuracy: 0.6372 - val_loss: 0.6270 - val_accuracy: 0.7500\n",
      "Epoch 51/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.6472 - accuracy: 0.6726 - val_loss: 0.6256 - val_accuracy: 0.7500\n",
      "Epoch 52/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.6492 - accuracy: 0.6630 - val_loss: 0.6240 - val_accuracy: 0.7500\n",
      "Epoch 53/1000\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.6432 - accuracy: 0.6522 - val_loss: 0.6248 - val_accuracy: 0.7826\n",
      "Epoch 54/1000\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.6447 - accuracy: 0.6671 - val_loss: 0.6227 - val_accuracy: 0.7609\n",
      "Epoch 55/1000\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.6496 - accuracy: 0.6522 - val_loss: 0.6227 - val_accuracy: 0.7826\n",
      "Epoch 56/1000\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.6410 - accuracy: 0.6793 - val_loss: 0.6210 - val_accuracy: 0.7717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.6429 - accuracy: 0.6671 - val_loss: 0.6195 - val_accuracy: 0.7717\n",
      "Epoch 58/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.6399 - accuracy: 0.6454 - val_loss: 0.6186 - val_accuracy: 0.7717\n",
      "Epoch 59/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6415 - accuracy: 0.6726 - val_loss: 0.6167 - val_accuracy: 0.7609\n",
      "Epoch 60/1000\n",
      "736/736 [==============================] - 0s 121us/step - loss: 0.6435 - accuracy: 0.6576 - val_loss: 0.6177 - val_accuracy: 0.8043\n",
      "Epoch 61/1000\n",
      "736/736 [==============================] - 0s 77us/step - loss: 0.6446 - accuracy: 0.6549 - val_loss: 0.6156 - val_accuracy: 0.7826\n",
      "Epoch 62/1000\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.6465 - accuracy: 0.6576 - val_loss: 0.6141 - val_accuracy: 0.7826\n",
      "Epoch 63/1000\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.6432 - accuracy: 0.6467 - val_loss: 0.6126 - val_accuracy: 0.7717\n",
      "Epoch 64/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.6399 - accuracy: 0.6644 - val_loss: 0.6120 - val_accuracy: 0.7826\n",
      "Epoch 65/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.6342 - accuracy: 0.6549 - val_loss: 0.6120 - val_accuracy: 0.8043\n",
      "Epoch 66/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.6328 - accuracy: 0.6739 - val_loss: 0.6096 - val_accuracy: 0.7935\n",
      "Epoch 67/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.6370 - accuracy: 0.6562 - val_loss: 0.6107 - val_accuracy: 0.7826\n",
      "Epoch 68/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6366 - accuracy: 0.6780 - val_loss: 0.6087 - val_accuracy: 0.7935\n",
      "Epoch 69/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.6380 - accuracy: 0.6617 - val_loss: 0.6072 - val_accuracy: 0.8043\n",
      "Epoch 70/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6249 - accuracy: 0.6984 - val_loss: 0.6049 - val_accuracy: 0.8043\n",
      "Epoch 71/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.6265 - accuracy: 0.6889 - val_loss: 0.6034 - val_accuracy: 0.8043\n",
      "Epoch 72/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.6312 - accuracy: 0.6766 - val_loss: 0.6033 - val_accuracy: 0.7935\n",
      "Epoch 73/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.6307 - accuracy: 0.6889 - val_loss: 0.6006 - val_accuracy: 0.8043\n",
      "Epoch 74/1000\n",
      "736/736 [==============================] - 0s 51us/step - loss: 0.6295 - accuracy: 0.6793 - val_loss: 0.6000 - val_accuracy: 0.8043\n",
      "Epoch 75/1000\n",
      "736/736 [==============================] - 0s 57us/step - loss: 0.6222 - accuracy: 0.6848 - val_loss: 0.5975 - val_accuracy: 0.8043\n",
      "Epoch 76/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.6209 - accuracy: 0.6889 - val_loss: 0.5974 - val_accuracy: 0.7935\n",
      "Epoch 77/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.6241 - accuracy: 0.6807 - val_loss: 0.5978 - val_accuracy: 0.8043\n",
      "Epoch 78/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.6244 - accuracy: 0.6875 - val_loss: 0.5957 - val_accuracy: 0.7717\n",
      "Epoch 79/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.6294 - accuracy: 0.6821 - val_loss: 0.5948 - val_accuracy: 0.7935\n",
      "Epoch 80/1000\n",
      "736/736 [==============================] - 0s 48us/step - loss: 0.6216 - accuracy: 0.6875 - val_loss: 0.5963 - val_accuracy: 0.7935\n",
      "Epoch 81/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.6206 - accuracy: 0.7065 - val_loss: 0.5925 - val_accuracy: 0.8043\n",
      "Epoch 82/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.6210 - accuracy: 0.7024 - val_loss: 0.5895 - val_accuracy: 0.7935\n",
      "Epoch 83/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.6245 - accuracy: 0.6766 - val_loss: 0.5901 - val_accuracy: 0.7935\n",
      "Epoch 84/1000\n",
      "736/736 [==============================] - 0s 83us/step - loss: 0.6190 - accuracy: 0.6889 - val_loss: 0.5891 - val_accuracy: 0.8043\n",
      "Epoch 85/1000\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.6114 - accuracy: 0.7024 - val_loss: 0.5849 - val_accuracy: 0.7935\n",
      "Epoch 86/1000\n",
      "736/736 [==============================] - 0s 56us/step - loss: 0.6196 - accuracy: 0.6821 - val_loss: 0.5859 - val_accuracy: 0.8043\n",
      "Epoch 87/1000\n",
      "736/736 [==============================] - 0s 53us/step - loss: 0.6145 - accuracy: 0.7052 - val_loss: 0.5827 - val_accuracy: 0.7717\n",
      "Epoch 88/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.6123 - accuracy: 0.7024 - val_loss: 0.5829 - val_accuracy: 0.8043\n",
      "Epoch 89/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.6121 - accuracy: 0.6943 - val_loss: 0.5800 - val_accuracy: 0.7717\n",
      "Epoch 90/1000\n",
      "736/736 [==============================] - 0s 58us/step - loss: 0.6147 - accuracy: 0.6957 - val_loss: 0.5801 - val_accuracy: 0.8043\n",
      "Epoch 91/1000\n",
      "736/736 [==============================] - 0s 57us/step - loss: 0.6136 - accuracy: 0.6970 - val_loss: 0.5793 - val_accuracy: 0.8043\n",
      "Epoch 92/1000\n",
      "736/736 [==============================] - 0s 49us/step - loss: 0.6149 - accuracy: 0.6848 - val_loss: 0.5770 - val_accuracy: 0.8043\n",
      "Epoch 93/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.6076 - accuracy: 0.7024 - val_loss: 0.5750 - val_accuracy: 0.7935\n",
      "Epoch 94/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.6143 - accuracy: 0.6916 - val_loss: 0.5743 - val_accuracy: 0.8043\n",
      "Epoch 95/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.6105 - accuracy: 0.6970 - val_loss: 0.5727 - val_accuracy: 0.8043\n",
      "Epoch 96/1000\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.6125 - accuracy: 0.6957 - val_loss: 0.5709 - val_accuracy: 0.7935\n",
      "Epoch 97/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.6136 - accuracy: 0.6916 - val_loss: 0.5697 - val_accuracy: 0.7935\n",
      "Epoch 98/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.5974 - accuracy: 0.7147 - val_loss: 0.5672 - val_accuracy: 0.7717\n",
      "Epoch 99/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.6105 - accuracy: 0.6970 - val_loss: 0.5668 - val_accuracy: 0.7935\n",
      "Epoch 100/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5969 - accuracy: 0.7283 - val_loss: 0.5680 - val_accuracy: 0.7935\n",
      "Epoch 101/1000\n",
      "736/736 [==============================] - 0s 48us/step - loss: 0.5994 - accuracy: 0.7147 - val_loss: 0.5637 - val_accuracy: 0.7935\n",
      "Epoch 102/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.6029 - accuracy: 0.6834 - val_loss: 0.5640 - val_accuracy: 0.8043\n",
      "Epoch 103/1000\n",
      "736/736 [==============================] - 0s 52us/step - loss: 0.5955 - accuracy: 0.7188 - val_loss: 0.5631 - val_accuracy: 0.8043\n",
      "Epoch 104/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5941 - accuracy: 0.7052 - val_loss: 0.5614 - val_accuracy: 0.8043\n",
      "Epoch 105/1000\n",
      "736/736 [==============================] - 0s 56us/step - loss: 0.6001 - accuracy: 0.6929 - val_loss: 0.5595 - val_accuracy: 0.8043\n",
      "Epoch 106/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.5940 - accuracy: 0.7269 - val_loss: 0.5560 - val_accuracy: 0.7826\n",
      "Epoch 107/1000\n",
      "736/736 [==============================] - 0s 102us/step - loss: 0.5984 - accuracy: 0.6943 - val_loss: 0.5580 - val_accuracy: 0.8043\n",
      "Epoch 108/1000\n",
      "736/736 [==============================] - 0s 130us/step - loss: 0.5908 - accuracy: 0.7310 - val_loss: 0.5553 - val_accuracy: 0.8043\n",
      "Epoch 109/1000\n",
      "736/736 [==============================] - 0s 84us/step - loss: 0.5917 - accuracy: 0.7269 - val_loss: 0.5524 - val_accuracy: 0.8043\n",
      "Epoch 110/1000\n",
      "736/736 [==============================] - 0s 73us/step - loss: 0.5893 - accuracy: 0.7106 - val_loss: 0.5533 - val_accuracy: 0.8043\n",
      "Epoch 111/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.5931 - accuracy: 0.7242 - val_loss: 0.5498 - val_accuracy: 0.8043\n",
      "Epoch 112/1000\n",
      "736/736 [==============================] - 0s 73us/step - loss: 0.6006 - accuracy: 0.7188 - val_loss: 0.5531 - val_accuracy: 0.8043\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 61us/step - loss: 0.5953 - accuracy: 0.7065 - val_loss: 0.5508 - val_accuracy: 0.8043\n",
      "Epoch 114/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.5859 - accuracy: 0.7418 - val_loss: 0.5518 - val_accuracy: 0.7826\n",
      "Epoch 115/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5892 - accuracy: 0.7120 - val_loss: 0.5476 - val_accuracy: 0.8043\n",
      "Epoch 116/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5879 - accuracy: 0.7364 - val_loss: 0.5429 - val_accuracy: 0.8043\n",
      "Epoch 117/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5876 - accuracy: 0.7160 - val_loss: 0.5444 - val_accuracy: 0.7935\n",
      "Epoch 118/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5842 - accuracy: 0.7228 - val_loss: 0.5413 - val_accuracy: 0.8043\n",
      "Epoch 119/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5919 - accuracy: 0.7092 - val_loss: 0.5406 - val_accuracy: 0.8043\n",
      "Epoch 120/1000\n",
      "736/736 [==============================] - 0s 41us/step - loss: 0.5766 - accuracy: 0.7310 - val_loss: 0.5382 - val_accuracy: 0.8043\n",
      "Epoch 121/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.5871 - accuracy: 0.7133 - val_loss: 0.5362 - val_accuracy: 0.7935\n",
      "Epoch 122/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.5778 - accuracy: 0.7310 - val_loss: 0.5381 - val_accuracy: 0.8043\n",
      "Epoch 123/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5763 - accuracy: 0.7473 - val_loss: 0.5377 - val_accuracy: 0.8043\n",
      "Epoch 124/1000\n",
      "736/736 [==============================] - 0s 52us/step - loss: 0.5743 - accuracy: 0.7283 - val_loss: 0.5324 - val_accuracy: 0.8043\n",
      "Epoch 125/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5757 - accuracy: 0.6997 - val_loss: 0.5353 - val_accuracy: 0.8043\n",
      "Epoch 126/1000\n",
      "736/736 [==============================] - 0s 58us/step - loss: 0.5791 - accuracy: 0.7337 - val_loss: 0.5359 - val_accuracy: 0.7826\n",
      "Epoch 127/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5731 - accuracy: 0.7188 - val_loss: 0.5327 - val_accuracy: 0.8043\n",
      "Epoch 128/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5772 - accuracy: 0.7310 - val_loss: 0.5315 - val_accuracy: 0.7935\n",
      "Epoch 129/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.5752 - accuracy: 0.7201 - val_loss: 0.5297 - val_accuracy: 0.8043\n",
      "Epoch 130/1000\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.5712 - accuracy: 0.7255 - val_loss: 0.5284 - val_accuracy: 0.8043\n",
      "Epoch 131/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5767 - accuracy: 0.7323 - val_loss: 0.5254 - val_accuracy: 0.8043\n",
      "Epoch 132/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.5736 - accuracy: 0.7296 - val_loss: 0.5288 - val_accuracy: 0.7826\n",
      "Epoch 133/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5717 - accuracy: 0.7391 - val_loss: 0.5243 - val_accuracy: 0.8043\n",
      "Epoch 134/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5772 - accuracy: 0.7378 - val_loss: 0.5223 - val_accuracy: 0.8043\n",
      "Epoch 135/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.5667 - accuracy: 0.7391 - val_loss: 0.5201 - val_accuracy: 0.8043\n",
      "Epoch 136/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5604 - accuracy: 0.7418 - val_loss: 0.5181 - val_accuracy: 0.8043\n",
      "Epoch 137/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5734 - accuracy: 0.7283 - val_loss: 0.5176 - val_accuracy: 0.8043\n",
      "Epoch 138/1000\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.78 - 0s 68us/step - loss: 0.5635 - accuracy: 0.7201 - val_loss: 0.5229 - val_accuracy: 0.7935\n",
      "Epoch 139/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.5663 - accuracy: 0.7242 - val_loss: 0.5150 - val_accuracy: 0.8043\n",
      "Epoch 140/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.5726 - accuracy: 0.7174 - val_loss: 0.5165 - val_accuracy: 0.8043\n",
      "Epoch 141/1000\n",
      "736/736 [==============================] - 0s 73us/step - loss: 0.5554 - accuracy: 0.7432 - val_loss: 0.5176 - val_accuracy: 0.7826\n",
      "Epoch 142/1000\n",
      "736/736 [==============================] - 0s 73us/step - loss: 0.5550 - accuracy: 0.7364 - val_loss: 0.5125 - val_accuracy: 0.8043\n",
      "Epoch 143/1000\n",
      "736/736 [==============================] - 0s 74us/step - loss: 0.5705 - accuracy: 0.7337 - val_loss: 0.5142 - val_accuracy: 0.8043\n",
      "Epoch 144/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5610 - accuracy: 0.7418 - val_loss: 0.5121 - val_accuracy: 0.8043\n",
      "Epoch 145/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5650 - accuracy: 0.7255 - val_loss: 0.5102 - val_accuracy: 0.8043\n",
      "Epoch 146/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.5670 - accuracy: 0.7310 - val_loss: 0.5149 - val_accuracy: 0.7935\n",
      "Epoch 147/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5741 - accuracy: 0.7255 - val_loss: 0.5083 - val_accuracy: 0.8043\n",
      "Epoch 148/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5664 - accuracy: 0.7323 - val_loss: 0.5126 - val_accuracy: 0.7935\n",
      "Epoch 149/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5664 - accuracy: 0.7038 - val_loss: 0.5092 - val_accuracy: 0.8043\n",
      "Epoch 150/1000\n",
      "736/736 [==============================] - 0s 104us/step - loss: 0.5606 - accuracy: 0.7269 - val_loss: 0.5065 - val_accuracy: 0.8043\n",
      "Epoch 151/1000\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.5451 - accuracy: 0.7500 - val_loss: 0.5047 - val_accuracy: 0.8043\n",
      "Epoch 152/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5390 - accuracy: 0.7527 - val_loss: 0.5069 - val_accuracy: 0.7935\n",
      "Epoch 153/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.5635 - accuracy: 0.7174 - val_loss: 0.5057 - val_accuracy: 0.7935\n",
      "Epoch 154/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.5459 - accuracy: 0.7391 - val_loss: 0.5066 - val_accuracy: 0.7935\n",
      "Epoch 155/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5558 - accuracy: 0.7242 - val_loss: 0.5026 - val_accuracy: 0.7935\n",
      "Epoch 156/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5526 - accuracy: 0.7337 - val_loss: 0.5002 - val_accuracy: 0.8043\n",
      "Epoch 157/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5597 - accuracy: 0.7269 - val_loss: 0.5037 - val_accuracy: 0.7935\n",
      "Epoch 158/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5554 - accuracy: 0.7378 - val_loss: 0.4963 - val_accuracy: 0.8043\n",
      "Epoch 159/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5481 - accuracy: 0.7432 - val_loss: 0.5003 - val_accuracy: 0.7826\n",
      "Epoch 160/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5560 - accuracy: 0.7364 - val_loss: 0.4993 - val_accuracy: 0.7935\n",
      "Epoch 161/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5561 - accuracy: 0.7337 - val_loss: 0.5020 - val_accuracy: 0.7935\n",
      "Epoch 162/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5494 - accuracy: 0.7446 - val_loss: 0.4967 - val_accuracy: 0.7935\n",
      "Epoch 163/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.5472 - accuracy: 0.7541 - val_loss: 0.4958 - val_accuracy: 0.8043\n",
      "Epoch 164/1000\n",
      "736/736 [==============================] - 0s 57us/step - loss: 0.5306 - accuracy: 0.7500 - val_loss: 0.4913 - val_accuracy: 0.8152\n",
      "Epoch 165/1000\n",
      "736/736 [==============================] - 0s 44us/step - loss: 0.5460 - accuracy: 0.7283 - val_loss: 0.4923 - val_accuracy: 0.8043\n",
      "Epoch 166/1000\n",
      "736/736 [==============================] - 0s 40us/step - loss: 0.5512 - accuracy: 0.7147 - val_loss: 0.4920 - val_accuracy: 0.8152\n",
      "Epoch 167/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5436 - accuracy: 0.7609 - val_loss: 0.4962 - val_accuracy: 0.7935\n",
      "Epoch 168/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5266 - accuracy: 0.7690 - val_loss: 0.4895 - val_accuracy: 0.8043\n",
      "Epoch 169/1000\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.78 - 0s 54us/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.4882 - val_accuracy: 0.8043\n",
      "Epoch 170/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5488 - accuracy: 0.7554 - val_loss: 0.4863 - val_accuracy: 0.8043\n",
      "Epoch 171/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5354 - accuracy: 0.7595 - val_loss: 0.4909 - val_accuracy: 0.7935\n",
      "Epoch 172/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.5361 - accuracy: 0.7378 - val_loss: 0.4903 - val_accuracy: 0.7935\n",
      "Epoch 173/1000\n",
      "736/736 [==============================] - 0s 100us/step - loss: 0.5424 - accuracy: 0.7215 - val_loss: 0.4852 - val_accuracy: 0.8152\n",
      "Epoch 174/1000\n",
      "736/736 [==============================] - 0s 49us/step - loss: 0.5492 - accuracy: 0.7364 - val_loss: 0.4869 - val_accuracy: 0.8043\n",
      "Epoch 175/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.5370 - accuracy: 0.7554 - val_loss: 0.4854 - val_accuracy: 0.8043\n",
      "Epoch 176/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5412 - accuracy: 0.7473 - val_loss: 0.4912 - val_accuracy: 0.7826\n",
      "Epoch 177/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5344 - accuracy: 0.7364 - val_loss: 0.4847 - val_accuracy: 0.7935\n",
      "Epoch 178/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5315 - accuracy: 0.7446 - val_loss: 0.4816 - val_accuracy: 0.8043\n",
      "Epoch 179/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.5263 - accuracy: 0.7609 - val_loss: 0.4800 - val_accuracy: 0.8043\n",
      "Epoch 180/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5399 - accuracy: 0.7500 - val_loss: 0.4796 - val_accuracy: 0.8043\n",
      "Epoch 181/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5337 - accuracy: 0.7296 - val_loss: 0.4799 - val_accuracy: 0.7935\n",
      "Epoch 182/1000\n",
      "736/736 [==============================] - 0s 57us/step - loss: 0.5497 - accuracy: 0.7201 - val_loss: 0.4782 - val_accuracy: 0.8152\n",
      "Epoch 183/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.5428 - accuracy: 0.7527 - val_loss: 0.4845 - val_accuracy: 0.7935\n",
      "Epoch 184/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.5424 - accuracy: 0.7486 - val_loss: 0.4797 - val_accuracy: 0.8043\n",
      "Epoch 185/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5403 - accuracy: 0.7459 - val_loss: 0.4797 - val_accuracy: 0.8043\n",
      "Epoch 186/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.5320 - accuracy: 0.7595 - val_loss: 0.4812 - val_accuracy: 0.7935\n",
      "Epoch 187/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5283 - accuracy: 0.7677 - val_loss: 0.4786 - val_accuracy: 0.7935\n",
      "Epoch 188/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5351 - accuracy: 0.7649 - val_loss: 0.4771 - val_accuracy: 0.7935\n",
      "Epoch 189/1000\n",
      "736/736 [==============================] - 0s 47us/step - loss: 0.5374 - accuracy: 0.7473 - val_loss: 0.4762 - val_accuracy: 0.8043\n",
      "Epoch 190/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5378 - accuracy: 0.7514 - val_loss: 0.4761 - val_accuracy: 0.8043\n",
      "Epoch 191/1000\n",
      "736/736 [==============================] - 0s 57us/step - loss: 0.5307 - accuracy: 0.7649 - val_loss: 0.4742 - val_accuracy: 0.8152\n",
      "Epoch 192/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5355 - accuracy: 0.7432 - val_loss: 0.4762 - val_accuracy: 0.8043\n",
      "Epoch 193/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5361 - accuracy: 0.7527 - val_loss: 0.4764 - val_accuracy: 0.8043\n",
      "Epoch 194/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5338 - accuracy: 0.7364 - val_loss: 0.4730 - val_accuracy: 0.8152\n",
      "Epoch 195/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.5194 - accuracy: 0.7649 - val_loss: 0.4750 - val_accuracy: 0.7935\n",
      "Epoch 196/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.5250 - accuracy: 0.7582 - val_loss: 0.4745 - val_accuracy: 0.7935\n",
      "Epoch 197/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.5413 - accuracy: 0.7351 - val_loss: 0.4764 - val_accuracy: 0.8043\n",
      "Epoch 198/1000\n",
      "736/736 [==============================] - 0s 58us/step - loss: 0.5337 - accuracy: 0.7541 - val_loss: 0.4747 - val_accuracy: 0.7935\n",
      "Epoch 199/1000\n",
      "736/736 [==============================] - 0s 80us/step - loss: 0.5301 - accuracy: 0.7582 - val_loss: 0.4708 - val_accuracy: 0.8152\n",
      "Epoch 200/1000\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.5296 - accuracy: 0.7473 - val_loss: 0.4720 - val_accuracy: 0.7935\n",
      "Epoch 201/1000\n",
      "736/736 [==============================] - 0s 73us/step - loss: 0.5332 - accuracy: 0.7582 - val_loss: 0.4718 - val_accuracy: 0.7935\n",
      "Epoch 202/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5332 - accuracy: 0.7446 - val_loss: 0.4703 - val_accuracy: 0.8043\n",
      "Epoch 203/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5087 - accuracy: 0.7690 - val_loss: 0.4706 - val_accuracy: 0.7935\n",
      "Epoch 204/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.5349 - accuracy: 0.7568 - val_loss: 0.4670 - val_accuracy: 0.8043\n",
      "Epoch 205/1000\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.5314 - accuracy: 0.7595 - val_loss: 0.4677 - val_accuracy: 0.8152\n",
      "Epoch 206/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.5338 - accuracy: 0.7500 - val_loss: 0.4678 - val_accuracy: 0.8043\n",
      "Epoch 207/1000\n",
      "736/736 [==============================] - 0s 56us/step - loss: 0.5252 - accuracy: 0.7609 - val_loss: 0.4685 - val_accuracy: 0.8043\n",
      "Epoch 208/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5228 - accuracy: 0.7446 - val_loss: 0.4668 - val_accuracy: 0.8043\n",
      "Epoch 209/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5211 - accuracy: 0.7595 - val_loss: 0.4655 - val_accuracy: 0.8043\n",
      "Epoch 210/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5179 - accuracy: 0.7554 - val_loss: 0.4685 - val_accuracy: 0.7935\n",
      "Epoch 211/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5098 - accuracy: 0.7473 - val_loss: 0.4663 - val_accuracy: 0.8043\n",
      "Epoch 212/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5179 - accuracy: 0.7799 - val_loss: 0.4660 - val_accuracy: 0.7935\n",
      "Epoch 213/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.5199 - accuracy: 0.7595 - val_loss: 0.4655 - val_accuracy: 0.8043\n",
      "Epoch 214/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5141 - accuracy: 0.7636 - val_loss: 0.4639 - val_accuracy: 0.8043\n",
      "Epoch 215/1000\n",
      "736/736 [==============================] - 0s 58us/step - loss: 0.5287 - accuracy: 0.7568 - val_loss: 0.4638 - val_accuracy: 0.8152\n",
      "Epoch 216/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.5181 - accuracy: 0.7568 - val_loss: 0.4619 - val_accuracy: 0.8152\n",
      "Epoch 217/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.5329 - accuracy: 0.7622 - val_loss: 0.4627 - val_accuracy: 0.8043\n",
      "Epoch 218/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5201 - accuracy: 0.7514 - val_loss: 0.4626 - val_accuracy: 0.8043\n",
      "Epoch 219/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.5187 - accuracy: 0.7568 - val_loss: 0.4665 - val_accuracy: 0.7826\n",
      "Epoch 220/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5269 - accuracy: 0.7663 - val_loss: 0.4621 - val_accuracy: 0.8043\n",
      "Epoch 221/1000\n",
      "736/736 [==============================] - 0s 52us/step - loss: 0.5257 - accuracy: 0.7649 - val_loss: 0.4643 - val_accuracy: 0.8043\n",
      "Epoch 222/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5324 - accuracy: 0.7500 - val_loss: 0.4643 - val_accuracy: 0.7935\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 55us/step - loss: 0.5163 - accuracy: 0.7554 - val_loss: 0.4609 - val_accuracy: 0.8152\n",
      "Epoch 224/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.5124 - accuracy: 0.7758 - val_loss: 0.4590 - val_accuracy: 0.8152\n",
      "Epoch 225/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.5294 - accuracy: 0.7636 - val_loss: 0.4611 - val_accuracy: 0.8043\n",
      "Epoch 226/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5179 - accuracy: 0.7622 - val_loss: 0.4610 - val_accuracy: 0.8043\n",
      "Epoch 227/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.5201 - accuracy: 0.7527 - val_loss: 0.4590 - val_accuracy: 0.8043\n",
      "Epoch 228/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5210 - accuracy: 0.7473 - val_loss: 0.4603 - val_accuracy: 0.8043\n",
      "Epoch 229/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.5096 - accuracy: 0.7636 - val_loss: 0.4587 - val_accuracy: 0.8043\n",
      "Epoch 230/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5159 - accuracy: 0.7527 - val_loss: 0.4641 - val_accuracy: 0.7826\n",
      "Epoch 231/1000\n",
      "736/736 [==============================] - 0s 80us/step - loss: 0.5251 - accuracy: 0.7541 - val_loss: 0.4579 - val_accuracy: 0.8043\n",
      "Epoch 232/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.5179 - accuracy: 0.7649 - val_loss: 0.4590 - val_accuracy: 0.8043\n",
      "Epoch 233/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.5142 - accuracy: 0.7541 - val_loss: 0.4577 - val_accuracy: 0.8043\n",
      "Epoch 234/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5418 - accuracy: 0.7486 - val_loss: 0.4593 - val_accuracy: 0.8152\n",
      "Epoch 235/1000\n",
      "736/736 [==============================] - 0s 125us/step - loss: 0.5299 - accuracy: 0.7595 - val_loss: 0.4589 - val_accuracy: 0.8043\n",
      "Epoch 236/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.5270 - accuracy: 0.7636 - val_loss: 0.4584 - val_accuracy: 0.8152\n",
      "Epoch 237/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5091 - accuracy: 0.7704 - val_loss: 0.4555 - val_accuracy: 0.8152\n",
      "Epoch 238/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.5176 - accuracy: 0.7541 - val_loss: 0.4554 - val_accuracy: 0.8043\n",
      "Epoch 239/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5090 - accuracy: 0.7677 - val_loss: 0.4538 - val_accuracy: 0.8043\n",
      "Epoch 240/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.5194 - accuracy: 0.7826 - val_loss: 0.4546 - val_accuracy: 0.8152\n",
      "Epoch 241/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.5127 - accuracy: 0.7704 - val_loss: 0.4565 - val_accuracy: 0.7935\n",
      "Epoch 242/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5048 - accuracy: 0.7704 - val_loss: 0.4555 - val_accuracy: 0.7935\n",
      "Epoch 243/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.5097 - accuracy: 0.7622 - val_loss: 0.4537 - val_accuracy: 0.8152\n",
      "Epoch 244/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5227 - accuracy: 0.7649 - val_loss: 0.4549 - val_accuracy: 0.8043\n",
      "Epoch 245/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5087 - accuracy: 0.7663 - val_loss: 0.4548 - val_accuracy: 0.8152\n",
      "Epoch 246/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.5196 - accuracy: 0.7663 - val_loss: 0.4532 - val_accuracy: 0.8043\n",
      "Epoch 247/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5155 - accuracy: 0.7568 - val_loss: 0.4532 - val_accuracy: 0.8043\n",
      "Epoch 248/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5043 - accuracy: 0.7853 - val_loss: 0.4538 - val_accuracy: 0.8043\n",
      "Epoch 249/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5141 - accuracy: 0.7554 - val_loss: 0.4537 - val_accuracy: 0.8152\n",
      "Epoch 250/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5106 - accuracy: 0.7609 - val_loss: 0.4581 - val_accuracy: 0.7826\n",
      "Epoch 251/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5295 - accuracy: 0.7541 - val_loss: 0.4526 - val_accuracy: 0.8152\n",
      "Epoch 252/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.5126 - accuracy: 0.7582 - val_loss: 0.4523 - val_accuracy: 0.8152\n",
      "Epoch 253/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.5089 - accuracy: 0.7799 - val_loss: 0.4505 - val_accuracy: 0.8152\n",
      "Epoch 254/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5110 - accuracy: 0.7568 - val_loss: 0.4519 - val_accuracy: 0.8152\n",
      "Epoch 255/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5199 - accuracy: 0.7785 - val_loss: 0.4529 - val_accuracy: 0.8152\n",
      "Epoch 256/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5265 - accuracy: 0.7473 - val_loss: 0.4531 - val_accuracy: 0.8152\n",
      "Epoch 257/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5058 - accuracy: 0.7731 - val_loss: 0.4520 - val_accuracy: 0.8043\n",
      "Epoch 258/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5054 - accuracy: 0.7609 - val_loss: 0.4521 - val_accuracy: 0.8043\n",
      "Epoch 259/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5041 - accuracy: 0.7785 - val_loss: 0.4527 - val_accuracy: 0.8043\n",
      "Epoch 260/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5016 - accuracy: 0.7731 - val_loss: 0.4502 - val_accuracy: 0.8043\n",
      "Epoch 261/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.5128 - accuracy: 0.7609 - val_loss: 0.4554 - val_accuracy: 0.7826\n",
      "Epoch 262/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5020 - accuracy: 0.7785 - val_loss: 0.4500 - val_accuracy: 0.8043\n",
      "Epoch 263/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5120 - accuracy: 0.7677 - val_loss: 0.4527 - val_accuracy: 0.7826\n",
      "Epoch 264/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.5105 - accuracy: 0.7677 - val_loss: 0.4496 - val_accuracy: 0.8043\n",
      "Epoch 265/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.5126 - accuracy: 0.7704 - val_loss: 0.4505 - val_accuracy: 0.8152\n",
      "Epoch 266/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4993 - accuracy: 0.7704 - val_loss: 0.4493 - val_accuracy: 0.8043\n",
      "Epoch 267/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4984 - accuracy: 0.7731 - val_loss: 0.4472 - val_accuracy: 0.8152\n",
      "Epoch 268/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5022 - accuracy: 0.7799 - val_loss: 0.4454 - val_accuracy: 0.8043\n",
      "Epoch 269/1000\n",
      "736/736 [==============================] - 0s 107us/step - loss: 0.5098 - accuracy: 0.7622 - val_loss: 0.4500 - val_accuracy: 0.7826\n",
      "Epoch 270/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.4998 - accuracy: 0.7595 - val_loss: 0.4471 - val_accuracy: 0.8043\n",
      "Epoch 271/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5162 - accuracy: 0.7500 - val_loss: 0.4482 - val_accuracy: 0.8043\n",
      "Epoch 272/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5044 - accuracy: 0.7690 - val_loss: 0.4516 - val_accuracy: 0.7826\n",
      "Epoch 273/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.5071 - accuracy: 0.7758 - val_loss: 0.4499 - val_accuracy: 0.8043\n",
      "Epoch 274/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5026 - accuracy: 0.7622 - val_loss: 0.4491 - val_accuracy: 0.8043\n",
      "Epoch 275/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4881 - accuracy: 0.7785 - val_loss: 0.4453 - val_accuracy: 0.8152\n",
      "Epoch 276/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5011 - accuracy: 0.7745 - val_loss: 0.4466 - val_accuracy: 0.8043\n",
      "Epoch 277/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5082 - accuracy: 0.7731 - val_loss: 0.4474 - val_accuracy: 0.7935\n",
      "Epoch 278/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4978 - accuracy: 0.7826 - val_loss: 0.4452 - val_accuracy: 0.8152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5029 - accuracy: 0.7663 - val_loss: 0.4437 - val_accuracy: 0.8152\n",
      "Epoch 280/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5061 - accuracy: 0.7677 - val_loss: 0.4459 - val_accuracy: 0.8043\n",
      "Epoch 281/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4987 - accuracy: 0.7772 - val_loss: 0.4411 - val_accuracy: 0.8152\n",
      "Epoch 282/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4805 - accuracy: 0.7948 - val_loss: 0.4398 - val_accuracy: 0.8043\n",
      "Epoch 283/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4938 - accuracy: 0.7772 - val_loss: 0.4407 - val_accuracy: 0.8152\n",
      "Epoch 284/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5061 - accuracy: 0.7663 - val_loss: 0.4418 - val_accuracy: 0.8152\n",
      "Epoch 285/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5045 - accuracy: 0.7772 - val_loss: 0.4430 - val_accuracy: 0.8043\n",
      "Epoch 286/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.5025 - accuracy: 0.7731 - val_loss: 0.4427 - val_accuracy: 0.8043\n",
      "Epoch 287/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4959 - accuracy: 0.7812 - val_loss: 0.4468 - val_accuracy: 0.7826\n",
      "Epoch 288/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5057 - accuracy: 0.7690 - val_loss: 0.4445 - val_accuracy: 0.8152\n",
      "Epoch 289/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.5027 - accuracy: 0.7649 - val_loss: 0.4423 - val_accuracy: 0.8152\n",
      "Epoch 290/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.4935 - accuracy: 0.7745 - val_loss: 0.4472 - val_accuracy: 0.7826\n",
      "Epoch 291/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4957 - accuracy: 0.7745 - val_loss: 0.4453 - val_accuracy: 0.7826\n",
      "Epoch 292/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.5034 - accuracy: 0.7704 - val_loss: 0.4428 - val_accuracy: 0.8152\n",
      "Epoch 293/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.5000 - accuracy: 0.7758 - val_loss: 0.4419 - val_accuracy: 0.8152\n",
      "Epoch 294/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.5040 - accuracy: 0.7812 - val_loss: 0.4424 - val_accuracy: 0.8043\n",
      "Epoch 295/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.4799 - accuracy: 0.7867 - val_loss: 0.4404 - val_accuracy: 0.8152\n",
      "Epoch 296/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4963 - accuracy: 0.7609 - val_loss: 0.4403 - val_accuracy: 0.8152\n",
      "Epoch 297/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.4847 - accuracy: 0.7717 - val_loss: 0.4391 - val_accuracy: 0.8152\n",
      "Epoch 298/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.4948 - accuracy: 0.7595 - val_loss: 0.4421 - val_accuracy: 0.7826\n",
      "Epoch 299/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.4940 - accuracy: 0.7826 - val_loss: 0.4453 - val_accuracy: 0.7826\n",
      "Epoch 300/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.4860 - accuracy: 0.7731 - val_loss: 0.4381 - val_accuracy: 0.8152\n",
      "Epoch 301/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.5027 - accuracy: 0.7731 - val_loss: 0.4394 - val_accuracy: 0.8152\n",
      "Epoch 302/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4907 - accuracy: 0.7677 - val_loss: 0.4399 - val_accuracy: 0.8152\n",
      "Epoch 303/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.5000 - accuracy: 0.7582 - val_loss: 0.4392 - val_accuracy: 0.8152\n",
      "Epoch 304/1000\n",
      "736/736 [==============================] - 0s 58us/step - loss: 0.4949 - accuracy: 0.7731 - val_loss: 0.4379 - val_accuracy: 0.8152\n",
      "Epoch 305/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.4939 - accuracy: 0.7745 - val_loss: 0.4382 - val_accuracy: 0.8152\n",
      "Epoch 306/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4928 - accuracy: 0.7935 - val_loss: 0.4383 - val_accuracy: 0.8043\n",
      "Epoch 307/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4905 - accuracy: 0.7745 - val_loss: 0.4383 - val_accuracy: 0.8152\n",
      "Epoch 308/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4967 - accuracy: 0.7745 - val_loss: 0.4417 - val_accuracy: 0.7826\n",
      "Epoch 309/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4918 - accuracy: 0.7826 - val_loss: 0.4375 - val_accuracy: 0.8152\n",
      "Epoch 310/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.4992 - accuracy: 0.7840 - val_loss: 0.4386 - val_accuracy: 0.8152\n",
      "Epoch 311/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.4875 - accuracy: 0.7880 - val_loss: 0.4368 - val_accuracy: 0.8152\n",
      "Epoch 312/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4942 - accuracy: 0.7880 - val_loss: 0.4351 - val_accuracy: 0.8043\n",
      "Epoch 313/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4917 - accuracy: 0.7704 - val_loss: 0.4380 - val_accuracy: 0.7826\n",
      "Epoch 314/1000\n",
      "736/736 [==============================] - 0s 72us/step - loss: 0.4901 - accuracy: 0.7717 - val_loss: 0.4377 - val_accuracy: 0.8152\n",
      "Epoch 315/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.4915 - accuracy: 0.7853 - val_loss: 0.4359 - val_accuracy: 0.8261\n",
      "Epoch 316/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4916 - accuracy: 0.7853 - val_loss: 0.4401 - val_accuracy: 0.7826\n",
      "Epoch 317/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4878 - accuracy: 0.7840 - val_loss: 0.4362 - val_accuracy: 0.8152\n",
      "Epoch 318/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4975 - accuracy: 0.7717 - val_loss: 0.4381 - val_accuracy: 0.7826\n",
      "Epoch 319/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4942 - accuracy: 0.7717 - val_loss: 0.4344 - val_accuracy: 0.8152\n",
      "Epoch 320/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4801 - accuracy: 0.7772 - val_loss: 0.4358 - val_accuracy: 0.8043\n",
      "Epoch 321/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.4989 - accuracy: 0.7840 - val_loss: 0.4356 - val_accuracy: 0.8043\n",
      "Epoch 322/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.4996 - accuracy: 0.7840 - val_loss: 0.4369 - val_accuracy: 0.8152\n",
      "Epoch 323/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4936 - accuracy: 0.7908 - val_loss: 0.4388 - val_accuracy: 0.7826\n",
      "Epoch 324/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.4911 - accuracy: 0.7826 - val_loss: 0.4368 - val_accuracy: 0.8043\n",
      "Epoch 325/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.4931 - accuracy: 0.7908 - val_loss: 0.4345 - val_accuracy: 0.8152\n",
      "Epoch 326/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4977 - accuracy: 0.7826 - val_loss: 0.4353 - val_accuracy: 0.8152\n",
      "Epoch 327/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4933 - accuracy: 0.7799 - val_loss: 0.4343 - val_accuracy: 0.8152\n",
      "Epoch 328/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4932 - accuracy: 0.7812 - val_loss: 0.4353 - val_accuracy: 0.8043\n",
      "Epoch 329/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.4899 - accuracy: 0.7853 - val_loss: 0.4332 - val_accuracy: 0.8261\n",
      "Epoch 330/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4811 - accuracy: 0.7840 - val_loss: 0.4335 - val_accuracy: 0.8152\n",
      "Epoch 331/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.4979 - accuracy: 0.7826 - val_loss: 0.4332 - val_accuracy: 0.8152\n",
      "Epoch 332/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4889 - accuracy: 0.7962 - val_loss: 0.4377 - val_accuracy: 0.8478\n",
      "Epoch 333/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.4926 - accuracy: 0.7853 - val_loss: 0.4382 - val_accuracy: 0.7826\n",
      "Epoch 334/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4815 - accuracy: 0.7921 - val_loss: 0.4315 - val_accuracy: 0.8261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/1000\n",
      "736/736 [==============================] - 0s 73us/step - loss: 0.4939 - accuracy: 0.7609 - val_loss: 0.4326 - val_accuracy: 0.8261\n",
      "Epoch 336/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4810 - accuracy: 0.8043 - val_loss: 0.4304 - val_accuracy: 0.8261\n",
      "Epoch 337/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.4837 - accuracy: 0.7840 - val_loss: 0.4344 - val_accuracy: 0.8261\n",
      "Epoch 338/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.4853 - accuracy: 0.7758 - val_loss: 0.4308 - val_accuracy: 0.8261\n",
      "Epoch 339/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.4854 - accuracy: 0.7812 - val_loss: 0.4307 - val_accuracy: 0.8261\n",
      "Epoch 340/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.4847 - accuracy: 0.7921 - val_loss: 0.4303 - val_accuracy: 0.8261\n",
      "Epoch 341/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4943 - accuracy: 0.7962 - val_loss: 0.4322 - val_accuracy: 0.8261\n",
      "Epoch 342/1000\n",
      "736/736 [==============================] - 0s 56us/step - loss: 0.4736 - accuracy: 0.8003 - val_loss: 0.4335 - val_accuracy: 0.7935\n",
      "Epoch 343/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4829 - accuracy: 0.7908 - val_loss: 0.4319 - val_accuracy: 0.8261\n",
      "Epoch 344/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4808 - accuracy: 0.7880 - val_loss: 0.4306 - val_accuracy: 0.8152\n",
      "Epoch 345/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4744 - accuracy: 0.7880 - val_loss: 0.4293 - val_accuracy: 0.8261\n",
      "Epoch 346/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4718 - accuracy: 0.8016 - val_loss: 0.4317 - val_accuracy: 0.7826\n",
      "Epoch 347/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4579 - accuracy: 0.8030 - val_loss: 0.4312 - val_accuracy: 0.7826\n",
      "Epoch 348/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4821 - accuracy: 0.7826 - val_loss: 0.4285 - val_accuracy: 0.8152\n",
      "Epoch 349/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.4786 - accuracy: 0.7758 - val_loss: 0.4273 - val_accuracy: 0.8152\n",
      "Epoch 350/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4776 - accuracy: 0.7772 - val_loss: 0.4280 - val_accuracy: 0.8261\n",
      "Epoch 351/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4861 - accuracy: 0.7799 - val_loss: 0.4266 - val_accuracy: 0.8261\n",
      "Epoch 352/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4795 - accuracy: 0.7948 - val_loss: 0.4276 - val_accuracy: 0.8261\n",
      "Epoch 353/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4901 - accuracy: 0.7908 - val_loss: 0.4258 - val_accuracy: 0.8152\n",
      "Epoch 354/1000\n",
      "736/736 [==============================] - 0s 137us/step - loss: 0.4834 - accuracy: 0.7880 - val_loss: 0.4261 - val_accuracy: 0.8152\n",
      "Epoch 355/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.4660 - accuracy: 0.7989 - val_loss: 0.4252 - val_accuracy: 0.8152\n",
      "Epoch 356/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4886 - accuracy: 0.7717 - val_loss: 0.4259 - val_accuracy: 0.8261\n",
      "Epoch 357/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.4738 - accuracy: 0.8057 - val_loss: 0.4257 - val_accuracy: 0.8043\n",
      "Epoch 358/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4795 - accuracy: 0.7840 - val_loss: 0.4255 - val_accuracy: 0.8152\n",
      "Epoch 359/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.4862 - accuracy: 0.7935 - val_loss: 0.4315 - val_accuracy: 0.7826\n",
      "Epoch 360/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4816 - accuracy: 0.7840 - val_loss: 0.4252 - val_accuracy: 0.8261\n",
      "Epoch 361/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4668 - accuracy: 0.7948 - val_loss: 0.4236 - val_accuracy: 0.8261\n",
      "Epoch 362/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.4729 - accuracy: 0.7853 - val_loss: 0.4223 - val_accuracy: 0.8261\n",
      "Epoch 363/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4937 - accuracy: 0.7840 - val_loss: 0.4256 - val_accuracy: 0.8261\n",
      "Epoch 364/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4720 - accuracy: 0.7894 - val_loss: 0.4248 - val_accuracy: 0.8370\n",
      "Epoch 365/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4872 - accuracy: 0.7948 - val_loss: 0.4239 - val_accuracy: 0.8152\n",
      "Epoch 366/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.4810 - accuracy: 0.7894 - val_loss: 0.4248 - val_accuracy: 0.8261\n",
      "Epoch 367/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4799 - accuracy: 0.7840 - val_loss: 0.4237 - val_accuracy: 0.8370\n",
      "Epoch 368/1000\n",
      "736/736 [==============================] - 0s 114us/step - loss: 0.4707 - accuracy: 0.7935 - val_loss: 0.4212 - val_accuracy: 0.8370\n",
      "Epoch 369/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4824 - accuracy: 0.7894 - val_loss: 0.4222 - val_accuracy: 0.8261\n",
      "Epoch 370/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4814 - accuracy: 0.7731 - val_loss: 0.4216 - val_accuracy: 0.8261\n",
      "Epoch 371/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4664 - accuracy: 0.7989 - val_loss: 0.4274 - val_accuracy: 0.7826\n",
      "Epoch 372/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4824 - accuracy: 0.7826 - val_loss: 0.4234 - val_accuracy: 0.8261\n",
      "Epoch 373/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4687 - accuracy: 0.8043 - val_loss: 0.4215 - val_accuracy: 0.8261\n",
      "Epoch 374/1000\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.4732 - accuracy: 0.7840 - val_loss: 0.4215 - val_accuracy: 0.8152\n",
      "Epoch 375/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4754 - accuracy: 0.7989 - val_loss: 0.4220 - val_accuracy: 0.8152\n",
      "Epoch 376/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4700 - accuracy: 0.8030 - val_loss: 0.4209 - val_accuracy: 0.8152\n",
      "Epoch 377/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.4736 - accuracy: 0.7962 - val_loss: 0.4206 - val_accuracy: 0.8370\n",
      "Epoch 378/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.4655 - accuracy: 0.7880 - val_loss: 0.4189 - val_accuracy: 0.8370\n",
      "Epoch 379/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4901 - accuracy: 0.7731 - val_loss: 0.4209 - val_accuracy: 0.8370\n",
      "Epoch 380/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4637 - accuracy: 0.7921 - val_loss: 0.4186 - val_accuracy: 0.8370\n",
      "Epoch 381/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4602 - accuracy: 0.8016 - val_loss: 0.4186 - val_accuracy: 0.8261\n",
      "Epoch 382/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.4666 - accuracy: 0.7894 - val_loss: 0.4180 - val_accuracy: 0.8152\n",
      "Epoch 383/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4631 - accuracy: 0.7962 - val_loss: 0.4182 - val_accuracy: 0.8261\n",
      "Epoch 384/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4669 - accuracy: 0.8016 - val_loss: 0.4176 - val_accuracy: 0.8261\n",
      "Epoch 385/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4739 - accuracy: 0.7921 - val_loss: 0.4163 - val_accuracy: 0.8261\n",
      "Epoch 386/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4596 - accuracy: 0.7908 - val_loss: 0.4176 - val_accuracy: 0.8261\n",
      "Epoch 387/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4710 - accuracy: 0.7989 - val_loss: 0.4208 - val_accuracy: 0.8261\n",
      "Epoch 388/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4735 - accuracy: 0.8016 - val_loss: 0.4175 - val_accuracy: 0.8152\n",
      "Epoch 389/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4665 - accuracy: 0.8016 - val_loss: 0.4172 - val_accuracy: 0.8370\n",
      "Epoch 390/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.4697 - accuracy: 0.7989 - val_loss: 0.4164 - val_accuracy: 0.8261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4683 - accuracy: 0.8098 - val_loss: 0.4170 - val_accuracy: 0.8152\n",
      "Epoch 392/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.4718 - accuracy: 0.7840 - val_loss: 0.4176 - val_accuracy: 0.8261\n",
      "Epoch 393/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.4727 - accuracy: 0.7894 - val_loss: 0.4181 - val_accuracy: 0.8261\n",
      "Epoch 394/1000\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.4693 - accuracy: 0.7989 - val_loss: 0.4145 - val_accuracy: 0.8370\n",
      "Epoch 395/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.4486 - accuracy: 0.8166 - val_loss: 0.4161 - val_accuracy: 0.8043\n",
      "Epoch 396/1000\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.4683 - accuracy: 0.7894 - val_loss: 0.4135 - val_accuracy: 0.8370\n",
      "Epoch 397/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4692 - accuracy: 0.7948 - val_loss: 0.4210 - val_accuracy: 0.8043\n",
      "Epoch 398/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.4681 - accuracy: 0.7976 - val_loss: 0.4149 - val_accuracy: 0.8370\n",
      "Epoch 399/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.4575 - accuracy: 0.7894 - val_loss: 0.4127 - val_accuracy: 0.8370\n",
      "Epoch 400/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4603 - accuracy: 0.7989 - val_loss: 0.4144 - val_accuracy: 0.8261\n",
      "Epoch 401/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4633 - accuracy: 0.7908 - val_loss: 0.4131 - val_accuracy: 0.8370\n",
      "Epoch 402/1000\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.81 - 0s 71us/step - loss: 0.4603 - accuracy: 0.7935 - val_loss: 0.4162 - val_accuracy: 0.8370\n",
      "Epoch 403/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4621 - accuracy: 0.7840 - val_loss: 0.4196 - val_accuracy: 0.8043\n",
      "Epoch 404/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.4608 - accuracy: 0.8043 - val_loss: 0.4116 - val_accuracy: 0.8370\n",
      "Epoch 405/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.4624 - accuracy: 0.7989 - val_loss: 0.4118 - val_accuracy: 0.8370\n",
      "Epoch 406/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.4696 - accuracy: 0.8030 - val_loss: 0.4118 - val_accuracy: 0.8370\n",
      "Epoch 407/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4498 - accuracy: 0.8057 - val_loss: 0.4099 - val_accuracy: 0.8370\n",
      "Epoch 408/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4707 - accuracy: 0.7962 - val_loss: 0.4107 - val_accuracy: 0.8370\n",
      "Epoch 409/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4646 - accuracy: 0.7948 - val_loss: 0.4114 - val_accuracy: 0.8370\n",
      "Epoch 410/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.4596 - accuracy: 0.7989 - val_loss: 0.4104 - val_accuracy: 0.8370\n",
      "Epoch 411/1000\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.4578 - accuracy: 0.8016 - val_loss: 0.4097 - val_accuracy: 0.8370\n",
      "Epoch 412/1000\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.4585 - accuracy: 0.7989 - val_loss: 0.4127 - val_accuracy: 0.8370\n",
      "Epoch 413/1000\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.4564 - accuracy: 0.8111 - val_loss: 0.4091 - val_accuracy: 0.8370\n",
      "Epoch 414/1000\n",
      "736/736 [==============================] - 0s 84us/step - loss: 0.4545 - accuracy: 0.8179 - val_loss: 0.4094 - val_accuracy: 0.8370\n",
      "Epoch 415/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.4525 - accuracy: 0.8057 - val_loss: 0.4119 - val_accuracy: 0.8261\n",
      "Epoch 416/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4564 - accuracy: 0.7948 - val_loss: 0.4111 - val_accuracy: 0.8370\n",
      "Epoch 417/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.4551 - accuracy: 0.8207 - val_loss: 0.4075 - val_accuracy: 0.8370\n",
      "Epoch 418/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4614 - accuracy: 0.8003 - val_loss: 0.4103 - val_accuracy: 0.8370\n",
      "Epoch 419/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4581 - accuracy: 0.8016 - val_loss: 0.4086 - val_accuracy: 0.8370\n",
      "Epoch 420/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.4614 - accuracy: 0.8071 - val_loss: 0.4104 - val_accuracy: 0.8370\n",
      "Epoch 421/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.4618 - accuracy: 0.7976 - val_loss: 0.4080 - val_accuracy: 0.8478\n",
      "Epoch 422/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4374 - accuracy: 0.8152 - val_loss: 0.4047 - val_accuracy: 0.8370\n",
      "Epoch 423/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.4454 - accuracy: 0.8071 - val_loss: 0.4129 - val_accuracy: 0.8152\n",
      "Epoch 424/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.4524 - accuracy: 0.8098 - val_loss: 0.4074 - val_accuracy: 0.8370\n",
      "Epoch 425/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4486 - accuracy: 0.8125 - val_loss: 0.4058 - val_accuracy: 0.8370\n",
      "Epoch 426/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4677 - accuracy: 0.8016 - val_loss: 0.4058 - val_accuracy: 0.8370\n",
      "Epoch 427/1000\n",
      "736/736 [==============================] - 0s 84us/step - loss: 0.4446 - accuracy: 0.7989 - val_loss: 0.4054 - val_accuracy: 0.8370\n",
      "Epoch 428/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.4500 - accuracy: 0.8166 - val_loss: 0.4024 - val_accuracy: 0.8370\n",
      "Epoch 429/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.4485 - accuracy: 0.8057 - val_loss: 0.4037 - val_accuracy: 0.8370\n",
      "Epoch 430/1000\n",
      "736/736 [==============================] - 0s 72us/step - loss: 0.4388 - accuracy: 0.8125 - val_loss: 0.4019 - val_accuracy: 0.8370\n",
      "Epoch 431/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.4608 - accuracy: 0.8139 - val_loss: 0.4135 - val_accuracy: 0.8152\n",
      "Epoch 432/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4505 - accuracy: 0.8084 - val_loss: 0.4029 - val_accuracy: 0.8370\n",
      "Epoch 433/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4593 - accuracy: 0.7989 - val_loss: 0.4028 - val_accuracy: 0.8478\n",
      "Epoch 434/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4576 - accuracy: 0.8057 - val_loss: 0.4071 - val_accuracy: 0.8261\n",
      "Epoch 435/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4632 - accuracy: 0.8043 - val_loss: 0.4068 - val_accuracy: 0.8152\n",
      "Epoch 436/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4609 - accuracy: 0.8125 - val_loss: 0.4045 - val_accuracy: 0.8478\n",
      "Epoch 437/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4509 - accuracy: 0.8057 - val_loss: 0.4041 - val_accuracy: 0.8370\n",
      "Epoch 438/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4373 - accuracy: 0.8030 - val_loss: 0.4063 - val_accuracy: 0.8587\n",
      "Epoch 439/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4539 - accuracy: 0.8166 - val_loss: 0.4027 - val_accuracy: 0.8370\n",
      "Epoch 440/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4442 - accuracy: 0.8098 - val_loss: 0.4000 - val_accuracy: 0.8478\n",
      "Epoch 441/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4445 - accuracy: 0.8016 - val_loss: 0.3998 - val_accuracy: 0.8478\n",
      "Epoch 442/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4505 - accuracy: 0.8003 - val_loss: 0.4035 - val_accuracy: 0.8370\n",
      "Epoch 443/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4568 - accuracy: 0.8098 - val_loss: 0.4195 - val_accuracy: 0.8043\n",
      "Epoch 444/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4515 - accuracy: 0.8016 - val_loss: 0.3997 - val_accuracy: 0.8478\n",
      "Epoch 445/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.4412 - accuracy: 0.8043 - val_loss: 0.3998 - val_accuracy: 0.8587\n",
      "Epoch 446/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4410 - accuracy: 0.8207 - val_loss: 0.3991 - val_accuracy: 0.8370\n",
      "Epoch 447/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.4616 - accuracy: 0.8030 - val_loss: 0.4025 - val_accuracy: 0.8478\n",
      "Epoch 448/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.4449 - accuracy: 0.8179 - val_loss: 0.3984 - val_accuracy: 0.8370\n",
      "Epoch 449/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.4615 - accuracy: 0.7948 - val_loss: 0.4037 - val_accuracy: 0.8587\n",
      "Epoch 450/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.4377 - accuracy: 0.8234 - val_loss: 0.4017 - val_accuracy: 0.8478\n",
      "Epoch 451/1000\n",
      "736/736 [==============================] - 0s 73us/step - loss: 0.4564 - accuracy: 0.8043 - val_loss: 0.4005 - val_accuracy: 0.8370\n",
      "Epoch 452/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4378 - accuracy: 0.8125 - val_loss: 0.4000 - val_accuracy: 0.8587\n",
      "Epoch 453/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4423 - accuracy: 0.8166 - val_loss: 0.3980 - val_accuracy: 0.8478\n",
      "Epoch 454/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4458 - accuracy: 0.8071 - val_loss: 0.3974 - val_accuracy: 0.8587\n",
      "Epoch 455/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4425 - accuracy: 0.8220 - val_loss: 0.3955 - val_accuracy: 0.8370\n",
      "Epoch 456/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4379 - accuracy: 0.8152 - val_loss: 0.3986 - val_accuracy: 0.8370\n",
      "Epoch 457/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4230 - accuracy: 0.8274 - val_loss: 0.3961 - val_accuracy: 0.8370\n",
      "Epoch 458/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4350 - accuracy: 0.8071 - val_loss: 0.3979 - val_accuracy: 0.8587\n",
      "Epoch 459/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.4327 - accuracy: 0.8247 - val_loss: 0.3956 - val_accuracy: 0.8478\n",
      "Epoch 460/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4407 - accuracy: 0.8111 - val_loss: 0.3936 - val_accuracy: 0.8370\n",
      "Epoch 461/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.4523 - accuracy: 0.8111 - val_loss: 0.3954 - val_accuracy: 0.8370\n",
      "Epoch 462/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4329 - accuracy: 0.8166 - val_loss: 0.3958 - val_accuracy: 0.8696\n",
      "Epoch 463/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4414 - accuracy: 0.8247 - val_loss: 0.3988 - val_accuracy: 0.8587\n",
      "Epoch 464/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4335 - accuracy: 0.8207 - val_loss: 0.3917 - val_accuracy: 0.8370\n",
      "Epoch 465/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4518 - accuracy: 0.8166 - val_loss: 0.3954 - val_accuracy: 0.8370\n",
      "Epoch 466/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4222 - accuracy: 0.8125 - val_loss: 0.3946 - val_accuracy: 0.8478\n",
      "Epoch 467/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4341 - accuracy: 0.8098 - val_loss: 0.4018 - val_accuracy: 0.8261\n",
      "Epoch 468/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4351 - accuracy: 0.8043 - val_loss: 0.3971 - val_accuracy: 0.8370\n",
      "Epoch 469/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4338 - accuracy: 0.8247 - val_loss: 0.3933 - val_accuracy: 0.8587\n",
      "Epoch 470/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4405 - accuracy: 0.8152 - val_loss: 0.3923 - val_accuracy: 0.8696\n",
      "Epoch 471/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4341 - accuracy: 0.8125 - val_loss: 0.3900 - val_accuracy: 0.8478\n",
      "Epoch 472/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4410 - accuracy: 0.8207 - val_loss: 0.3906 - val_accuracy: 0.8587\n",
      "Epoch 473/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.4439 - accuracy: 0.8139 - val_loss: 0.3893 - val_accuracy: 0.8587\n",
      "Epoch 474/1000\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.4343 - accuracy: 0.8179 - val_loss: 0.3891 - val_accuracy: 0.8696\n",
      "Epoch 475/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4388 - accuracy: 0.8207 - val_loss: 0.3894 - val_accuracy: 0.8478\n",
      "Epoch 476/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.4267 - accuracy: 0.8207 - val_loss: 0.3913 - val_accuracy: 0.8587\n",
      "Epoch 477/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4458 - accuracy: 0.8207 - val_loss: 0.3920 - val_accuracy: 0.8587\n",
      "Epoch 478/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.4230 - accuracy: 0.8234 - val_loss: 0.3904 - val_accuracy: 0.8587\n",
      "Epoch 479/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.4320 - accuracy: 0.8274 - val_loss: 0.3878 - val_accuracy: 0.8478\n",
      "Epoch 480/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4379 - accuracy: 0.8152 - val_loss: 0.3873 - val_accuracy: 0.8587\n",
      "Epoch 481/1000\n",
      "736/736 [==============================] - 0s 84us/step - loss: 0.4241 - accuracy: 0.8098 - val_loss: 0.3927 - val_accuracy: 0.8478\n",
      "Epoch 482/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4414 - accuracy: 0.8098 - val_loss: 0.3862 - val_accuracy: 0.8696\n",
      "Epoch 483/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.4386 - accuracy: 0.8193 - val_loss: 0.4002 - val_accuracy: 0.8261\n",
      "Epoch 484/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.4372 - accuracy: 0.8247 - val_loss: 0.3853 - val_accuracy: 0.8696\n",
      "Epoch 485/1000\n",
      "736/736 [==============================] - 0s 77us/step - loss: 0.4255 - accuracy: 0.8302 - val_loss: 0.3855 - val_accuracy: 0.8696\n",
      "Epoch 486/1000\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.4271 - accuracy: 0.8220 - val_loss: 0.3900 - val_accuracy: 0.8587\n",
      "Epoch 487/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.4251 - accuracy: 0.8302 - val_loss: 0.3832 - val_accuracy: 0.8696\n",
      "Epoch 488/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4289 - accuracy: 0.8220 - val_loss: 0.3838 - val_accuracy: 0.8587\n",
      "Epoch 489/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4221 - accuracy: 0.8247 - val_loss: 0.3833 - val_accuracy: 0.8696\n",
      "Epoch 490/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4380 - accuracy: 0.8247 - val_loss: 0.3856 - val_accuracy: 0.8696\n",
      "Epoch 491/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4349 - accuracy: 0.8220 - val_loss: 0.3852 - val_accuracy: 0.8696\n",
      "Epoch 492/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4247 - accuracy: 0.8274 - val_loss: 0.3814 - val_accuracy: 0.8696\n",
      "Epoch 493/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4473 - accuracy: 0.8193 - val_loss: 0.3847 - val_accuracy: 0.8696\n",
      "Epoch 494/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.4299 - accuracy: 0.8356 - val_loss: 0.3826 - val_accuracy: 0.8696\n",
      "Epoch 495/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4133 - accuracy: 0.8288 - val_loss: 0.3800 - val_accuracy: 0.8696\n",
      "Epoch 496/1000\n",
      "736/736 [==============================] - 0s 108us/step - loss: 0.4331 - accuracy: 0.8356 - val_loss: 0.3850 - val_accuracy: 0.8478\n",
      "Epoch 497/1000\n",
      "736/736 [==============================] - 0s 115us/step - loss: 0.4363 - accuracy: 0.8166 - val_loss: 0.3823 - val_accuracy: 0.8696\n",
      "Epoch 498/1000\n",
      "736/736 [==============================] - 0s 113us/step - loss: 0.4295 - accuracy: 0.8207 - val_loss: 0.3795 - val_accuracy: 0.8696\n",
      "Epoch 499/1000\n",
      "736/736 [==============================] - 0s 117us/step - loss: 0.4232 - accuracy: 0.8274 - val_loss: 0.3803 - val_accuracy: 0.8696\n",
      "Epoch 500/1000\n",
      "736/736 [==============================] - 0s 112us/step - loss: 0.4318 - accuracy: 0.8247 - val_loss: 0.3825 - val_accuracy: 0.8696\n",
      "Epoch 501/1000\n",
      "736/736 [==============================] - 0s 107us/step - loss: 0.4305 - accuracy: 0.8315 - val_loss: 0.3806 - val_accuracy: 0.8587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.4147 - accuracy: 0.8302 - val_loss: 0.3785 - val_accuracy: 0.8696\n",
      "Epoch 503/1000\n",
      "736/736 [==============================] - 0s 105us/step - loss: 0.4165 - accuracy: 0.8261 - val_loss: 0.3778 - val_accuracy: 0.8587\n",
      "Epoch 504/1000\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.4161 - accuracy: 0.8274 - val_loss: 0.3774 - val_accuracy: 0.8696\n",
      "Epoch 505/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4343 - accuracy: 0.8234 - val_loss: 0.3781 - val_accuracy: 0.8696\n",
      "Epoch 506/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.4043 - accuracy: 0.8424 - val_loss: 0.3779 - val_accuracy: 0.8587\n",
      "Epoch 507/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4217 - accuracy: 0.8356 - val_loss: 0.3790 - val_accuracy: 0.8587\n",
      "Epoch 508/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.4106 - accuracy: 0.8274 - val_loss: 0.3771 - val_accuracy: 0.8696\n",
      "Epoch 509/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4135 - accuracy: 0.8234 - val_loss: 0.3798 - val_accuracy: 0.8587\n",
      "Epoch 510/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.4164 - accuracy: 0.8329 - val_loss: 0.3771 - val_accuracy: 0.8696\n",
      "Epoch 511/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4106 - accuracy: 0.8302 - val_loss: 0.3785 - val_accuracy: 0.8696\n",
      "Epoch 512/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.4129 - accuracy: 0.8302 - val_loss: 0.3898 - val_accuracy: 0.8370\n",
      "Epoch 513/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4092 - accuracy: 0.8451 - val_loss: 0.3740 - val_accuracy: 0.8696\n",
      "Epoch 514/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4236 - accuracy: 0.8179 - val_loss: 0.3762 - val_accuracy: 0.8804\n",
      "Epoch 515/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4242 - accuracy: 0.8383 - val_loss: 0.3794 - val_accuracy: 0.8587\n",
      "Epoch 516/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4236 - accuracy: 0.8370 - val_loss: 0.3767 - val_accuracy: 0.8587\n",
      "Epoch 517/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.4149 - accuracy: 0.8261 - val_loss: 0.3756 - val_accuracy: 0.8696\n",
      "Epoch 518/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.4164 - accuracy: 0.8397 - val_loss: 0.3806 - val_accuracy: 0.8478\n",
      "Epoch 519/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.4031 - accuracy: 0.8397 - val_loss: 0.3772 - val_accuracy: 0.8696\n",
      "Epoch 520/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4175 - accuracy: 0.8370 - val_loss: 0.3773 - val_accuracy: 0.8696\n",
      "Epoch 521/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4165 - accuracy: 0.8261 - val_loss: 0.3727 - val_accuracy: 0.8804\n",
      "Epoch 522/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4115 - accuracy: 0.8383 - val_loss: 0.3772 - val_accuracy: 0.8696\n",
      "Epoch 523/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4238 - accuracy: 0.8465 - val_loss: 0.3738 - val_accuracy: 0.8696\n",
      "Epoch 524/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4036 - accuracy: 0.8438 - val_loss: 0.3716 - val_accuracy: 0.8804\n",
      "Epoch 525/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4145 - accuracy: 0.8356 - val_loss: 0.3709 - val_accuracy: 0.8804\n",
      "Epoch 526/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4017 - accuracy: 0.8356 - val_loss: 0.3734 - val_accuracy: 0.8696\n",
      "Epoch 527/1000\n",
      "736/736 [==============================] - 0s 79us/step - loss: 0.4045 - accuracy: 0.8451 - val_loss: 0.3972 - val_accuracy: 0.8478\n",
      "Epoch 528/1000\n",
      "736/736 [==============================] - 0s 131us/step - loss: 0.4051 - accuracy: 0.8302 - val_loss: 0.3701 - val_accuracy: 0.8696\n",
      "Epoch 529/1000\n",
      "736/736 [==============================] - 0s 101us/step - loss: 0.4073 - accuracy: 0.8261 - val_loss: 0.3672 - val_accuracy: 0.8804\n",
      "Epoch 530/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.4151 - accuracy: 0.8220 - val_loss: 0.3757 - val_accuracy: 0.8696\n",
      "Epoch 531/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3871 - accuracy: 0.8492 - val_loss: 0.3660 - val_accuracy: 0.8804\n",
      "Epoch 532/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4138 - accuracy: 0.8424 - val_loss: 0.3693 - val_accuracy: 0.8804\n",
      "Epoch 533/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3989 - accuracy: 0.8505 - val_loss: 0.3661 - val_accuracy: 0.8696\n",
      "Epoch 534/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4131 - accuracy: 0.8220 - val_loss: 0.3743 - val_accuracy: 0.8478\n",
      "Epoch 535/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4062 - accuracy: 0.8315 - val_loss: 0.3691 - val_accuracy: 0.8587\n",
      "Epoch 536/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4150 - accuracy: 0.8234 - val_loss: 0.3715 - val_accuracy: 0.8804\n",
      "Epoch 537/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.4120 - accuracy: 0.8234 - val_loss: 0.3741 - val_accuracy: 0.8804\n",
      "Epoch 538/1000\n",
      "736/736 [==============================] - 0s 77us/step - loss: 0.3979 - accuracy: 0.8573 - val_loss: 0.3663 - val_accuracy: 0.8804\n",
      "Epoch 539/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3898 - accuracy: 0.8519 - val_loss: 0.3652 - val_accuracy: 0.8804\n",
      "Epoch 540/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.3984 - accuracy: 0.8424 - val_loss: 0.3718 - val_accuracy: 0.8478\n",
      "Epoch 541/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4175 - accuracy: 0.8397 - val_loss: 0.3655 - val_accuracy: 0.8804\n",
      "Epoch 542/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4138 - accuracy: 0.8356 - val_loss: 0.3641 - val_accuracy: 0.8804\n",
      "Epoch 543/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.4055 - accuracy: 0.8438 - val_loss: 0.3643 - val_accuracy: 0.8804\n",
      "Epoch 544/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.4118 - accuracy: 0.8234 - val_loss: 0.3628 - val_accuracy: 0.8804\n",
      "Epoch 545/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4020 - accuracy: 0.8478 - val_loss: 0.3627 - val_accuracy: 0.8804\n",
      "Epoch 546/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.3953 - accuracy: 0.8465 - val_loss: 0.3624 - val_accuracy: 0.8696\n",
      "Epoch 547/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.3940 - accuracy: 0.8533 - val_loss: 0.3605 - val_accuracy: 0.8804\n",
      "Epoch 548/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.4157 - accuracy: 0.8356 - val_loss: 0.3661 - val_accuracy: 0.8696\n",
      "Epoch 549/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.3990 - accuracy: 0.8397 - val_loss: 0.3619 - val_accuracy: 0.8804\n",
      "Epoch 550/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3985 - accuracy: 0.8397 - val_loss: 0.3633 - val_accuracy: 0.8696\n",
      "Epoch 551/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.3935 - accuracy: 0.8519 - val_loss: 0.3590 - val_accuracy: 0.8804\n",
      "Epoch 552/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3865 - accuracy: 0.8383 - val_loss: 0.3661 - val_accuracy: 0.8696\n",
      "Epoch 553/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3892 - accuracy: 0.8505 - val_loss: 0.3614 - val_accuracy: 0.8804\n",
      "Epoch 554/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.4152 - accuracy: 0.8302 - val_loss: 0.3611 - val_accuracy: 0.8913\n",
      "Epoch 555/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.4039 - accuracy: 0.8533 - val_loss: 0.3684 - val_accuracy: 0.8804\n",
      "Epoch 556/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3918 - accuracy: 0.8478 - val_loss: 0.3585 - val_accuracy: 0.8913\n",
      "Epoch 557/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3909 - accuracy: 0.8397 - val_loss: 0.3643 - val_accuracy: 0.8913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3888 - accuracy: 0.8424 - val_loss: 0.3610 - val_accuracy: 0.8804\n",
      "Epoch 559/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3839 - accuracy: 0.8478 - val_loss: 0.3550 - val_accuracy: 0.8804\n",
      "Epoch 560/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3963 - accuracy: 0.8519 - val_loss: 0.3555 - val_accuracy: 0.8913\n",
      "Epoch 561/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3905 - accuracy: 0.8505 - val_loss: 0.3554 - val_accuracy: 0.8696\n",
      "Epoch 562/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3907 - accuracy: 0.8492 - val_loss: 0.3715 - val_accuracy: 0.8804\n",
      "Epoch 563/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.4089 - accuracy: 0.8342 - val_loss: 0.3550 - val_accuracy: 0.8913\n",
      "Epoch 564/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3914 - accuracy: 0.8492 - val_loss: 0.3603 - val_accuracy: 0.8913\n",
      "Epoch 565/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3834 - accuracy: 0.8451 - val_loss: 0.3518 - val_accuracy: 0.8913\n",
      "Epoch 566/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.4007 - accuracy: 0.8438 - val_loss: 0.3542 - val_accuracy: 0.8696\n",
      "Epoch 567/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.3846 - accuracy: 0.8356 - val_loss: 0.3541 - val_accuracy: 0.8913\n",
      "Epoch 568/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.3978 - accuracy: 0.8478 - val_loss: 0.3571 - val_accuracy: 0.8804\n",
      "Epoch 569/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.3722 - accuracy: 0.8614 - val_loss: 0.3546 - val_accuracy: 0.8913\n",
      "Epoch 570/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.4047 - accuracy: 0.8451 - val_loss: 0.3534 - val_accuracy: 0.8696\n",
      "Epoch 571/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3859 - accuracy: 0.8438 - val_loss: 0.3547 - val_accuracy: 0.8913\n",
      "Epoch 572/1000\n",
      "736/736 [==============================] - 0s 58us/step - loss: 0.3985 - accuracy: 0.8546 - val_loss: 0.3540 - val_accuracy: 0.8696\n",
      "Epoch 573/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.4005 - accuracy: 0.8451 - val_loss: 0.3520 - val_accuracy: 0.8804\n",
      "Epoch 574/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.3872 - accuracy: 0.8601 - val_loss: 0.3512 - val_accuracy: 0.8804\n",
      "Epoch 575/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.3847 - accuracy: 0.8533 - val_loss: 0.3524 - val_accuracy: 0.8696\n",
      "Epoch 576/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3977 - accuracy: 0.8492 - val_loss: 0.3540 - val_accuracy: 0.8913\n",
      "Epoch 577/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3881 - accuracy: 0.8587 - val_loss: 0.3501 - val_accuracy: 0.8804\n",
      "Epoch 578/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3655 - accuracy: 0.8573 - val_loss: 0.3512 - val_accuracy: 0.8696\n",
      "Epoch 579/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3985 - accuracy: 0.8587 - val_loss: 0.3688 - val_accuracy: 0.8478\n",
      "Epoch 580/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3864 - accuracy: 0.8424 - val_loss: 0.3474 - val_accuracy: 0.8696\n",
      "Epoch 581/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.3955 - accuracy: 0.8465 - val_loss: 0.3500 - val_accuracy: 0.8696\n",
      "Epoch 582/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3794 - accuracy: 0.8410 - val_loss: 0.3460 - val_accuracy: 0.8913\n",
      "Epoch 583/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3886 - accuracy: 0.8438 - val_loss: 0.3514 - val_accuracy: 0.8696\n",
      "Epoch 584/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3774 - accuracy: 0.8573 - val_loss: 0.3557 - val_accuracy: 0.8478\n",
      "Epoch 585/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3736 - accuracy: 0.8601 - val_loss: 0.3461 - val_accuracy: 0.8696\n",
      "Epoch 586/1000\n",
      "736/736 [==============================] - 0s 136us/step - loss: 0.3715 - accuracy: 0.8573 - val_loss: 0.3528 - val_accuracy: 0.8587\n",
      "Epoch 587/1000\n",
      "736/736 [==============================] - 0s 124us/step - loss: 0.3791 - accuracy: 0.8628 - val_loss: 0.3460 - val_accuracy: 0.8913\n",
      "Epoch 588/1000\n",
      "736/736 [==============================] - 0s 89us/step - loss: 0.3885 - accuracy: 0.8492 - val_loss: 0.3496 - val_accuracy: 0.8696\n",
      "Epoch 589/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3894 - accuracy: 0.8465 - val_loss: 0.3479 - val_accuracy: 0.8913\n",
      "Epoch 590/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3827 - accuracy: 0.8560 - val_loss: 0.3550 - val_accuracy: 0.8478\n",
      "Epoch 591/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3810 - accuracy: 0.8573 - val_loss: 0.3464 - val_accuracy: 0.8696\n",
      "Epoch 592/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3699 - accuracy: 0.8533 - val_loss: 0.3685 - val_accuracy: 0.8587\n",
      "Epoch 593/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.3954 - accuracy: 0.8438 - val_loss: 0.3454 - val_accuracy: 0.9130\n",
      "Epoch 594/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.3824 - accuracy: 0.8438 - val_loss: 0.3496 - val_accuracy: 0.8913\n",
      "Epoch 595/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3903 - accuracy: 0.8451 - val_loss: 0.3452 - val_accuracy: 0.8804\n",
      "Epoch 596/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.3738 - accuracy: 0.8682 - val_loss: 0.3478 - val_accuracy: 0.8913\n",
      "Epoch 597/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.3879 - accuracy: 0.8560 - val_loss: 0.3427 - val_accuracy: 0.8804\n",
      "Epoch 598/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.3764 - accuracy: 0.8601 - val_loss: 0.3433 - val_accuracy: 0.8804\n",
      "Epoch 599/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3860 - accuracy: 0.8546 - val_loss: 0.3413 - val_accuracy: 0.9022\n",
      "Epoch 600/1000\n",
      "736/736 [==============================] - 0s 152us/step - loss: 0.3732 - accuracy: 0.8560 - val_loss: 0.3404 - val_accuracy: 0.8804\n",
      "Epoch 601/1000\n",
      "736/736 [==============================] - 0s 195us/step - loss: 0.3719 - accuracy: 0.8533 - val_loss: 0.3489 - val_accuracy: 0.8913\n",
      "Epoch 602/1000\n",
      "736/736 [==============================] - 0s 105us/step - loss: 0.3709 - accuracy: 0.8587 - val_loss: 0.3423 - val_accuracy: 0.8913\n",
      "Epoch 603/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3599 - accuracy: 0.8628 - val_loss: 0.3390 - val_accuracy: 0.8804\n",
      "Epoch 604/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3655 - accuracy: 0.8465 - val_loss: 0.3487 - val_accuracy: 0.8913\n",
      "Epoch 605/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3701 - accuracy: 0.8492 - val_loss: 0.3360 - val_accuracy: 0.9130\n",
      "Epoch 606/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3816 - accuracy: 0.8628 - val_loss: 0.3382 - val_accuracy: 0.9022\n",
      "Epoch 607/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3823 - accuracy: 0.8587 - val_loss: 0.3386 - val_accuracy: 0.9130\n",
      "Epoch 608/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3833 - accuracy: 0.8587 - val_loss: 0.3387 - val_accuracy: 0.9130\n",
      "Epoch 609/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3795 - accuracy: 0.8573 - val_loss: 0.3417 - val_accuracy: 0.8913\n",
      "Epoch 610/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.3710 - accuracy: 0.8601 - val_loss: 0.3436 - val_accuracy: 0.8587\n",
      "Epoch 611/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3640 - accuracy: 0.8601 - val_loss: 0.3375 - val_accuracy: 0.8804\n",
      "Epoch 612/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3606 - accuracy: 0.8682 - val_loss: 0.3358 - val_accuracy: 0.8804\n",
      "Epoch 613/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3637 - accuracy: 0.8614 - val_loss: 0.3382 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3765 - accuracy: 0.8492 - val_loss: 0.3336 - val_accuracy: 0.9022\n",
      "Epoch 615/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3749 - accuracy: 0.8533 - val_loss: 0.3429 - val_accuracy: 0.8913\n",
      "Epoch 616/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3699 - accuracy: 0.8601 - val_loss: 0.3339 - val_accuracy: 0.9130\n",
      "Epoch 617/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3776 - accuracy: 0.8601 - val_loss: 0.3354 - val_accuracy: 0.9130\n",
      "Epoch 618/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3823 - accuracy: 0.8573 - val_loss: 0.3332 - val_accuracy: 0.9130\n",
      "Epoch 619/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3713 - accuracy: 0.8655 - val_loss: 0.3322 - val_accuracy: 0.8804\n",
      "Epoch 620/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3530 - accuracy: 0.8750 - val_loss: 0.3331 - val_accuracy: 0.8696\n",
      "Epoch 621/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3556 - accuracy: 0.8791 - val_loss: 0.3290 - val_accuracy: 0.9130\n",
      "Epoch 622/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3568 - accuracy: 0.8655 - val_loss: 0.3409 - val_accuracy: 0.8587\n",
      "Epoch 623/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3654 - accuracy: 0.8546 - val_loss: 0.3368 - val_accuracy: 0.8913\n",
      "Epoch 624/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3588 - accuracy: 0.8859 - val_loss: 0.3298 - val_accuracy: 0.9130\n",
      "Epoch 625/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3738 - accuracy: 0.8696 - val_loss: 0.3318 - val_accuracy: 0.8696\n",
      "Epoch 626/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3546 - accuracy: 0.8601 - val_loss: 0.3284 - val_accuracy: 0.9130\n",
      "Epoch 627/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3701 - accuracy: 0.8709 - val_loss: 0.3286 - val_accuracy: 0.8913\n",
      "Epoch 628/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3673 - accuracy: 0.8628 - val_loss: 0.3325 - val_accuracy: 0.9130\n",
      "Epoch 629/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3745 - accuracy: 0.8641 - val_loss: 0.3266 - val_accuracy: 0.8913\n",
      "Epoch 630/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3645 - accuracy: 0.8709 - val_loss: 0.3582 - val_accuracy: 0.8370\n",
      "Epoch 631/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3808 - accuracy: 0.8573 - val_loss: 0.3366 - val_accuracy: 0.9130\n",
      "Epoch 632/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3565 - accuracy: 0.8696 - val_loss: 0.3338 - val_accuracy: 0.8696\n",
      "Epoch 633/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3575 - accuracy: 0.8696 - val_loss: 0.3272 - val_accuracy: 0.9130\n",
      "Epoch 634/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3660 - accuracy: 0.8709 - val_loss: 0.3305 - val_accuracy: 0.8913\n",
      "Epoch 635/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3579 - accuracy: 0.8777 - val_loss: 0.3250 - val_accuracy: 0.9022\n",
      "Epoch 636/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3478 - accuracy: 0.8750 - val_loss: 0.3340 - val_accuracy: 0.8913\n",
      "Epoch 637/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.3729 - accuracy: 0.8696 - val_loss: 0.3270 - val_accuracy: 0.9130\n",
      "Epoch 638/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3573 - accuracy: 0.8723 - val_loss: 0.3345 - val_accuracy: 0.8587\n",
      "Epoch 639/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3625 - accuracy: 0.8709 - val_loss: 0.3237 - val_accuracy: 0.8913\n",
      "Epoch 640/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.3496 - accuracy: 0.8668 - val_loss: 0.3227 - val_accuracy: 0.9022\n",
      "Epoch 641/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3568 - accuracy: 0.8696 - val_loss: 0.3375 - val_accuracy: 0.8913\n",
      "Epoch 642/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3686 - accuracy: 0.8764 - val_loss: 0.3258 - val_accuracy: 0.9022\n",
      "Epoch 643/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3581 - accuracy: 0.8641 - val_loss: 0.3234 - val_accuracy: 0.9022\n",
      "Epoch 644/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3473 - accuracy: 0.8791 - val_loss: 0.3227 - val_accuracy: 0.9022\n",
      "Epoch 645/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3511 - accuracy: 0.8845 - val_loss: 0.3202 - val_accuracy: 0.9022\n",
      "Epoch 646/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.3431 - accuracy: 0.8723 - val_loss: 0.3256 - val_accuracy: 0.8696\n",
      "Epoch 647/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3534 - accuracy: 0.8682 - val_loss: 0.3237 - val_accuracy: 0.8696\n",
      "Epoch 648/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.3602 - accuracy: 0.8668 - val_loss: 0.3345 - val_accuracy: 0.8587\n",
      "Epoch 649/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3498 - accuracy: 0.8777 - val_loss: 0.3202 - val_accuracy: 0.8913\n",
      "Epoch 650/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3447 - accuracy: 0.8859 - val_loss: 0.3228 - val_accuracy: 0.8696\n",
      "Epoch 651/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3597 - accuracy: 0.8628 - val_loss: 0.3195 - val_accuracy: 0.9022\n",
      "Epoch 652/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3532 - accuracy: 0.8777 - val_loss: 0.3292 - val_accuracy: 0.8696\n",
      "Epoch 653/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3653 - accuracy: 0.8696 - val_loss: 0.3214 - val_accuracy: 0.9022\n",
      "Epoch 654/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3406 - accuracy: 0.8777 - val_loss: 0.3189 - val_accuracy: 0.9022\n",
      "Epoch 655/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.3276 - accuracy: 0.8872 - val_loss: 0.3195 - val_accuracy: 0.8913\n",
      "Epoch 656/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.3658 - accuracy: 0.8696 - val_loss: 0.3340 - val_accuracy: 0.8587\n",
      "Epoch 657/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3474 - accuracy: 0.8845 - val_loss: 0.3160 - val_accuracy: 0.9022\n",
      "Epoch 658/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.3462 - accuracy: 0.8560 - val_loss: 0.3146 - val_accuracy: 0.8913\n",
      "Epoch 659/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3518 - accuracy: 0.8696 - val_loss: 0.3284 - val_accuracy: 0.8696\n",
      "Epoch 660/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.3521 - accuracy: 0.8750 - val_loss: 0.3212 - val_accuracy: 0.9022\n",
      "Epoch 661/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3467 - accuracy: 0.8709 - val_loss: 0.3256 - val_accuracy: 0.8696\n",
      "Epoch 662/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3352 - accuracy: 0.8859 - val_loss: 0.3218 - val_accuracy: 0.9022\n",
      "Epoch 663/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3565 - accuracy: 0.8723 - val_loss: 0.3367 - val_accuracy: 0.8587\n",
      "Epoch 664/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3447 - accuracy: 0.8696 - val_loss: 0.3156 - val_accuracy: 0.8913\n",
      "Epoch 665/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.3468 - accuracy: 0.8750 - val_loss: 0.3148 - val_accuracy: 0.9022\n",
      "Epoch 666/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.3462 - accuracy: 0.8655 - val_loss: 0.3140 - val_accuracy: 0.8913\n",
      "Epoch 667/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.3704 - accuracy: 0.8655 - val_loss: 0.3223 - val_accuracy: 0.8696\n",
      "Epoch 668/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3498 - accuracy: 0.8750 - val_loss: 0.3638 - val_accuracy: 0.8696\n",
      "Epoch 669/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3740 - accuracy: 0.8560 - val_loss: 0.3279 - val_accuracy: 0.8696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3428 - accuracy: 0.8832 - val_loss: 0.3168 - val_accuracy: 0.9022\n",
      "Epoch 671/1000\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.3259 - accuracy: 0.8791 - val_loss: 0.3154 - val_accuracy: 0.9022\n",
      "Epoch 672/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3438 - accuracy: 0.8804 - val_loss: 0.3187 - val_accuracy: 0.8913\n",
      "Epoch 673/1000\n",
      "736/736 [==============================] - 0s 100us/step - loss: 0.3483 - accuracy: 0.8845 - val_loss: 0.3198 - val_accuracy: 0.9022\n",
      "Epoch 674/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.3515 - accuracy: 0.8641 - val_loss: 0.3181 - val_accuracy: 0.8913\n",
      "Epoch 675/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3440 - accuracy: 0.8886 - val_loss: 0.3183 - val_accuracy: 0.8913\n",
      "Epoch 676/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3606 - accuracy: 0.8655 - val_loss: 0.3155 - val_accuracy: 0.8913\n",
      "Epoch 677/1000\n",
      "736/736 [==============================] - 0s 185us/step - loss: 0.3293 - accuracy: 0.8791 - val_loss: 0.3106 - val_accuracy: 0.8913\n",
      "Epoch 678/1000\n",
      "736/736 [==============================] - 0s 137us/step - loss: 0.3323 - accuracy: 0.8845 - val_loss: 0.3121 - val_accuracy: 0.9022\n",
      "Epoch 679/1000\n",
      "736/736 [==============================] - 0s 120us/step - loss: 0.3374 - accuracy: 0.8832 - val_loss: 0.3090 - val_accuracy: 0.9022\n",
      "Epoch 680/1000\n",
      "736/736 [==============================] - 0s 107us/step - loss: 0.3439 - accuracy: 0.8886 - val_loss: 0.3243 - val_accuracy: 0.9022\n",
      "Epoch 681/1000\n",
      "736/736 [==============================] - 0s 130us/step - loss: 0.3664 - accuracy: 0.8668 - val_loss: 0.3190 - val_accuracy: 0.8696\n",
      "Epoch 682/1000\n",
      "736/736 [==============================] - 0s 117us/step - loss: 0.3429 - accuracy: 0.8750 - val_loss: 0.3376 - val_accuracy: 0.8587\n",
      "Epoch 683/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3429 - accuracy: 0.8899 - val_loss: 0.3105 - val_accuracy: 0.9022\n",
      "Epoch 684/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3210 - accuracy: 0.8872 - val_loss: 0.3097 - val_accuracy: 0.8913\n",
      "Epoch 685/1000\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.3237 - accuracy: 0.8859 - val_loss: 0.3467 - val_accuracy: 0.8696\n",
      "Epoch 686/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.3447 - accuracy: 0.8696 - val_loss: 0.3774 - val_accuracy: 0.8370\n",
      "Epoch 687/1000\n",
      "736/736 [==============================] - 0s 72us/step - loss: 0.3383 - accuracy: 0.8791 - val_loss: 0.3253 - val_accuracy: 0.8804\n",
      "Epoch 688/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.3350 - accuracy: 0.8804 - val_loss: 0.3343 - val_accuracy: 0.8587\n",
      "Epoch 689/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.3296 - accuracy: 0.8899 - val_loss: 0.3059 - val_accuracy: 0.8913\n",
      "Epoch 690/1000\n",
      "736/736 [==============================] - 0s 77us/step - loss: 0.3413 - accuracy: 0.8832 - val_loss: 0.3128 - val_accuracy: 0.9022\n",
      "Epoch 691/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.3450 - accuracy: 0.8818 - val_loss: 0.3086 - val_accuracy: 0.9022\n",
      "Epoch 692/1000\n",
      "736/736 [==============================] - 0s 72us/step - loss: 0.3250 - accuracy: 0.8845 - val_loss: 0.3142 - val_accuracy: 0.9022\n",
      "Epoch 693/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3283 - accuracy: 0.8859 - val_loss: 0.3108 - val_accuracy: 0.8913\n",
      "Epoch 694/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3414 - accuracy: 0.8750 - val_loss: 0.3058 - val_accuracy: 0.9022\n",
      "Epoch 695/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.3297 - accuracy: 0.9022 - val_loss: 0.3123 - val_accuracy: 0.8804\n",
      "Epoch 696/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3231 - accuracy: 0.8954 - val_loss: 0.3042 - val_accuracy: 0.8913\n",
      "Epoch 697/1000\n",
      "736/736 [==============================] - 0s 72us/step - loss: 0.3345 - accuracy: 0.8804 - val_loss: 0.3074 - val_accuracy: 0.9022\n",
      "Epoch 698/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3304 - accuracy: 0.8899 - val_loss: 0.3763 - val_accuracy: 0.8370\n",
      "Epoch 699/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3269 - accuracy: 0.8967 - val_loss: 0.3065 - val_accuracy: 0.8913\n",
      "Epoch 700/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3364 - accuracy: 0.8818 - val_loss: 0.3570 - val_accuracy: 0.8478\n",
      "Epoch 701/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3268 - accuracy: 0.8899 - val_loss: 0.3117 - val_accuracy: 0.9022\n",
      "Epoch 702/1000\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.3310 - accuracy: 0.8886 - val_loss: 0.3210 - val_accuracy: 0.8913\n",
      "Epoch 703/1000\n",
      "736/736 [==============================] - 0s 77us/step - loss: 0.3243 - accuracy: 0.9090 - val_loss: 0.3096 - val_accuracy: 0.9022\n",
      "Epoch 704/1000\n",
      "736/736 [==============================] - 0s 91us/step - loss: 0.3424 - accuracy: 0.8818 - val_loss: 0.3030 - val_accuracy: 0.9022\n",
      "Epoch 705/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.3294 - accuracy: 0.8859 - val_loss: 0.3064 - val_accuracy: 0.9022\n",
      "Epoch 706/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3352 - accuracy: 0.8899 - val_loss: 0.3034 - val_accuracy: 0.9022\n",
      "Epoch 707/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3397 - accuracy: 0.8777 - val_loss: 0.3040 - val_accuracy: 0.8913\n",
      "Epoch 708/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3342 - accuracy: 0.8954 - val_loss: 0.3334 - val_accuracy: 0.8804\n",
      "Epoch 709/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3319 - accuracy: 0.8818 - val_loss: 0.3032 - val_accuracy: 0.9022\n",
      "Epoch 710/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3421 - accuracy: 0.8872 - val_loss: 0.3038 - val_accuracy: 0.9022\n",
      "Epoch 711/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3283 - accuracy: 0.8913 - val_loss: 0.3026 - val_accuracy: 0.8913\n",
      "Epoch 712/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3019 - accuracy: 0.8967 - val_loss: 0.3261 - val_accuracy: 0.8696\n",
      "Epoch 713/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.3282 - accuracy: 0.9049 - val_loss: 0.3134 - val_accuracy: 0.9022\n",
      "Epoch 714/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3352 - accuracy: 0.8927 - val_loss: 0.3016 - val_accuracy: 0.8913\n",
      "Epoch 715/1000\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.3320 - accuracy: 0.8913 - val_loss: 0.3025 - val_accuracy: 0.8913\n",
      "Epoch 716/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3279 - accuracy: 0.8818 - val_loss: 0.3014 - val_accuracy: 0.8913\n",
      "Epoch 717/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3314 - accuracy: 0.8981 - val_loss: 0.3320 - val_accuracy: 0.8804\n",
      "Epoch 718/1000\n",
      "736/736 [==============================] - 0s 77us/step - loss: 0.3288 - accuracy: 0.8899 - val_loss: 0.3194 - val_accuracy: 0.8804\n",
      "Epoch 719/1000\n",
      "736/736 [==============================] - 0s 117us/step - loss: 0.3202 - accuracy: 0.8967 - val_loss: 0.2995 - val_accuracy: 0.8913\n",
      "Epoch 720/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.3461 - accuracy: 0.8872 - val_loss: 0.3011 - val_accuracy: 0.8913\n",
      "Epoch 721/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3351 - accuracy: 0.8845 - val_loss: 0.3321 - val_accuracy: 0.8696\n",
      "Epoch 722/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3142 - accuracy: 0.8954 - val_loss: 0.3233 - val_accuracy: 0.8696\n",
      "Epoch 723/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3300 - accuracy: 0.9035 - val_loss: 0.3379 - val_accuracy: 0.8804\n",
      "Epoch 724/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3321 - accuracy: 0.8736 - val_loss: 0.3039 - val_accuracy: 0.8913\n",
      "Epoch 725/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.3155 - accuracy: 0.8913 - val_loss: 0.2975 - val_accuracy: 0.8913\n",
      "Epoch 726/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.3088 - accuracy: 0.9008 - val_loss: 0.3111 - val_accuracy: 0.9022\n",
      "Epoch 727/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3211 - accuracy: 0.8995 - val_loss: 0.2995 - val_accuracy: 0.9022\n",
      "Epoch 728/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3308 - accuracy: 0.8818 - val_loss: 0.3039 - val_accuracy: 0.9022\n",
      "Epoch 729/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3197 - accuracy: 0.8940 - val_loss: 0.3042 - val_accuracy: 0.9022\n",
      "Epoch 730/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3222 - accuracy: 0.8927 - val_loss: 0.3216 - val_accuracy: 0.8913\n",
      "Epoch 731/1000\n",
      "736/736 [==============================] - 0s 114us/step - loss: 0.3098 - accuracy: 0.8913 - val_loss: 0.2967 - val_accuracy: 0.9022\n",
      "Epoch 732/1000\n",
      "736/736 [==============================] - 0s 125us/step - loss: 0.3107 - accuracy: 0.8899 - val_loss: 0.2967 - val_accuracy: 0.9022\n",
      "Epoch 733/1000\n",
      "736/736 [==============================] - 0s 121us/step - loss: 0.3153 - accuracy: 0.8927 - val_loss: 0.3152 - val_accuracy: 0.8913\n",
      "Epoch 734/1000\n",
      "736/736 [==============================] - 0s 126us/step - loss: 0.3208 - accuracy: 0.8967 - val_loss: 0.3000 - val_accuracy: 0.9022\n",
      "Epoch 735/1000\n",
      "736/736 [==============================] - 0s 107us/step - loss: 0.3117 - accuracy: 0.8913 - val_loss: 0.3008 - val_accuracy: 0.9022\n",
      "Epoch 736/1000\n",
      "736/736 [==============================] - 0s 110us/step - loss: 0.3238 - accuracy: 0.9049 - val_loss: 0.2999 - val_accuracy: 0.9022\n",
      "Epoch 737/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.3052 - accuracy: 0.8913 - val_loss: 0.3007 - val_accuracy: 0.9022\n",
      "Epoch 738/1000\n",
      "736/736 [==============================] - 0s 108us/step - loss: 0.3133 - accuracy: 0.8954 - val_loss: 0.2962 - val_accuracy: 0.8913\n",
      "Epoch 739/1000\n",
      "736/736 [==============================] - 0s 105us/step - loss: 0.3392 - accuracy: 0.8818 - val_loss: 0.3018 - val_accuracy: 0.9022\n",
      "Epoch 740/1000\n",
      "736/736 [==============================] - 0s 112us/step - loss: 0.3278 - accuracy: 0.8804 - val_loss: 0.2989 - val_accuracy: 0.9022\n",
      "Epoch 741/1000\n",
      "736/736 [==============================] - 0s 111us/step - loss: 0.3436 - accuracy: 0.8859 - val_loss: 0.2992 - val_accuracy: 0.9022\n",
      "Epoch 742/1000\n",
      "736/736 [==============================] - 0s 253us/step - loss: 0.3388 - accuracy: 0.8736 - val_loss: 0.2995 - val_accuracy: 0.9022\n",
      "Epoch 743/1000\n",
      "736/736 [==============================] - 0s 135us/step - loss: 0.3039 - accuracy: 0.9008 - val_loss: 0.2968 - val_accuracy: 0.9022\n",
      "Epoch 744/1000\n",
      "736/736 [==============================] - 0s 125us/step - loss: 0.3156 - accuracy: 0.8981 - val_loss: 0.3051 - val_accuracy: 0.9130\n",
      "Epoch 745/1000\n",
      "736/736 [==============================] - 0s 101us/step - loss: 0.3162 - accuracy: 0.9022 - val_loss: 0.2959 - val_accuracy: 0.9022\n",
      "Epoch 746/1000\n",
      "736/736 [==============================] - 0s 101us/step - loss: 0.3182 - accuracy: 0.8927 - val_loss: 0.2934 - val_accuracy: 0.8913\n",
      "Epoch 747/1000\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.3215 - accuracy: 0.8859 - val_loss: 0.3077 - val_accuracy: 0.9022\n",
      "Epoch 748/1000\n",
      "736/736 [==============================] - 0s 97us/step - loss: 0.3211 - accuracy: 0.8954 - val_loss: 0.2973 - val_accuracy: 0.9022\n",
      "Epoch 749/1000\n",
      "736/736 [==============================] - 0s 106us/step - loss: 0.3237 - accuracy: 0.8913 - val_loss: 0.3294 - val_accuracy: 0.8587\n",
      "Epoch 750/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.3173 - accuracy: 0.8913 - val_loss: 0.3005 - val_accuracy: 0.9022\n",
      "Epoch 751/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3186 - accuracy: 0.8995 - val_loss: 0.3203 - val_accuracy: 0.8913\n",
      "Epoch 752/1000\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.3072 - accuracy: 0.8954 - val_loss: 0.2980 - val_accuracy: 0.9022\n",
      "Epoch 753/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2927 - accuracy: 0.8995 - val_loss: 0.2928 - val_accuracy: 0.8913\n",
      "Epoch 754/1000\n",
      "736/736 [==============================] - 0s 228us/step - loss: 0.3186 - accuracy: 0.8818 - val_loss: 0.3345 - val_accuracy: 0.8587\n",
      "Epoch 755/1000\n",
      "736/736 [==============================] - 0s 120us/step - loss: 0.2945 - accuracy: 0.9035 - val_loss: 0.2955 - val_accuracy: 0.9022\n",
      "Epoch 756/1000\n",
      "736/736 [==============================] - 0s 113us/step - loss: 0.3107 - accuracy: 0.8913 - val_loss: 0.3301 - val_accuracy: 0.8913\n",
      "Epoch 757/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3262 - accuracy: 0.8927 - val_loss: 0.2900 - val_accuracy: 0.8913\n",
      "Epoch 758/1000\n",
      "736/736 [==============================] - 0s 110us/step - loss: 0.2990 - accuracy: 0.9049 - val_loss: 0.3142 - val_accuracy: 0.8913\n",
      "Epoch 759/1000\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.3217 - accuracy: 0.8899 - val_loss: 0.2916 - val_accuracy: 0.8913\n",
      "Epoch 760/1000\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.3046 - accuracy: 0.9008 - val_loss: 0.2905 - val_accuracy: 0.9022\n",
      "Epoch 761/1000\n",
      "736/736 [==============================] - 0s 83us/step - loss: 0.3082 - accuracy: 0.9117 - val_loss: 0.2904 - val_accuracy: 0.9022\n",
      "Epoch 762/1000\n",
      "736/736 [==============================] - 0s 168us/step - loss: 0.3181 - accuracy: 0.8995 - val_loss: 0.3210 - val_accuracy: 0.8804\n",
      "Epoch 763/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.3442 - accuracy: 0.8777 - val_loss: 0.3366 - val_accuracy: 0.8587\n",
      "Epoch 764/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2970 - accuracy: 0.8899 - val_loss: 0.2897 - val_accuracy: 0.9022\n",
      "Epoch 765/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.3084 - accuracy: 0.9035 - val_loss: 0.2897 - val_accuracy: 0.9022\n",
      "Epoch 766/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3166 - accuracy: 0.8954 - val_loss: 0.2984 - val_accuracy: 0.9130\n",
      "Epoch 767/1000\n",
      "736/736 [==============================] - 0s 83us/step - loss: 0.3136 - accuracy: 0.8886 - val_loss: 0.2882 - val_accuracy: 0.9022\n",
      "Epoch 768/1000\n",
      "736/736 [==============================] - 0s 96us/step - loss: 0.3079 - accuracy: 0.8981 - val_loss: 0.2874 - val_accuracy: 0.9022\n",
      "Epoch 769/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.3254 - accuracy: 0.8954 - val_loss: 0.3221 - val_accuracy: 0.8913\n",
      "Epoch 770/1000\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.3173 - accuracy: 0.8899 - val_loss: 0.3153 - val_accuracy: 0.8913\n",
      "Epoch 771/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3063 - accuracy: 0.9144 - val_loss: 0.3034 - val_accuracy: 0.9022\n",
      "Epoch 772/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3132 - accuracy: 0.8954 - val_loss: 0.2914 - val_accuracy: 0.9022\n",
      "Epoch 773/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3124 - accuracy: 0.8954 - val_loss: 0.2899 - val_accuracy: 0.9022\n",
      "Epoch 774/1000\n",
      "736/736 [==============================] - 0s 206us/step - loss: 0.3302 - accuracy: 0.9022 - val_loss: 0.3072 - val_accuracy: 0.8913\n",
      "Epoch 775/1000\n",
      "736/736 [==============================] - 0s 125us/step - loss: 0.3258 - accuracy: 0.8981 - val_loss: 0.2887 - val_accuracy: 0.9022\n",
      "Epoch 776/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.2996 - accuracy: 0.8927 - val_loss: 0.3512 - val_accuracy: 0.8370\n",
      "Epoch 777/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.3100 - accuracy: 0.8940 - val_loss: 0.2862 - val_accuracy: 0.9022\n",
      "Epoch 778/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3019 - accuracy: 0.9035 - val_loss: 0.2914 - val_accuracy: 0.9022\n",
      "Epoch 779/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.3006 - accuracy: 0.9090 - val_loss: 0.2862 - val_accuracy: 0.9022\n",
      "Epoch 780/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 0s 82us/step - loss: 0.3004 - accuracy: 0.9035 - val_loss: 0.2836 - val_accuracy: 0.9022\n",
      "Epoch 781/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3011 - accuracy: 0.8981 - val_loss: 0.2839 - val_accuracy: 0.9022\n",
      "Epoch 782/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2783 - accuracy: 0.9090 - val_loss: 0.2844 - val_accuracy: 0.9022\n",
      "Epoch 783/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2975 - accuracy: 0.9022 - val_loss: 0.2909 - val_accuracy: 0.9022\n",
      "Epoch 784/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2879 - accuracy: 0.9117 - val_loss: 0.2831 - val_accuracy: 0.8913\n",
      "Epoch 785/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3113 - accuracy: 0.8940 - val_loss: 0.3064 - val_accuracy: 0.9022\n",
      "Epoch 786/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3153 - accuracy: 0.8913 - val_loss: 0.2839 - val_accuracy: 0.8913\n",
      "Epoch 787/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3300 - accuracy: 0.9008 - val_loss: 0.2833 - val_accuracy: 0.8913\n",
      "Epoch 788/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3292 - accuracy: 0.8913 - val_loss: 0.3083 - val_accuracy: 0.9022\n",
      "Epoch 789/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3047 - accuracy: 0.8995 - val_loss: 0.2886 - val_accuracy: 0.9022\n",
      "Epoch 790/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3121 - accuracy: 0.8777 - val_loss: 0.3066 - val_accuracy: 0.9022\n",
      "Epoch 791/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3062 - accuracy: 0.9076 - val_loss: 0.2823 - val_accuracy: 0.9022\n",
      "Epoch 792/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2952 - accuracy: 0.9035 - val_loss: 0.2850 - val_accuracy: 0.9022\n",
      "Epoch 793/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3060 - accuracy: 0.9049 - val_loss: 0.3439 - val_accuracy: 0.8696\n",
      "Epoch 794/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3150 - accuracy: 0.9022 - val_loss: 0.2830 - val_accuracy: 0.9022\n",
      "Epoch 795/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3036 - accuracy: 0.8954 - val_loss: 0.2951 - val_accuracy: 0.9130\n",
      "Epoch 796/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2947 - accuracy: 0.9062 - val_loss: 0.2870 - val_accuracy: 0.9022\n",
      "Epoch 797/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2836 - accuracy: 0.9103 - val_loss: 0.2833 - val_accuracy: 0.9022\n",
      "Epoch 798/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3011 - accuracy: 0.8940 - val_loss: 0.2914 - val_accuracy: 0.9130\n",
      "Epoch 799/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2983 - accuracy: 0.9049 - val_loss: 0.3177 - val_accuracy: 0.8913\n",
      "Epoch 800/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3025 - accuracy: 0.9022 - val_loss: 0.3390 - val_accuracy: 0.8478\n",
      "Epoch 801/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.3300 - accuracy: 0.8927 - val_loss: 0.2806 - val_accuracy: 0.8913\n",
      "Epoch 802/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.2992 - accuracy: 0.9076 - val_loss: 0.2884 - val_accuracy: 0.9022\n",
      "Epoch 803/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2965 - accuracy: 0.9035 - val_loss: 0.3060 - val_accuracy: 0.9130\n",
      "Epoch 804/1000\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.84 - 0s 75us/step - loss: 0.2990 - accuracy: 0.8927 - val_loss: 0.2806 - val_accuracy: 0.9022\n",
      "Epoch 805/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2956 - accuracy: 0.9103 - val_loss: 0.2960 - val_accuracy: 0.9022\n",
      "Epoch 806/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.3081 - accuracy: 0.8899 - val_loss: 0.2804 - val_accuracy: 0.9022\n",
      "Epoch 807/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2866 - accuracy: 0.9144 - val_loss: 0.2816 - val_accuracy: 0.9022\n",
      "Epoch 808/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3002 - accuracy: 0.9008 - val_loss: 0.2781 - val_accuracy: 0.9022\n",
      "Epoch 809/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.2823 - accuracy: 0.9049 - val_loss: 0.2892 - val_accuracy: 0.9130\n",
      "Epoch 810/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.3205 - accuracy: 0.9076 - val_loss: 0.2818 - val_accuracy: 0.9022\n",
      "Epoch 811/1000\n",
      "736/736 [==============================] - 0s 115us/step - loss: 0.2994 - accuracy: 0.9008 - val_loss: 0.2773 - val_accuracy: 0.9022\n",
      "Epoch 812/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.3031 - accuracy: 0.8954 - val_loss: 0.2928 - val_accuracy: 0.9022\n",
      "Epoch 813/1000\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.92 - 0s 92us/step - loss: 0.3014 - accuracy: 0.9158 - val_loss: 0.2881 - val_accuracy: 0.9022\n",
      "Epoch 814/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3014 - accuracy: 0.9022 - val_loss: 0.3099 - val_accuracy: 0.9022\n",
      "Epoch 815/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.3114 - accuracy: 0.8927 - val_loss: 0.2814 - val_accuracy: 0.8913\n",
      "Epoch 816/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2867 - accuracy: 0.9008 - val_loss: 0.3390 - val_accuracy: 0.8370\n",
      "Epoch 817/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2917 - accuracy: 0.9103 - val_loss: 0.2788 - val_accuracy: 0.9022\n",
      "Epoch 818/1000\n",
      "736/736 [==============================] - 0s 86us/step - loss: 0.2819 - accuracy: 0.9049 - val_loss: 0.2782 - val_accuracy: 0.9022\n",
      "Epoch 819/1000\n",
      "736/736 [==============================] - 0s 78us/step - loss: 0.3117 - accuracy: 0.8995 - val_loss: 0.2765 - val_accuracy: 0.9022\n",
      "Epoch 820/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.3108 - accuracy: 0.9076 - val_loss: 0.2856 - val_accuracy: 0.9130\n",
      "Epoch 821/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2993 - accuracy: 0.8927 - val_loss: 0.3268 - val_accuracy: 0.8696\n",
      "Epoch 822/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3014 - accuracy: 0.9103 - val_loss: 0.2796 - val_accuracy: 0.9022\n",
      "Epoch 823/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3160 - accuracy: 0.9076 - val_loss: 0.2753 - val_accuracy: 0.9022\n",
      "Epoch 824/1000\n",
      "736/736 [==============================] - 0s 107us/step - loss: 0.2943 - accuracy: 0.9076 - val_loss: 0.2762 - val_accuracy: 0.9022\n",
      "Epoch 825/1000\n",
      "736/736 [==============================] - 0s 124us/step - loss: 0.2936 - accuracy: 0.8967 - val_loss: 0.2843 - val_accuracy: 0.9130\n",
      "Epoch 826/1000\n",
      "736/736 [==============================] - 0s 111us/step - loss: 0.3203 - accuracy: 0.8954 - val_loss: 0.2890 - val_accuracy: 0.9130\n",
      "Epoch 827/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.2927 - accuracy: 0.9008 - val_loss: 0.2811 - val_accuracy: 0.9022\n",
      "Epoch 828/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3202 - accuracy: 0.9022 - val_loss: 0.3025 - val_accuracy: 0.9022\n",
      "Epoch 829/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.3026 - accuracy: 0.9062 - val_loss: 0.2739 - val_accuracy: 0.9022\n",
      "Epoch 830/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.2976 - accuracy: 0.9062 - val_loss: 0.2768 - val_accuracy: 0.9022\n",
      "Epoch 831/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.2987 - accuracy: 0.9035 - val_loss: 0.2774 - val_accuracy: 0.9022\n",
      "Epoch 832/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2986 - accuracy: 0.9076 - val_loss: 0.2839 - val_accuracy: 0.9022\n",
      "Epoch 833/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.2834 - accuracy: 0.9049 - val_loss: 0.2863 - val_accuracy: 0.9130\n",
      "Epoch 834/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2851 - accuracy: 0.9076 - val_loss: 0.2821 - val_accuracy: 0.9022\n",
      "Epoch 835/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.3153 - accuracy: 0.9008 - val_loss: 0.2848 - val_accuracy: 0.9130\n",
      "Epoch 836/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2963 - accuracy: 0.9062 - val_loss: 0.3124 - val_accuracy: 0.9022\n",
      "Epoch 837/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.3005 - accuracy: 0.9035 - val_loss: 0.2758 - val_accuracy: 0.9022\n",
      "Epoch 838/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.2870 - accuracy: 0.9144 - val_loss: 0.2855 - val_accuracy: 0.9022\n",
      "Epoch 839/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.3127 - accuracy: 0.8981 - val_loss: 0.2774 - val_accuracy: 0.9022\n",
      "Epoch 840/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.3112 - accuracy: 0.9022 - val_loss: 0.2946 - val_accuracy: 0.9022\n",
      "Epoch 841/1000\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.2967 - accuracy: 0.9239 - val_loss: 0.2700 - val_accuracy: 0.9022\n",
      "Epoch 842/1000\n",
      "736/736 [==============================] - 0s 114us/step - loss: 0.2871 - accuracy: 0.9198 - val_loss: 0.2971 - val_accuracy: 0.9130\n",
      "Epoch 843/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.2908 - accuracy: 0.9049 - val_loss: 0.2848 - val_accuracy: 0.9022\n",
      "Epoch 844/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3011 - accuracy: 0.9008 - val_loss: 0.2746 - val_accuracy: 0.9022\n",
      "Epoch 845/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2935 - accuracy: 0.9090 - val_loss: 0.2827 - val_accuracy: 0.9022\n",
      "Epoch 846/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.3103 - accuracy: 0.8981 - val_loss: 0.2750 - val_accuracy: 0.9022\n",
      "Epoch 847/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.2970 - accuracy: 0.8981 - val_loss: 0.2889 - val_accuracy: 0.9130\n",
      "Epoch 848/1000\n",
      "736/736 [==============================] - 0s 115us/step - loss: 0.2947 - accuracy: 0.9049 - val_loss: 0.2714 - val_accuracy: 0.9022\n",
      "Epoch 849/1000\n",
      "736/736 [==============================] - 0s 80us/step - loss: 0.2696 - accuracy: 0.9117 - val_loss: 0.2735 - val_accuracy: 0.9022\n",
      "Epoch 850/1000\n",
      "736/736 [==============================] - 0s 85us/step - loss: 0.2839 - accuracy: 0.9090 - val_loss: 0.2841 - val_accuracy: 0.9130\n",
      "Epoch 851/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2951 - accuracy: 0.9090 - val_loss: 0.3232 - val_accuracy: 0.9022\n",
      "Epoch 852/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3044 - accuracy: 0.9130 - val_loss: 0.2793 - val_accuracy: 0.9130\n",
      "Epoch 853/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2909 - accuracy: 0.9022 - val_loss: 0.2688 - val_accuracy: 0.9022\n",
      "Epoch 854/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3024 - accuracy: 0.8913 - val_loss: 0.2747 - val_accuracy: 0.9022\n",
      "Epoch 855/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2889 - accuracy: 0.9130 - val_loss: 0.3071 - val_accuracy: 0.9022\n",
      "Epoch 856/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2915 - accuracy: 0.9049 - val_loss: 0.2716 - val_accuracy: 0.9022\n",
      "Epoch 857/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2996 - accuracy: 0.9062 - val_loss: 0.2825 - val_accuracy: 0.9022\n",
      "Epoch 858/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.3025 - accuracy: 0.9062 - val_loss: 0.3054 - val_accuracy: 0.9022\n",
      "Epoch 859/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2922 - accuracy: 0.9144 - val_loss: 0.2702 - val_accuracy: 0.9022\n",
      "Epoch 860/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3083 - accuracy: 0.9022 - val_loss: 0.2912 - val_accuracy: 0.9130\n",
      "Epoch 861/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2796 - accuracy: 0.9130 - val_loss: 0.2700 - val_accuracy: 0.9022\n",
      "Epoch 862/1000\n",
      "736/736 [==============================] - 0s 120us/step - loss: 0.2666 - accuracy: 0.9158 - val_loss: 0.2684 - val_accuracy: 0.9022\n",
      "Epoch 863/1000\n",
      "736/736 [==============================] - 0s 110us/step - loss: 0.3118 - accuracy: 0.8899 - val_loss: 0.2779 - val_accuracy: 0.9130\n",
      "Epoch 864/1000\n",
      "736/736 [==============================] - 0s 102us/step - loss: 0.2901 - accuracy: 0.9144 - val_loss: 0.2773 - val_accuracy: 0.9130\n",
      "Epoch 865/1000\n",
      "736/736 [==============================] - 0s 129us/step - loss: 0.2839 - accuracy: 0.9035 - val_loss: 0.2771 - val_accuracy: 0.9022\n",
      "Epoch 866/1000\n",
      "736/736 [==============================] - 0s 120us/step - loss: 0.2916 - accuracy: 0.9158 - val_loss: 0.2763 - val_accuracy: 0.9130\n",
      "Epoch 867/1000\n",
      "736/736 [==============================] - 0s 59us/step - loss: 0.2859 - accuracy: 0.9049 - val_loss: 0.2696 - val_accuracy: 0.9022\n",
      "Epoch 868/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2917 - accuracy: 0.9212 - val_loss: 0.2739 - val_accuracy: 0.9022\n",
      "Epoch 869/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.3051 - accuracy: 0.9076 - val_loss: 0.2684 - val_accuracy: 0.9022\n",
      "Epoch 870/1000\n",
      "736/736 [==============================] - 0s 92us/step - loss: 0.2713 - accuracy: 0.9226 - val_loss: 0.2695 - val_accuracy: 0.9022\n",
      "Epoch 871/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2898 - accuracy: 0.9090 - val_loss: 0.2706 - val_accuracy: 0.9022\n",
      "Epoch 872/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2890 - accuracy: 0.9144 - val_loss: 0.2677 - val_accuracy: 0.9022\n",
      "Epoch 873/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2964 - accuracy: 0.9103 - val_loss: 0.2728 - val_accuracy: 0.9022\n",
      "Epoch 874/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2990 - accuracy: 0.9035 - val_loss: 0.3003 - val_accuracy: 0.8913\n",
      "Epoch 875/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.3099 - accuracy: 0.8967 - val_loss: 0.2682 - val_accuracy: 0.9022\n",
      "Epoch 876/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2766 - accuracy: 0.9117 - val_loss: 0.2679 - val_accuracy: 0.9022\n",
      "Epoch 877/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2862 - accuracy: 0.9008 - val_loss: 0.2754 - val_accuracy: 0.9022\n",
      "Epoch 878/1000\n",
      "736/736 [==============================] - 0s 103us/step - loss: 0.3020 - accuracy: 0.8967 - val_loss: 0.2719 - val_accuracy: 0.9022\n",
      "Epoch 879/1000\n",
      "736/736 [==============================] - 0s 87us/step - loss: 0.3003 - accuracy: 0.9103 - val_loss: 0.2760 - val_accuracy: 0.9022\n",
      "Epoch 880/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.2892 - accuracy: 0.9090 - val_loss: 0.2671 - val_accuracy: 0.9022\n",
      "Epoch 881/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.3000 - accuracy: 0.9090 - val_loss: 0.2768 - val_accuracy: 0.9022\n",
      "Epoch 882/1000\n",
      "736/736 [==============================] - 0s 70us/step - loss: 0.2966 - accuracy: 0.9171 - val_loss: 0.3029 - val_accuracy: 0.9130\n",
      "Epoch 883/1000\n",
      "736/736 [==============================] - 0s 77us/step - loss: 0.2951 - accuracy: 0.9130 - val_loss: 0.2679 - val_accuracy: 0.9022\n",
      "Epoch 884/1000\n",
      "736/736 [==============================] - 0s 57us/step - loss: 0.2859 - accuracy: 0.9103 - val_loss: 0.3278 - val_accuracy: 0.8804\n",
      "Epoch 885/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.2934 - accuracy: 0.9022 - val_loss: 0.2779 - val_accuracy: 0.9130\n",
      "Epoch 886/1000\n",
      "736/736 [==============================] - 0s 58us/step - loss: 0.2745 - accuracy: 0.9117 - val_loss: 0.2722 - val_accuracy: 0.9022\n",
      "Epoch 887/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.2893 - accuracy: 0.9266 - val_loss: 0.2685 - val_accuracy: 0.9022\n",
      "Epoch 888/1000\n",
      "736/736 [==============================] - 0s 52us/step - loss: 0.2925 - accuracy: 0.9103 - val_loss: 0.2759 - val_accuracy: 0.9130\n",
      "Epoch 889/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2791 - accuracy: 0.9022 - val_loss: 0.2688 - val_accuracy: 0.9022\n",
      "Epoch 890/1000\n",
      "736/736 [==============================] - 0s 73us/step - loss: 0.3070 - accuracy: 0.9022 - val_loss: 0.2665 - val_accuracy: 0.9022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/1000\n",
      "736/736 [==============================] - 0s 66us/step - loss: 0.2935 - accuracy: 0.9049 - val_loss: 0.2755 - val_accuracy: 0.9130\n",
      "Epoch 892/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2879 - accuracy: 0.9117 - val_loss: 0.2726 - val_accuracy: 0.9022\n",
      "Epoch 893/1000\n",
      "736/736 [==============================] - 0s 62us/step - loss: 0.3157 - accuracy: 0.9049 - val_loss: 0.2637 - val_accuracy: 0.9022\n",
      "Epoch 894/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2729 - accuracy: 0.9090 - val_loss: 0.3609 - val_accuracy: 0.8043\n",
      "Epoch 895/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.2767 - accuracy: 0.9130 - val_loss: 0.2744 - val_accuracy: 0.9130\n",
      "Epoch 896/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.2874 - accuracy: 0.9062 - val_loss: 0.2805 - val_accuracy: 0.9130\n",
      "Epoch 897/1000\n",
      "736/736 [==============================] - 0s 63us/step - loss: 0.2899 - accuracy: 0.9144 - val_loss: 0.2680 - val_accuracy: 0.9130\n",
      "Epoch 898/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.2742 - accuracy: 0.9185 - val_loss: 0.2641 - val_accuracy: 0.9022\n",
      "Epoch 899/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.2822 - accuracy: 0.9035 - val_loss: 0.2707 - val_accuracy: 0.9130\n",
      "Epoch 900/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2759 - accuracy: 0.9253 - val_loss: 0.2768 - val_accuracy: 0.9130\n",
      "Epoch 901/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.2798 - accuracy: 0.9103 - val_loss: 0.2640 - val_accuracy: 0.9022\n",
      "Epoch 902/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.2890 - accuracy: 0.9117 - val_loss: 0.2660 - val_accuracy: 0.9022\n",
      "Epoch 903/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.3058 - accuracy: 0.9049 - val_loss: 0.2852 - val_accuracy: 0.9130\n",
      "Epoch 904/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.3022 - accuracy: 0.9144 - val_loss: 0.2650 - val_accuracy: 0.9022\n",
      "Epoch 905/1000\n",
      "736/736 [==============================] - 0s 60us/step - loss: 0.2806 - accuracy: 0.9035 - val_loss: 0.2724 - val_accuracy: 0.9130\n",
      "Epoch 906/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2746 - accuracy: 0.9198 - val_loss: 0.2674 - val_accuracy: 0.9022\n",
      "Epoch 907/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2835 - accuracy: 0.9076 - val_loss: 0.2643 - val_accuracy: 0.9022\n",
      "Epoch 908/1000\n",
      "736/736 [==============================] - 0s 57us/step - loss: 0.2719 - accuracy: 0.9212 - val_loss: 0.3005 - val_accuracy: 0.8913\n",
      "Epoch 909/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2866 - accuracy: 0.9090 - val_loss: 0.3460 - val_accuracy: 0.8152\n",
      "Epoch 910/1000\n",
      "736/736 [==============================] - 0s 71us/step - loss: 0.2834 - accuracy: 0.9158 - val_loss: 0.2709 - val_accuracy: 0.9130\n",
      "Epoch 911/1000\n",
      "736/736 [==============================] - 0s 65us/step - loss: 0.2945 - accuracy: 0.9158 - val_loss: 0.2643 - val_accuracy: 0.9022\n",
      "Epoch 912/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.3127 - accuracy: 0.9062 - val_loss: 0.2900 - val_accuracy: 0.9130\n",
      "Epoch 913/1000\n",
      "736/736 [==============================] - 0s 56us/step - loss: 0.2830 - accuracy: 0.9103 - val_loss: 0.2744 - val_accuracy: 0.9130\n",
      "Epoch 914/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2883 - accuracy: 0.9049 - val_loss: 0.2683 - val_accuracy: 0.9130\n",
      "Epoch 915/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2611 - accuracy: 0.9239 - val_loss: 0.2637 - val_accuracy: 0.9022\n",
      "Epoch 916/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.2878 - accuracy: 0.9103 - val_loss: 0.2652 - val_accuracy: 0.9022\n",
      "Epoch 917/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2792 - accuracy: 0.9103 - val_loss: 0.2690 - val_accuracy: 0.9130\n",
      "Epoch 918/1000\n",
      "736/736 [==============================] - 0s 72us/step - loss: 0.3056 - accuracy: 0.9103 - val_loss: 0.2866 - val_accuracy: 0.9130\n",
      "Epoch 919/1000\n",
      "736/736 [==============================] - 0s 64us/step - loss: 0.3045 - accuracy: 0.8981 - val_loss: 0.2631 - val_accuracy: 0.9022\n",
      "Epoch 920/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2736 - accuracy: 0.9226 - val_loss: 0.2614 - val_accuracy: 0.9022\n",
      "Epoch 921/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2903 - accuracy: 0.9117 - val_loss: 0.2703 - val_accuracy: 0.9130\n",
      "Epoch 922/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2913 - accuracy: 0.9103 - val_loss: 0.2784 - val_accuracy: 0.9130\n",
      "Epoch 923/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2955 - accuracy: 0.9090 - val_loss: 0.2975 - val_accuracy: 0.8913\n",
      "Epoch 924/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2939 - accuracy: 0.9103 - val_loss: 0.2647 - val_accuracy: 0.9239\n",
      "Epoch 925/1000\n",
      "736/736 [==============================] - 0s 98us/step - loss: 0.2860 - accuracy: 0.9144 - val_loss: 0.2604 - val_accuracy: 0.9022\n",
      "Epoch 926/1000\n",
      "736/736 [==============================] - 0s 110us/step - loss: 0.2858 - accuracy: 0.9103 - val_loss: 0.2741 - val_accuracy: 0.9130\n",
      "Epoch 927/1000\n",
      "736/736 [==============================] - 0s 69us/step - loss: 0.3034 - accuracy: 0.9049 - val_loss: 0.3047 - val_accuracy: 0.9130\n",
      "Epoch 928/1000\n",
      "736/736 [==============================] - 0s 94us/step - loss: 0.3120 - accuracy: 0.8940 - val_loss: 0.2738 - val_accuracy: 0.9130\n",
      "Epoch 929/1000\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.2985 - accuracy: 0.9062 - val_loss: 0.2610 - val_accuracy: 0.9022\n",
      "Epoch 930/1000\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.2855 - accuracy: 0.9090 - val_loss: 0.2634 - val_accuracy: 0.9130\n",
      "Epoch 931/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.2924 - accuracy: 0.9117 - val_loss: 0.2665 - val_accuracy: 0.9239\n",
      "Epoch 932/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2881 - accuracy: 0.9117 - val_loss: 0.2641 - val_accuracy: 0.9022\n",
      "Epoch 933/1000\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.2700 - accuracy: 0.9198 - val_loss: 0.3184 - val_accuracy: 0.8696\n",
      "Epoch 934/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.2712 - accuracy: 0.9062 - val_loss: 0.2811 - val_accuracy: 0.9130\n",
      "Epoch 935/1000\n",
      "736/736 [==============================] - 0s 90us/step - loss: 0.2993 - accuracy: 0.9022 - val_loss: 0.3039 - val_accuracy: 0.8804\n",
      "Epoch 936/1000\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.2788 - accuracy: 0.9103 - val_loss: 0.2600 - val_accuracy: 0.9022\n",
      "Epoch 937/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.2723 - accuracy: 0.9198 - val_loss: 0.2784 - val_accuracy: 0.9130\n",
      "Epoch 938/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.2882 - accuracy: 0.9198 - val_loss: 0.2598 - val_accuracy: 0.9022\n",
      "Epoch 939/1000\n",
      "736/736 [==============================] - 0s 95us/step - loss: 0.2974 - accuracy: 0.9117 - val_loss: 0.2862 - val_accuracy: 0.9130\n",
      "Epoch 940/1000\n",
      "736/736 [==============================] - 0s 88us/step - loss: 0.2890 - accuracy: 0.9103 - val_loss: 0.2610 - val_accuracy: 0.9022\n",
      "Epoch 941/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2817 - accuracy: 0.9185 - val_loss: 0.2578 - val_accuracy: 0.9022\n",
      "Epoch 942/1000\n",
      "736/736 [==============================] - 0s 102us/step - loss: 0.3048 - accuracy: 0.9144 - val_loss: 0.2699 - val_accuracy: 0.9022\n",
      "Epoch 943/1000\n",
      "736/736 [==============================] - 0s 102us/step - loss: 0.2941 - accuracy: 0.9130 - val_loss: 0.2628 - val_accuracy: 0.9239\n",
      "Epoch 944/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.2689 - accuracy: 0.9090 - val_loss: 0.2738 - val_accuracy: 0.9130\n",
      "Epoch 945/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.2927 - accuracy: 0.9049 - val_loss: 0.2585 - val_accuracy: 0.9022\n",
      "Epoch 946/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.2922 - accuracy: 0.9022 - val_loss: 0.2669 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/1000\n",
      "736/736 [==============================] - 0s 109us/step - loss: 0.2908 - accuracy: 0.9130 - val_loss: 0.2606 - val_accuracy: 0.9022\n",
      "Epoch 948/1000\n",
      "736/736 [==============================] - 0s 240us/step - loss: 0.2997 - accuracy: 0.9090 - val_loss: 0.2668 - val_accuracy: 0.9239\n",
      "Epoch 949/1000\n",
      "736/736 [==============================] - 0s 417us/step - loss: 0.2779 - accuracy: 0.9090 - val_loss: 0.2614 - val_accuracy: 0.9239\n",
      "Epoch 950/1000\n",
      "736/736 [==============================] - 0s 229us/step - loss: 0.2809 - accuracy: 0.9062 - val_loss: 0.2596 - val_accuracy: 0.9022\n",
      "Epoch 951/1000\n",
      "736/736 [==============================] - 0s 177us/step - loss: 0.2789 - accuracy: 0.9130 - val_loss: 0.2914 - val_accuracy: 0.9130\n",
      "Epoch 952/1000\n",
      "736/736 [==============================] - 0s 156us/step - loss: 0.2977 - accuracy: 0.9062 - val_loss: 0.2998 - val_accuracy: 0.9130\n",
      "Epoch 953/1000\n",
      "736/736 [==============================] - 0s 149us/step - loss: 0.2922 - accuracy: 0.9117 - val_loss: 0.3294 - val_accuracy: 0.8804\n",
      "Epoch 954/1000\n",
      "736/736 [==============================] - 0s 163us/step - loss: 0.2814 - accuracy: 0.9062 - val_loss: 0.2758 - val_accuracy: 0.9130\n",
      "Epoch 955/1000\n",
      "736/736 [==============================] - 0s 122us/step - loss: 0.2808 - accuracy: 0.9103 - val_loss: 0.3055 - val_accuracy: 0.8804\n",
      "Epoch 956/1000\n",
      "736/736 [==============================] - 0s 147us/step - loss: 0.2719 - accuracy: 0.9130 - val_loss: 0.2561 - val_accuracy: 0.9022\n",
      "Epoch 957/1000\n",
      "736/736 [==============================] - 0s 152us/step - loss: 0.2812 - accuracy: 0.9198 - val_loss: 0.2646 - val_accuracy: 0.9239\n",
      "Epoch 958/1000\n",
      "736/736 [==============================] - 0s 135us/step - loss: 0.2745 - accuracy: 0.9185 - val_loss: 0.2929 - val_accuracy: 0.8913\n",
      "Epoch 959/1000\n",
      "736/736 [==============================] - 0s 99us/step - loss: 0.2681 - accuracy: 0.9293 - val_loss: 0.2582 - val_accuracy: 0.9022\n",
      "Epoch 960/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2746 - accuracy: 0.9198 - val_loss: 0.2688 - val_accuracy: 0.9130\n",
      "Epoch 961/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2855 - accuracy: 0.9022 - val_loss: 0.2616 - val_accuracy: 0.9239\n",
      "Epoch 962/1000\n",
      "736/736 [==============================] - 0s 67us/step - loss: 0.2556 - accuracy: 0.9266 - val_loss: 0.2567 - val_accuracy: 0.9022\n",
      "Epoch 963/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.2931 - accuracy: 0.9198 - val_loss: 0.2608 - val_accuracy: 0.9130\n",
      "Epoch 964/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2893 - accuracy: 0.9130 - val_loss: 0.2904 - val_accuracy: 0.9130\n",
      "Epoch 965/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.3015 - accuracy: 0.9198 - val_loss: 0.3002 - val_accuracy: 0.9130\n",
      "Epoch 966/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2554 - accuracy: 0.9239 - val_loss: 0.2549 - val_accuracy: 0.9022\n",
      "Epoch 967/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2818 - accuracy: 0.9103 - val_loss: 0.2596 - val_accuracy: 0.9239\n",
      "Epoch 968/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2910 - accuracy: 0.9035 - val_loss: 0.2712 - val_accuracy: 0.9130\n",
      "Epoch 969/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2874 - accuracy: 0.9158 - val_loss: 0.4409 - val_accuracy: 0.7935\n",
      "Epoch 970/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2882 - accuracy: 0.9076 - val_loss: 0.2841 - val_accuracy: 0.9130\n",
      "Epoch 971/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.2846 - accuracy: 0.9198 - val_loss: 0.2719 - val_accuracy: 0.9130\n",
      "Epoch 972/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2776 - accuracy: 0.9158 - val_loss: 0.2639 - val_accuracy: 0.9239\n",
      "Epoch 973/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2777 - accuracy: 0.9103 - val_loss: 0.2570 - val_accuracy: 0.9130\n",
      "Epoch 974/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.2858 - accuracy: 0.9226 - val_loss: 0.2755 - val_accuracy: 0.9130\n",
      "Epoch 975/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2621 - accuracy: 0.9144 - val_loss: 0.2564 - val_accuracy: 0.9022\n",
      "Epoch 976/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2696 - accuracy: 0.9035 - val_loss: 0.2616 - val_accuracy: 0.9239\n",
      "Epoch 977/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.2630 - accuracy: 0.9117 - val_loss: 0.2806 - val_accuracy: 0.9130\n",
      "Epoch 978/1000\n",
      "736/736 [==============================] - 0s 81us/step - loss: 0.2761 - accuracy: 0.9117 - val_loss: 0.3939 - val_accuracy: 0.8043\n",
      "Epoch 979/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2819 - accuracy: 0.9198 - val_loss: 0.2549 - val_accuracy: 0.9022\n",
      "Epoch 980/1000\n",
      "736/736 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.90 - 0s 74us/step - loss: 0.2763 - accuracy: 0.9090 - val_loss: 0.2564 - val_accuracy: 0.9022\n",
      "Epoch 981/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2769 - accuracy: 0.9253 - val_loss: 0.2575 - val_accuracy: 0.9239\n",
      "Epoch 982/1000\n",
      "736/736 [==============================] - 0s 74us/step - loss: 0.2701 - accuracy: 0.9198 - val_loss: 0.2591 - val_accuracy: 0.9022\n",
      "Epoch 983/1000\n",
      "736/736 [==============================] - 0s 75us/step - loss: 0.2732 - accuracy: 0.9253 - val_loss: 0.2605 - val_accuracy: 0.9130\n",
      "Epoch 984/1000\n",
      "736/736 [==============================] - 0s 61us/step - loss: 0.2800 - accuracy: 0.9062 - val_loss: 0.2807 - val_accuracy: 0.9130\n",
      "Epoch 985/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2933 - accuracy: 0.9171 - val_loss: 0.2820 - val_accuracy: 0.9239\n",
      "Epoch 986/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2796 - accuracy: 0.9266 - val_loss: 0.2576 - val_accuracy: 0.9239\n",
      "Epoch 987/1000\n",
      "736/736 [==============================] - 0s 55us/step - loss: 0.2796 - accuracy: 0.9144 - val_loss: 0.2597 - val_accuracy: 0.9022\n",
      "Epoch 988/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2778 - accuracy: 0.9280 - val_loss: 0.2543 - val_accuracy: 0.9022\n",
      "Epoch 989/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2846 - accuracy: 0.9198 - val_loss: 0.2689 - val_accuracy: 0.9239\n",
      "Epoch 990/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2789 - accuracy: 0.9130 - val_loss: 0.3104 - val_accuracy: 0.8804\n",
      "Epoch 991/1000\n",
      "736/736 [==============================] - 0s 76us/step - loss: 0.2807 - accuracy: 0.9212 - val_loss: 0.2797 - val_accuracy: 0.9239\n",
      "Epoch 992/1000\n",
      "736/736 [==============================] - 0s 56us/step - loss: 0.2737 - accuracy: 0.9185 - val_loss: 0.2612 - val_accuracy: 0.9022\n",
      "Epoch 993/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2618 - accuracy: 0.9198 - val_loss: 0.2528 - val_accuracy: 0.9022\n",
      "Epoch 994/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2704 - accuracy: 0.9185 - val_loss: 0.2654 - val_accuracy: 0.9130\n",
      "Epoch 995/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2699 - accuracy: 0.9185 - val_loss: 0.2578 - val_accuracy: 0.9239\n",
      "Epoch 996/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2828 - accuracy: 0.9185 - val_loss: 0.2522 - val_accuracy: 0.9022\n",
      "Epoch 997/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2652 - accuracy: 0.9239 - val_loss: 0.2673 - val_accuracy: 0.9130\n",
      "Epoch 998/1000\n",
      "736/736 [==============================] - 0s 68us/step - loss: 0.2741 - accuracy: 0.9266 - val_loss: 0.2538 - val_accuracy: 0.9239\n",
      "Epoch 999/1000\n",
      "736/736 [==============================] - 0s 82us/step - loss: 0.2777 - accuracy: 0.9130 - val_loss: 0.2555 - val_accuracy: 0.9022\n",
      "Epoch 1000/1000\n",
      "736/736 [==============================] - 0s 54us/step - loss: 0.2752 - accuracy: 0.9253 - val_loss: 0.2666 - val_accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "          batch_size=32, epochs=1000,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 76us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.945652186870575"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3xUVfbAv2cmFUgCJPTQmzRBiiiCSBHB3gV1VSzort3VXXVdZdddy66ra1v92cu62LErKvZOVaRJkRJqCB0Skpm5vz/em5k3k5nMpEzanO/nE+a9++67774Muefec+45R4wxKIqiKMmLq647oCiKotQtKggURVGSHBUEiqIoSY4KAkVRlCRHBYGiKEqSo4JAURQlyVFBoCQFItJFRIyIpMRR9wIR+ao2+qUo9QEVBEq9Q0TWiEipiOSFlS+0B/MuddMzRWmcqCBQ6iu/AlP8JyIyAMisu+7UD+JZ0ShKZVFBoNRXngfOc5yfDzznrCAiOSLynIgUishaEblFRFz2NbeI3CMi20RkNXBchHufFJFNIrJBRP4mIu54OiYir4jIZhHZJSJfiEg/x7VMEfmX3Z9dIvKViGTa10aKyDcislNE1ovIBXb5ZyJysaONENWUvQq6XERWACvssvvtNnaLyDwRGeWo7xaRm0VklYjssa93FJGHReRfYe/ytohcE897K40XFQRKfeU7IFtE+tgD9FnAf8PqPAjkAN2A0ViCY6p97RLgeOAQYChweti9zwIeoIddZwJwMfHxPtATaA3MB15wXLsHGAKMAFoCfwB8ItLJvu9BoBUwCFgY5/MATgaGA33t8zl2Gy2B/wGviEiGfe06rNXUsUA2cCGw337nKQ5hmQeMA2ZUoh9KY8QYoz/6U69+gDXAeOAW4E5gIvARkAIYoAvgBg4AfR33XQp8Zh9/AlzmuDbBvjcFaGPfm+m4PgX41D6+APgqzr42t9vNwZpYFQMDI9S7CZgZpY3PgIsd5yHPt9sfG6MfO/zPBZYDJ0WptxQ42j6+Anivrr9v/an7H9U3KvWZ54EvgK6EqYWAPCANWOsoWwt0sI/bA+vDrvnpDKQCm0TEX+YKqx8Re3Xyd+AMrJm9z9GfdCADWBXh1o5RyuMlpG8i8nusFUx7LEGRbfch1rOeBc7FEqznAvdXo09KI0FVQ0q9xRizFstofCzwetjlbUAZ1qDupxOwwT7ehDUgOq/5WY+1IsgzxjS3f7KNMf2IzdnASVgrlhys1QmA2H0qAbpHuG99lHKAfUATx3nbCHUCYYJte8AfgTOBFsaY5sAuuw+xnvVf4CQRGQj0Ad6IUk9JIlQQKPWdi7DUIvuchcYYL/Ay8HcRyRKRzli6cb8d4WXgKhHJF5EWwI2OezcBHwL/EpFsEXGJSHcRGR1Hf7KwhEgR1uB9h6NdH/AUcK+ItLeNtoeLSDqWHWG8iJwpIikikisig+xbFwKnikgTEelhv3OsPniAQiBFRG7FWhH4eQK4XUR6isXBIpJr97EAy77wPPCaMaY4jndWGjkqCJR6jTFmlTFmbpTLV2LNplcDX2EZTZ+yrz0OzAJ+xDLohq8ozsNSLS3B0q+/CrSLo0vPYamZNtj3fhd2/XpgEdZgux24G3AZY9ZhrWx+b5cvBAba99wHlAJbsFQ3L1Axs7AMz7/YfSkhVHV0L5Yg/BDYDTxJ6NbbZ4EBWMJAURBjNDGNoiQTInIk1sqpi72KUZIcXREoShIhIqnA1cATKgQUPyoIFCVJEJE+wE4sFdi/67g7Sj1CVUOKoihJjq4IFEVRkpwG51CWl5dnunTpUtfdUBRFaVDMmzdvmzGmVaRrDU4QdOnShblzo+0mVBRFUSIhImujXVPVkKIoSpKjgkBRFCXJUUGgKIqS5DQ4G0EkysrKKCgooKSkpK67UmtkZGSQn59PampqXXdFUZQGTqMQBAUFBWRlZdGlSxccYYUbLcYYioqKKCgooGvXrnXdHUVRGjiNQjVUUlJCbm5uUggBABEhNzc3qVZAiqIkjkYhCICkEQJ+ku19FUVJHI1GECiKojQU1mzbx+e/FNZ1NwKoIKgBioqKGDRoEIMGDaJt27Z06NAhcF5aWhpXG1OnTmX58uUJ7qmiKJVhT0kZv2zZU+Ptjrv3c85/6gfWFe2PeN3j9XH8g1/yx1d/AmDzrhLWb49ctyZoFMbiuiY3N5eFCxcCMH36dJo1a8b1118fUsefJNrliix7n3766YT3U1GSFY/Xx/4yL9kZldtld/5TPzB/3U5+vfNYRIRvVm3ju1VFXDehd6DOnpIyMlPdpLhdULwDMlvA/u3Wpwj4vHBgDxgfiAsym9PUtweDizH//JgFNxxGdk4OeA6A8XLXh6t4/ts15LCPTze44YSuTLrzHYpJ59/njmBi/0iZTKuHCoIEsnLlSk4++WRGjhzJ999/zzvvvMNf/vIX5s+fT3FxMWeddRa33norACNHjuShhx6if//+5OXlcdlll/H+++/TpEkT3nzzTVq3bl3Hb6MoDZebXl/EK/MKWH3Hsbhcke1r368uYl+ph7EHtQmUzV+3E4BSr4/0FDdnP/49QEAQGGMYMP1DDuvWkovbr2P83Glw4oPw1pVwzB1w+OXw0a3w7UNWg9kd4Kzn+SljmtW+rwfZD64M6ceNwI0ZjoI7L2eBff5yyc/V/E1EptEJgr+8vZglG3fXaJt922dz2wnx5DUvz5IlS3j66ad59NFHAbjrrrto2bIlHo+HMWPGcPrpp9O3b9+Qe3bt2sXo0aO56667uO6663jqqae48cYbIzWvKEocvLtoEwDrd+ync27Tcte/W13E5MesrKNr7jqu3PXiUi/pKe5y9R+Ycoh9vp1haz9kfCow38oAumPhO3yYcgKnL3qNwJ27N2A2LsQviga7QoVALLIzEjNkq40gwXTv3p1hw4YFzmfMmMHgwYMZPHgwS5cuZcmSJeXuyczMZNKkSQAMGTKENWvW1FZ3FaVR0r65lbJ5TRSd/GvzCsqVrdm2L3C8r9TLzv1Be59faPzn0+BA7vUPp2XWM+ZvLOaPry1i/e7QRHBrt1Xd5pBVSdVWvDS6FUFVZ+6JomnT4OxjxYoV3H///fzwww80b96cc889N6IvQFpaWuDY7Xbj8Xhqpa+KUh/w+axkWdFUOE68PoMA//poOWcM6UiXvPKzfWMMbnu79f4DoX9LxaVe/jlrOa84BIExhv2lXo665zNHPQ8fLt5cru1lm4ODus8WBKZ0HwIcwBq0/Z9+ivYU0yXmm0UmM80du1IVaHSCoD6ze/dusrKyyM7OZtOmTcyaNYuJEyfWdbeUhsrCGdDrGGjSEvYWwqyboPs4SM2EjQssQ2V6NmyYBzkdrZlqt9HQrA10GVmH/f4f9Jpo9dtJ8U5Y9g7dXmrO4d3ymDHtsPL3bv8Vfn4NOgyG3Rs59CUX57dYxCM7RvD+z5v55Phiy0j765cwdCqs+Igf5s1l5ZbRnOv+hLTNPnzbl7HilyXM7nwdH306mzHuBTyUupl7PGewxrTjuW/XMrpXK050fU0n2YpgyJz/C4Xfr+XJ1IUsMx3JZTczvGO5MOUDtprm7Cedq1NmAiA7fgXgWPcP/NM8Sm9X6GpjyJK7qvyryypcAJ3GVvn+aKggqEUGDx5M37596d+/P926deOII46o6y4pDZVtK+GNy6DHeDj3NXh1Kqz5Eha9UvF985+1PqfvSnwfI7FtJbzxW+h5DJzzcqD4+Ae/5D7X/fQs/Ih+cgffrpaQaxP7teWKsT3h0VFQGpyFz8sAimGNy8frhUfCjLODz3Knwse3MRy4O/UXTnd/AV9bu/N6A5+uLWVm+jvB57i/o0vJ/7jtrcW0T9vPN2kPB9v67lX+AOCGcSwAYHLKZzFf94yULyrxy4lNR0/UlALVQgVBDTN9+vTAcY8ePQLbSsHyBn7++ecj3vfVV18Fjnfu3Bk4njx5MpMnT675jioNG1+Z9blzvfW5d0uddOPTZVv5Yc12/jjxoPhusPXn7AqdJf+8YTe709aAC9KxdPFLNu7mty/MY23Rfn7esJupR3SlaWlk/Xq27CeVMBXqvqDDVnu2lbunlUQXhu6yPZAex/vUMhlZLWNXqgJqLFaUhojL1jv7BYK7bkatqc/M4ZHPVsV/wwH/QG4CRaUey5gqdlmmHADgyhnzWesw7g77+8dRmxUMOewLKfv8h3mB4xTxxt9HKNdWvSG1vA2kJkioIBCRiSKyXERWiki5/Y8i0llEZovITyLymYjkJ7I/itJo8Mea8tqzYFO5gS4R3P3BMrrc+C4A2/eV8oUjhMI9s5Zb10pCZ+HLN++h1y3vh5T5B+FSb+hum/2l0d/RhSFH9oaUtSzbFDjOJj6v3DOHWkNQtiTOi7dapCRG4IsxJnatqjQs4gZ+AY4GCoA5wBRjzBJHnVeAd4wxz4rIWGCqMeY3FbU7dOhQE56zeOnSpfTp06emX6Hek6zvrQDbVsBDQ63jFl0tT9YDldT7tzoIjrjGsjWEM+ximPME9D4WdqyBrUtg0DnQcwK8cj4AHncmKd7ikNu+9x3EkNu+5fgHv6LX1g+4t8VrpOwrv9vGyZveEfSW9RzkWl/uWoHJI1+2lTsOZ7dpUm7w9hrBLabcsR+PcZEiocLmgLsp6d59FJkscqXmQ0tUm0s+tQzlVUBE5hljhka6lsgVwaHASmPMamNMKfAicFJYnb7AbPv40wjXFUWJhM+hD9/xa+WFAEDhsshCACwhALD8PUsIACx8AX4NGj/DhQDAcNcyivYUs2zzHka6fo4pBABOcn8TUQgAlJqgGTOSEHjHO5w1vjbsIyOkfLkvn88yxlGUdRBrfG143TuKNb42fOEdQIHJY7tpxkzvSLa1OoyvvP1Y6usI/U4l3WutRhb7ukTubGZLSzg6Gf1H3vMeGjj9R9mZodc7j2R3t+PZ1vzgcs0VHnFb8GT4b4PHE/4OHYYEzwecCWP/DO0PidyvapJIQdABcH67BXaZkx+B0+zjU4AsEckNb0hEponIXBGZW1hYfyL2KUqd4asjVVDJzphVjrnrbQByJLKevcTE7xQ121fx7PeKsqs4qvQ+5vl6hZRPK7uOWT1vpeV137HxvG+4wXMZDw94hfPKbmIi/2Hwgce4wXMZ2Ze+z7llf2JS6d1wxtN4XZYPz32e0/G4LSc0pn4AbQdYxxP+BlNmwJnPBR825mZ+V3ZN4PRR74mhnZz6LtnnvUDeNV9aqzAHrY6+LnjS3bEtdMQVcNRN1nGP8XDa43Dk9UGVYA2TSEEQqcfheqjrgdEisgAYDWyAcNM/GGMeM8YMNcYMbdWqVc33VFEaGnVlE9i/PWYVvwCIJggqQ17r9jFqWMPMLhNqRC0zKeQ2S0dEGNEjj5cvPZw7Tx3AS9MO443LRwTqpbpDhym/D9sumuJy285b7qCDJ2IPmRnNQ+778g9jAse+qg6rUQJS1gaJ3D5aAHR0nOcDG50VjDEbgVMBRKQZcJoxpo42OFedoqIixo0bB8DmzZtxu934BdYPP/wQ4ilcEU899RTHHnssbdvWfHRBpQGwZwvsLoCmraBktzXYiwtadLGMrM3awv5t1o6hbSvqpo+7yodiCGeQrEQw9JLI6p7K0LJ5c4gie8qMNVCfNKg9u39uEnLt+kn9OWpot8D5oV2tbZfDu4UqHMITPPnPPvnTyfDg7daJO8V5g/WZkRNyX8eWoc+PSkU2WUmM13A8JFIQzAF6ikhXrJn+ZOBsZwURyQO2G2N8wE3AUwnsT8KIJwx1PDz11FMMHjxYBUEyYgz8q1fFdXJ7QlEdCQAb7451xBqu7k/7T9RrP/u6sNq040T3txGvbzfNaOnY/XNYj9aw2joON+CW2sNXk7QUzhjZD757O3Dt1GFdoUn0CVi/9tksjhSc8qDjYfHr1kDvn6G70wiIiMCKIKf8vfmHQsEPrLrjWPhr1EcHadEl9NzVCAWBMcYjIlcAswA38JQxZrGI/BWYa4x5CzgKuFNEDPAFcHmi+lNXPPvsszz88MOUlpYyYsQIHnroIXw+H1OnTmXhwoUYY5g2bRpt2rRh4cKFnHXWWWRmZlZqJaE0Asri2K5YGSHQ9yRY8mb06/1OtQa8CvA2a8fU7edxovtbyysXcPsOsNyXHxI24b+ecZybMjtiG5eWXsNq055Jg7rw8sKt7DZN8OAuJwgOmBTSxcPDnpNZ4OvBjPxXSS/8mfS0VMy1i3n3k8/5fO5C/pn6WOCeJump9MvN5rLR3chb3iz0we6K7RAvX3o4u0ssH4zfHNaZzrn2jP7kR2D8dEhJC87QI6mGIrV/3ptQvAN3RTGSnCuQy74KveaqO//ehD7ZGPMe8F5Y2a2O41eBV2v0oe/fCJsX1WiTtB0AkyofH+Tnn39m5syZfPPNN6SkpDBt2jRefPFFunfvzrZt21i0yOrnzp07ad68OQ8++CAPPfQQgwYNqtn+K/Wf4thG2ErRZkCFgsC07oMsrriJHU2788W2gfSUApzLgM2mJb0JCoL1JnqujALTmhUmn4/OOoYFe7/nyxXld/6spT3pzbJou285rXNzee7yK0mfORcKfwZxIzn5dBp2HHvn2Bn8XKngK0PExbtXjbLLwoYyV8WCoGl6Ck3TrXtuP7l/8EJqBrTobLfhjtw2BAWCk7Qm1k+8pGeFtVl3KwL1LE4gH3/8MXPmzGHo0KEMGjSIzz//nFWrVtGjRw+WL1/O1VdfzaxZs8jJibDMVJKLOHbjVIoYA9KiwrKYTSzcaBl7y8Lmi3vIDDnfQdhs3MEugkbc4qgOYQafLWl6tW9Os3SnTt4aolLdLoxfPRNxYA4bRGOsCOLC36a4gjN5vwCIJAiqS2NUDdUZVZi5JwpjDBdeeCG33357uWs//fQT77//Pg888ACvvfYajz32WIQWlAaLzwffPwKH/AYWz7QigLYdAEvfsgKu7SqADXOh3UBY/RkUVS5BSUxSKxYEq3Yayu9qD8VjDw+esGFin8ms8NzJLtOUAR2sic6u4sjCJzPVxQF7TirhM3l7cHS7JBCCIuKAGb7jpiYGVf9gb3zly6o6e6/QWNw4dw0lPePHj+f000/n6quvJi8vj6KiIvbt20dmZiYZGRmcccYZdO3alcsus5x6srKy2LOnHnozKpVnxSyYdTNsXAiLXg695nDKomBOzT1z4t3wwR+t41YVB4HbVRZ7xlxmz9LLwszDaRI6oG91t47q9du2VR4vXDIcgLtOG8Bpj5Q3Euc1TWVtmTUUuVLChiR7wA3RuvsHeeegmgj9+rH/gHd/D1mOzRvhK4NYHHF16PmEv8H/zoDB55evGy688odCeg6MqvzGk8qigiCBDBgwgNtuu43x48fj8/lITU3l0Ucfxe12c9FFF2GMQUS4++67AZg6dSoXX3yxGosbA8U7rM/dGyuuF85VC+GBStiILvkk6IG6d2tQEOR2r/C2b9fv54IY/738u3Kc3r0AbbMzmbrjBp5O+ycAvz16ACPfe4A1GWcH+/S45RzVu11OIGH8kM6RI2e6MDRvlgn7oHub5mEXrcGxTU6GQzUUQYglQr9+0HHWT8hzbAEQ757/I/8Qet5rQvQQ4OHCLLMF3LQuvudUExUENYwzDDXA2Wefzdlnn12u3oIFC8qVnXnmmZx55pnlypUGSJkdfsFTPgNdhUTallgRzsHDeRyjnVJirwg8JrJqqHVOBr4dwYFwbJ92rDmyN0y3C1KCqqKUOLKMYQwtmjWBLdChZbgB1XpOdkYqj547GF4mqP937sCprR03lbURVMZWoaohRWlkeA6EfsZLZQWBcybs3OYYI0qliej4H0o01VC3vCb8c9gg8G9KCp+NO5597dGhvhG3Ht+XncVl8HVobwJqkfDBMNLgGGnQrzVDayVVQ5URUCoIFKWeYQw8OBiOvMFS88y62VqqXzkf7h8IB2xnJHsrY1S2VHIrcyUHtKVb9tG7tbHy+1Zi9umLSxCkhHz6EZ+P1jkOY3R4n1PtFUFKJp1zQ0M/XDiyq3XgFATGFxwww0NnOAdHvwG8SS7sWh+9XkII3zUU43tq2spKjFOpfiUmjlA8NBpB4Ne3JwuJCh+u2HjLYPtqK62in+IdsGF+UAhAxULASUomeMpH62Tw+ZZuf/tqGHmtVXb2y5DWFDb9CHs2WT4GCyJntrv8xZ84fUcuvzuqR4ju/OMlW2jh68kQ14qAsxbAyox+9ChZHBIPZ4dpRouwWP5PeibxkvcoAPaZ0MieVugLx0DoFwRnvwJN8yCrHYy7FfKHxfGLwRK6fkHgCws15vyb7jEejrnTMqI+eXTkei27WwbZRBGvaujij2Hdd5ULEqcrguqRkZFBUVERubm5SSEMjDEUFRWRkZERu7JSNaIN8OEql7xesO2X2O2NuRk++jM0ybPiBflp1hpOfCC0bq9jrE9ngvldBbD603LNenGxqMA2PjoMmD+s2U6q9xCGuFbwuPc4rkix9DhtW2TDJuu+Jb7O9HWt5aLS63k9fXpIu7d7gmlBnL4AgD2DdwoCexjpNSFYNur35X8HUXEKggqC6YnA4b+Dwki/b/vvvu0AOOjYCNdrCP/4Emvl1qJL+RAS8bZdBzQKQZCfn09BQQHJFKI6IyOD/HxN6JYwvKWRy8P/WOOdxaXYQjs1+p77cPaXevjh1+0c1Tu6564XF7tLygKZwdbYj9mwo5geeAN1At2wk7MM65JLi73NYfda3IQmZ3GSluLi2UuPhicdCQZ9YSuC6u7YMb6gWit8RRAJd0XDVoJXypXdPlqVtuuARiEIUlNT6dq1a113Q2loGANFqyCvB2xbac32i3dYg/W+KJOKnyuOzxMV/wyyEqkG//jaIt7+cSOjeubx1137iPQ/PA0PX68sKlf+7qJNXJtiDfA+Exy0/Fm6rptwEHyZC7vhj+M6wlflmgDgl79NggOhaiOML3QgrK6h1pigMPHGoWqL6FkswbYSSSI9i+vQRqAhJpTkZc4T8NAQ+PoB6/Pf/eH/RlkpIJ+eFPmeuU+GnofvM49FStiKoIKBa9kmyxbx5YptrN8Rwb4A7Ing1bvA1wOAn3xWGOaFpkfgmqvneOsgJx96TQRg6MFW0pVF0bJypYWphroeGbqPviqCoFMwJwB9joeudsygVr1j3xtxJ05tDaL+FUECnqc2AkWpA/xevUvfrrheNH7zhjUofvkv6/zqHwGBfdvgibGR76nEisAbx+y2kBYh5yPNkxSWWgPzsuyRDN/ZlS0EHbncR14Pg38D2e3g0GnQ5wTIbs+M0Z8xfdYaHjprAEf3bQO3fUF+C1vIiMD1K+EeW6AMv8wyZPupimroNzOhdJ9leM5saal7uh0F2bES0VA3UToTqRIKf0YdoIJASV78A22k3Tzx0KZf6GzYbxz0R6+MREqogb/E42PIrR9w/TG9WbxxN5t3lXD5mB4M7dICn6/yao4nf3sMx/zbCmHx34uHc+b/fctNI7taGcHBmslnt7OORQID71mjB9GpY0dGdM8FEd65ciTtmztWG80cmQFFwpy5qiAIUjOsHyfxCAGIIQhqSTXU0NqOgQoCRams05efKsxMd3ncOF3Gtu4uYV+pl7+8vSRQ9tXKbYzqmUdJWXQjrpPHzxvKJc/NBaBZRrBPHZpnMudPtiqo/IajEFwu4YgeeYHz/h1iOLYlOs5PRUQaMGvNRpDIWbvaCJRkZMM8+OmV2nnWtpXww+PB88Uzg8Hg4tn+GYkqDIAL1oWGm16yOXKQwS9XbGPz7orDU/iMNXAM6xJUD2VlpJBlh3FOS0nkn7djwK3tOPoRB+NED6K1oRrSFYGSjNiByTj4jMQ/66ljrP37h/zGUkm8ckHl28jOh31bg1tL/YLg6Nthy8+R7+kxngXZ47j4tUw+bdmJv+84h+ayh+c9E7gyZSa3bxga16MfSTmHdt4HWWE6sMjXjXHu+TzusfbLp6cEB+LsjFQ+/8MYyrzxrSZqhNqOo5+WBe0Hw+g/xK5bY9iCT20EitKA8TtxleyE1CrkhJ54NxxmhQtnuq028QuCI64KVNtdUsbu4jL8Hh7FZ77Mff+dRxGFHLzdypVxcqnl+fpa6ZFxP/6sE0/k6Jc6AfD3U/ozt8TDrPeXAZCe4uL9q0fhs9UiLZvWYtTadgNrfwBzuWBamK6r1vqQwOfoikBRaomSXdA0uoNWVCLt9omgGjrjkW9ZvmVPwLFrZ3EpOZnVy5b1/EWHMqRzUP3Tu00WQzq3YE9JGQfnN8flEvq0y67WMypNfQ1xkrB+1YJqSGMNKUotUbwTDkSJB18RKRHCeUSISb98S6jO//A7P6n8sxzkNk1jVE9rx84zU4fx1o8bGdSxOSLCDcdUnHwmsfgH3PoS0sXfjwZsLNYVgaJUwKOjYPNP0PtYmDIDnj8VVs2GU5+wVBMPD4Os9rAnLAmMO80Kh+CMaPnUBKpElP3/xhhenVfAwfnN6d02K2KdynL1uJ7cP3sFAAc8QV3/Ub1bVxhuolbxO8bFu+WzsjSz3zPcmS0a6Xbe5KatKq5Xn1EbgaJUwOafrM/l71mffkewDfNg51rrOFwIABx+Ofz8GuxcB83awt7NFT/nkHOtbF+l+y2jsPHBNw9a1zIiq17eWLiBG161+rfmruNIcQken+HUA9PxEL8RNb9FJgW293CWYwvoBSO6xN1GhVzwLqRXU3100cfBWWubvnDyo9B7YvX7FokJf4d2g6DbmPjqdx0NJz4I/U9LTH9qY5BWQaAoUQjX+RoTjEdTshOad4x+7/jpsGONJQgG/wa+sFIr0rS1NdADHHUTfHandXzSw+XbWPKmdX9Gi/LXgG17gsHp/jlrGR7bCWy+CU3I4hcQTqYc2pEZP6wnOyOFj68bzUF//gCAc4Z3pmBHMdce3YvsjBr6E3VGMq0qHcPCSg+aUv02o5HWBIZEyOsbDREYfF7i+lMb1KFqSP0IlPpN2f6w8+KgJ3DJrsi6+0ikNYtcntokcnngefZe/szm5S51ufFdSh3bNB/+dFXUZtIj7On35/J1Xu/WqimZaW6mn9iPnMzUpAir3iDwT0gSaiTXFYHS2Nm1wQo17Nf9HnAYVZe8ZX16SqDTYVbsfdzb1tYAACAASURBVP8AvWNNaDvzng4er/io4vj1QOCPK1r457TyguCVuet54ft1vHH5EUGvYzuF5LUvLeQ+R91/zloe4/l2L0RwuwSvY1XQzHb8Msa6/vKlh9OtVZw6caXxocZipdFzX1/rc7q9Y+d/k4PXXv5N+frRmHVz8NhXBitmVVy/1zGw+HVL9x8Jx4qgzOvD6zMBnf9Nry/i/DbHctC6GXy2poQj+xhmLtjAOWm9GOqqnDfyGUPz+eKXQlYV7guU+cNB+EXDoV1bRrhTqRcEgs4lcteQrgiUZGOtIwD+odPgh8cS85yBk6HnhOhJ4R0rihMe/IpljpAPM35Yx0scRxPGsff5H/nsestOMKX0FlKJI4EKVviHJy8YRtO0FC7dPi9EEPgdv1QAKICuCJQkRFzWrhyArCp4+laCaa+uZsf+UiJGNXLYIJZFiPvjw8VerFXDUfd8Zt1CSrmE7gDnH96Z80Z0weszfPFLIX97dyktmqQFbAHXHd2LeWu3s2N/GVMO7cSk/u3ofU0WnVrGsFMo9Qe1EShKFfFFiHuTkgll/tlx4v4AXp1XwIdLtlgntl3Za0xgY+fu3buoyqbKttkZfHfzOP746k+8NHc9AO2aZ9K9lWWUXltkCZgmacEtpH3bZ7Pg1lA/hoPa1rJHsFJFamP7qK4IlHj58UX46t9w4fvw/WMw4HRo0hK+vBfG3QqbfoKv7rWcr4pWwsApsOA5GPtna8fNh3+CwRfA1iWweyOMuclKBv7cidDqIMuBp3CZtX971SfQtj/0PRn6nQLvXGPt1Dn9afj2IfhlFqz50sp0ld3BiuK5cQHkD7Pa8do6/E6HB/v/zPGW4bYsqCJJ5B/A9a/8WK5s+75SWtl/189+vpgrK/FXcOyAtry3aHNArXP36QczsGNzbp65iMO65QbqjendistGd2fakd2q1X8liVAbgRI3My+1Pt++Bpa8AT/OsDI7zXsa2g6A1y+xri97x/r86l7rs3VfaJILC/5r7Yv/1UpewpHXw/Mnw55N1o+fopXW545fYe9W6D4W5j1j3/MH+PCWYN1fPgjt4+qwgGDrvg0er/my/DtFEgSZLaz8wQADzrC8hBe+YJ23PwRG3whzHrcE3evTQr2Ho/Cc52gW+rqzzrTmltQX6JCbw3ObjubKlDdi3uunX/sc3lu0mfTUYJ8nD+vIqJ55dHSoeFLcLm6cVJchIJTE4FANjbjKmgDVFLoiUCqNzzZW7i+yZvpQceJvb6kVZwdCt26W7LZm+dFo3tmOz7M7WOZ3xqopwmdC3Y6Ckx+Be/tY531PslIq+gXBtM+sT9urdVvXE9j5j0H0cEXwLnZwq2dq4Pjk0tthUwWVHV3zq4UfPXdIwG9g34GgsdjlkhAhoCQJE26v4QY1MY1SVTwVJy8JIdKAX7IzGF8/Es1aW/cVOxKq7FwX/zPjIuwPwJ0W6igWIwHMiLsiB3YzNWDYmzwsGPp5Yv+2HGTHExrRPa+i25RGi24frTQiMhG4H3ADTxhj7gq73gl4Fmhu17nRGPNeIvtUoxgT3H7oDvtVej3WUs8fodJbFtwp41wCGp810Pm8wemnv57LbZW73NY1j2PA9q8IvKVBtYipIBlJWbE1+w+vt7+oYkHQtJWl9/eraQC2/xq9flUIXxK7UislCEo9PiSt/KA/e2n1Vi7/OP1gSu2gbxl28pdebbL4/uZx5DWLPwm90phI4K6hxigIRMQNPAwcDRQAc0TkLWPMEke1W4CXjTGPiEhf4D2gS6L6VCN8+3CoU1Mshl9mDWTfPlT1Z7YfDBvnh5Y59fKL7I2Rb10RvY0Pbgweb3IYUJ88uuJnN2tjCYrnTgyW+e0ONcT0d5Yy3RGyvxQXKe704HI1LAPWNS8u4J4zBpLiDgqQNaYt3R26ngKTx8V2Ht/KcvtJ/TikUwv6tc9mvp1asml68E+lTXacYS2UxkOLzrBhbvzRUBsYiVwRHAqsNMasBhCRF4GTAKcgMBDYvZcDVKzkrQ988vfK1f/+UegyKnjebhBsWli5NsKFQCLoe7JlyN1fFFo+dCr89DKURs6tS/tDrBVDJKZ+AE9HiU454AzLCP3r55iw5fYvW4vpaSAw53aFJnZ5Y+FG5qzZwYadxfTvYP33ubbsd1xq3mbUaVdwzyuzWerrVMHLhnLCgb9xgOAzzj2scyDGz+BOzfn3WYM4qncDDm+sVJ8T7rdsVW36JfY5l3wSDPFdiyTSRtABWO84L7DLnEwHzhWRAqzVwJUJ7E/NUIWE5SG6+c5H1FxfotHv1OjXnMHXnPVOfACOvME6PtgR/iG7A4yoYKUx8W7LuOunl2Pgb1nB1skuoyCvJ1B+sV3qNXy9chtLfXZk0Qi/8w07LQP5zxssdddumvJPz2T+/aOLL3wDKSRytNBwXv/dCBaZbuzK6hEocwZ6ExFOPqQDGam1nJdXqV+kZ1mCINF0GGKF+K5lErkiiKTwCv+bnwI8Y4z5l4gcDjwvIv2NCVV2i8g0YBpAp07xz/QSQlUSdZc4DK0RoljWOBV56qZkQOle69gfUM1fHin5ijuNCg1k7hQQx+/EuXROqSB3bko6u/aXkgPlVgTicnHhM3N5L82ep1RC+H6yrGK7wJ2nDmDbHuu981tmMrhTC769aSx5zdLp+af3436OojQmEikICgBnsPh8yqt+LgImAhhjvhWRDCAPCPlrNsY8BjwGMHTo0LpNluquQv5Z5y6bjFoQBM0qyGLlNML6wzmDNeC7bUHgNFrFeN/bXp/PuZ5ievoLHEHcdh2w9H0RcaXw9o8bODelvCBYv8PaCeX/ok/4z3dszdrF91Gacm7xDOeSUV15/MtfaZeTwSPnDmFQx/K//3Y5waV4VrruqFaSj0SqhuYAPUWkq4ikAZOBt8LqrAPGAYhIH6wgAIUJ7FP1kWqqCKIFP/MTKz5+LMQNrfqElh10fPD44DOCx86lrkgw7WC7QcFyV8WC4MMN6azZ7tjC6uj/uc9EsR0AJV5w2UO9Dxfveg8NXCuzQzX7BYQBtuw+UK4NP5F28GRnpHDr8X25YkxP/n3WIF7/3YiIQsDJw2cP5t2rRlVYR1FqnIPPquseJE4QGGM8wBXALGAp1u6gxSLyVxHxb0H5PXCJiPwIzAAuMDWx+TuRhKspjr8v6OAEMCTotMRUh6oh3RYAftVQSgbcUgidRoS2d82i4PHNG+HP2+Can2Gwna1pxJVW2S2FcMYzVlluT6vuH36FP/5qOVpdvwJuXGeVnfmcdc/NGy1PXLBsBf42/XQfA9evhOGXOt63gv8if9rCJnJDZ/QO9dKizfsj3GRx7cs/IfgHfLii7Cqml/kzTAUFQPAsOvktyhvXDHDhyK7kNEnl5EM6hMz6o3Hcwe3olKuOYUotc/Kj1t9nHZLQdbDtE/BeWNmtjuMlQC1YT2uQcH+Bpq0g1aEXb5Ibei0cv2rInW7p0MP30Dt17P7j5h2DM+2sdkF1TVY7u14Tq67z3nLqIbd1n1815E6LvG+5WSV2x6RabXkd84lNez20C5xFH8J9uByCQDC4KLb3CfmMBOoAuIjuH/Habw/nm5VFLFi3M6S81FOBT4Wi1CdcLurat1c9iytL+IrAlRKqR3cOrpHUPLGMxe4ojkp+D2KnQde/eIo3XWOcdQv3RFfDOPEv3pyC4MV5W+K614srICb8K4pJ/S0R4hcA/vJo4uSvJ/VjSOeWFO61+vvn4/uyaLoV3fOACgJFiRu1jMWi8BdY+F8rGufL58OBCGEaohlUnekRJazMfx4+K4+mivHv8Akx9kYQDrHw73qKsBr4bPlW1m3fjwAhOcOieDze9tZiIDhwW8fxeUd6HSsC/z2DO2bDcvAGVEPWZ7QVgd/bd2B+c2Ath3ZpGUj/eNKg9nH1Q1EUFQSx+d+ZVgTOr+8vf61lN0tAOAOyOXEO0L+ZCfOfg+x8y44w2B5qT7gfPrvT2rvvj9p5zB2QGZa1atyfrYG/3ynBss4jLMesMX+K+RrGGJ7/bi2nD25Pk8Hnw5ALrAunPAb7LPv8BU/PASzP2otKf88xOetpv2IbIw+9BD67EzP8MubvbMqgza+w7YjbeO61tQDcUXY2fWUtLfNa8+GmobTzFLHFWP1/xHMC20w257hn0821mdvLzuVg12q+8fVjsa8LWbKfd72HAZDeczRLvjqEl3eNAeD6skt5qMPH/Ofsi1lZdICbnrmINDxM6t+W93/eHBCmpw7uwJG9WtEqy/p9L7z16BBPYEVRKkb/WmJRUXL0c1619OSOLFch+xids/cOQ4J5c0/4d7A8tzuc9oR13HO89Xn45eWfld0ezng6tCwlPXhvDD5ZtpVb31zMii17uf3kB4IXBpbfsWCA2b4hzN4xBJ70b9r8L+M2t2b2sq2cMPA43n4tuBN4M7mML72Hk1q3Z/nGjdzsuSRw7W6PZZx+0ntcoOyeUwfS6fNV3HbCKM59Muj4ld6mF8/3epCFP1jbbVeZDiw67F+c2TKLfV5hhncc7XIyGBlI+m79rkUkIAQAmjepwH9BUZRyqI0gFhXtmgkYfqMMPFVxPksQxWWWQNtm69O/XrmNP7xaPmkLgM8XeePWbNtZ6+0fI0cCieXM5advu2w+um40I3uWj+DptbOZpbhs9ZA92PszfXl8BpetqvKqGUBRagRdEcSiIr8Bv0+AUxDUYQTBivAPrB57kD/nCWum//dTBpDqDhV2+0pjJ3mJxJ6S+BK6t29e3mD96LnWamnakd3JyUylaG8pry/YEFhg+fvo9Rlc9rt46/lOY0VpKOiKIBYVzer9W0n9xuI2/YNOWU7qIIhUOP5ZdPhs3z94+2P3AKzaurfGnnve4Z05bXB+SFlOZnnj+sT+VliMHq2b8afj+tKtlbUVNtd2FmvRJI0jeuTywORD+O3o7gzokMNxA9qVa0dRlMqjK4JYRFsRXPiho47ABe9ZOX8zW1g7fDpZBlAunh3c719DPPP1r8xetpXnLxoeUr5xZzEpbqF1VnDG/Zsnv2fsQa3pbDtK+WfRKS7B4zPsKSmjZdM0Jtz7eeCeT5fXXAayMb1bk+p28ebCDdx92sG0zckICeoWjctGd6dXmyzG97H8Idwu4YWLDwtcf/vKkTXWR0VJdlQQxCJaHtFOoYMwXRx+cYf9NnicP7TGuzT97SURy/2Zupb+dSJeY2iWnsKXK7bx5YptPHWB1Q+vz/DqvIKAimhPiYe9Bzwh6qAd+ytIeVlJmqS5Gd4tl5V3HFup+1LcLib0qyB4nqIoNYYKglhUZCyup/S51Upa8/F1owNlZV5r4PcLBj/3ffRLwAgciymHduSbVUWsLbJ2SfVuk8UJA9uxcute3lgY2YCs2zgVpf6jf6WxqG6QuQRjjOHT5Vs5qlf5iKML1gXTSy7eGNnXIV4hAFZmrkxHXP7LjurGKYdY+v8bJ/XB4/Mx8u5PQ+5RQaAo9Z+GN92tbSLFwm9/SO33IwL3fricdxdt4sJn5vLwpyvLXf92VTDb2AOzV8TV5pG9oscaGtUzL2DE7ZrXlJMGBvMMtc3JIL9FE04dHJp7yL/tMxoDOuRENB4rilJ76HQtFmmOeEH9Ti3v1FWHPPDJSm493spm9GPBznLXX1+wodJtDszP4YtfykcCX3OX5RD2sZ0Q/vQh+YFtnE7uPXMQ/drn8M5PG1mwbmfMFYEafRWl7lFBEAvn1s+qJKWpYWYuKAg5/+s7luF4+77SGmlfRHh66jCm2uEmwvHH9ykpi+5rcNHIrpx3eGcK9xwIxP5RFKX+oqqhWPgcTlJ1IAje/nEjxz3wJV6fYW3RPq59KbI38Px15VcEkRgVwZvXybED2jKmd2vuOnVAxOuZdvrI4hhOZ6luF+2b173/hKIosUkeQeA5ADMvg53r46u/4iN4ahIUzA2WxcjWlQiunLGAxRt3s/eAJ27P3Yo4um+bqNe+v3kcB7XNBmDyoZ0C6iAnmWnWDN8TJQyFoigNj+QRBCtnw48z4L3r46u/5A3YMA/aD4TcHtB1NPQ5oUa7VFzq5eFPV+KJI2iOx+tjV3H19/efMaQjP946gbOHd2JgfmjazHiMtqcPzuesoR25cmyPavdFUZT6QfIocP2hIkyckcqKd1phps9/O2FdevCTFfzns1W0ykrnzKEdK6zr8Rl21oCjV3qKi8w0N3ecMoBftuxh2nNzeeGSw9h3wENGavkdPmcP70SaIxZRZpqbu08/uNr9UBSl/hBTEIjIFcALxpgdserWa/wewhWFlXZSsit2NrEqsn77flpnp7O7xBrYD9iGV2MMqwr38eq8AopLPVx/TO/APSu27OXy/82vsN3DurVkVM9W/HPW8pDyycM68uKc9cy7ZXzITp9ebbL47IYxFbZ5xymRbQWKojQe4lkRtAXmiMh84ClgVr1PMB8JvyCIZ0XgKYXC5cH8ATVISZmXUf/4lJMGtScrw/7127F37vvoFx74JOgP8LXDD+Bv70YOK+Hk5EEdOHFQ+xBB4Nfz33WazuIVRYlMTBuBMeYWoCfwJHABsEJE7hCR7gnuW81SGUHw0jmwbys0rXiHTVUos+0BnyzdGgixLMCKLXtChADASkcU0GWb98RsO9Xtokla8mj7FEWpGeIyFtsrgM32jwdoAbwqIv9IYN9qlsoIAv/OoqNuqvFueP3B3g54AlswRWD5ltgDfSxSU5LH9q8oSs0Rc+QQkatEZB7wD+BrYIAx5rfAEOC0BPev5qiMsdhTYuUCzukQu24lKXXsEFq/wwre9qeZPwcCuVWHVFv//+5Vlrdu8yZ17wCnKEr9Jx49Qh5wqjFmrbPQGOMTkeMT060EUCkbwYHQxPM1xNs/bsRpXJmzJmh/DzfwxmJ8nzZ8vHQLuU3TaJqewrrt+wNZvPq1z2Hl3yfVRJcVRUkC4tElvAds95+ISJaIDAcwxixNVMdqnMrsGvKUhCaerwYer493ftqIMYYrZyzgqhkLqtXeWfY209ymVnpMEQmkoUxxB3cEpbhdpLhVVaQoSmziGSkeAZy5C/fZZQ0LqaRqqIYEweNf/soV/1vA71+OHBrCybiDyoeSDic1xRrs01Otr07E2tsPhOz3VxRFiZd4Rg5xbhc1xvhoiI5o8aqGjKlRQVC45wAQXyTQs4ZV7FT29hUjA0Hf/Aga819RlOoRjyBYbRuMU+2fq4HVie5YjePPk2tiqIZ8HktYpNaMIPDP3OPBGaTtlEM60KtNs5DrA/JzArP/Uo8l0EQgyxYEew9UPxaRoijJRzyj1GXACGADUAAMB6YlslMJId5dQ2XF1mcNrQjSK7Gls21O8JkHPF46tQzmQvBHDfWHgWiankJOZip/Pr4vnXOtZDGuOJLCK4qihBNTp2CM2QpMroW+JBh7kPSFCYK3roI+J8Lar2HlR0Fjcg0JgrQ4BUG/9tnkNUvnxkkHcdf7yzhQ5gvZYeRPEekXBF6f4cfbJgDWDqIerZsxrk9sG4OiKEo48cQaygAuAvoBgdHRGHNhAvuVAOxhNXxFMP9Z6yc739KztB0AeT2h+9gaeepbUZK6h/OOnanrklHd2LG/lPMO78ItMxcB0K1VU/5ux/zxC4QDnqCKKyPVzdnDO9VIfxVFST7ima4+jxVv6BjgcyAfqL4bbG1jIggC51bSkp1WmOkpM+DM5yC3ZiJoxBMaAqxtoABul3DTpD50aJ6JP+T/n4/rS6ssy6/h2AFt6d8hm0uPbFgRPhRFqb/EIwh6GGP+DOwzxjwLHAc03JCUTmOx1xHWuXQvZOSUr1+H+JzBiGyaN0njnStH0SWvad10SlGURkc8gsA/Wu4Ukf5ADtAlYT1KGBFWBN6wPL8Z1Qs7vaekjHgDs+Y1S4u7XTUCK4qSSOIRBI+JSAvgFuAtYAlwdzyNi8hEEVkuIitF5MYI1+8TkYX2zy8iEl/i3argH6Cd6iBf2HbLauQf2FVcxoDpH/KPWct59PNVlJR5AwHmIvHYeUNZNH1ChW36VwQqBhRFSSQVGotFxAXstpPSfAF0i7dhEXEDDwNHY207nSMibxljAoH1jTHXOupfCRxSue5XgQStCPbYSWYe+WwVAAU79jM2gqfwpP5tuXR0dwZ1jP2sdjmWX0GzDHUYUxQlcVQ4wtiB5a4AXq5C24cCK40xqwFE5EXgJKwVRSSmALdV4TlxEkk1FJb6sRo2gpKy0N1I//1uHf/9bl25ei6RuIQAwF9O7McRPXIZ3KlFlfulKIoSi3hUQx+JyPUi0lFEWvp/4rivA7DecV5gl5VDRDoDXYFPolyfJiJzRWRuYWFhHI+OgF9LU9GKoJKqoXVF+7n/4xUYYygpizMFZhhZFcz2m6ancMoh+VVqV1EUJV7i0Tn4/QUud5QZYquJIqm2oynNJwOvGhM5/oMx5jHgMYChQ4dWL02m30ZgDMx7OvRaenalmvrd/+bx84bdnDioPcVxCgIT9iv45saxeLwNL/OnoiiNh3g8i7tWse0CwBlFLR+I5l01mVBBkwDCVEPL34NvHgyt0iS3Ui36nZT3HfDEvSLIyQxNFpOVocljFEWpW+LxLD4vUrkx5rkYt84BeopIV6w4RZOBsyO03xsr9eW3MXtbHcIdykodGcGmvAS9J1a6yabplpfvPkfayVj86bi+lX6OoihKIolHNTTMcZwBjAPmAxUKAmOMxzY0zwLcwFPGmMUi8ldgrjHmLbvqFOBFE+8G/Ori1z45o4u6qzYrz7QTxf/+lR/p0y6yWunwbrl8u7oIgF/+Ninu2EOKoii1RTyqoSud5yKSgxV2IibGmPewMpw5y24NO58eT1vVx78i8HvrOuL6V1EQNLVDQhfsKKZgR3HEOjOmHUaXG98F4g9ApyiKUptUZWTaD/Ss6Y7UGn5jsackWOaO38vXSZM03d+vKErDJx4bwdsEd/u4gL5Uza+gbgm3EXiszGF0HwttD65Sk03S3FGvPT11WGA3UPMmqezcXxa1rqIoSl0Sz5T2HsexB1hrjClIUH8SSLggsFcEJ/0H0ppEviWMRQW72F/qYXi3incXjendijG9g17FX/9xLJ4Kwk0oiqLUJfGohtYB3xtjPjfGfA0UiUiXhPYqkZgw1VBKety3nvDQV5z12HcAlHl9PP/d2sC1myYdFNga+q8zB4Xc588mpiiKUh+JRxC8AjjjJ3jtsoZFOdWQXxBULRPZlt1BG8PB+TlcOro7Uw61ksM002TyiqI0IOIZsVKMMYFYDMaYUhGpmnW1ToliI4hDEJR6fDz86crA+dcrt3HJc3MD56//dgQAf5zYm2uP7qm7gxRFaVDEM2IVisiJ/hMROQnYlrgu1RI+DyDgiv0reH1+AffPXhE4P+eJ79nvcCBLcVttiAjpKdENyIqiKPWReFYElwEviMhD9nkBENHbuF4T7q/m84IrPhWO5oVRFKUxE49D2SrgMBFpBogxpuHlKwbKxbvzecAV3+y9qer8FUVpxMTUi4jIHSLS3Biz1xizR0RaiMjfaqNzCcX4Qr2LKyBD1T2KojRi4rERTDLGBFJI2tnKjk1clxJEOdWQJ27VkPoAKIrSmIlnJHSLSLox5gCAiGQC8W++rzdEshFULAffWLCBFVv3kNcs+uteNbZHTXROURSlzohHEPwXmC0i/iwuU4FnE9elWsJ4Y6qGrnlpYcxmDs6vep5jRVGU+kA8xuJ/iMhPwHisrGMfAJ0T3bEapxqqoYo4rHvlktkoiqLUN+L1fNqM5V18GlY+gqUJ61Ft4fPFvWsoGl/cMEa9iBVFafBEHcVEpBdWVrEpQBHwEtb20TG11LcaJmxFYLzVFgT5LTKrdb+iKEp9oKIVwTKs2f8JxpiRxpgHseIMNUwiqYZi2AgyU0Ovv3Dx8JBzl0s9zRRFafhUJAhOw1IJfSoij4vIOCwbQePAF3lFUFzq5euVVgQNf05iP84Iood0UiOxoiiNg6iqIWPMTGCmiDQFTgauBdqIyCPATGPMh7XUxxoiPmPxzTMXMXPBBj6/4Si27S0NudazTTMemHIIo3u10rDSiqI0GmIai40x+4wxLxhjjgfygYXAjQnvWU0TrhqK4lm8dNNuAF6bv6HctVSXixMHtlchoChKo6JS8ZKNMduNMf9njBmbqA7VGlEcyvzy4gFHtFE/ahNQFKUxkkSB8+NTDfnCVw7ADcf0Lmc4VhRFaSwkzyb48PE9imdxeLX/XTycET3yuHyMhpJQFKVxkkQrgjCi7BoyYSuCvu2za6tHiqIodUISCQLHAG9M1MQ0qwr3hZxnpqlKSFGUxk0SCQIHpfts1VDo63u8vnJV09zJ+StSFCV5SJ5RzqnyKdkZMUPZ578UlrtNNE+loiiNnOQRBE7VUPHOiKqhi56dG3J+yaiutdExRVGUOiWJBIGDJ8bDxgXgqtgx7E/H9a2lDimKotQdSbR91F4R9JwAeb0AKO11LMXFZby5cIOqgBRFSVqSRxD4VUNH3QQdBgNwzqPfMGdNAwuZpCiKUsMkn2rIMfOfs2ZHHXZEURSlfpA8giDMUay4tOGmVlAURalJkkcQBHYNWSuC374wr+66oiiKUo9IqCAQkYkislxEVopIxNDVInKmiCwRkcUi8r9E9sd+IACfLS/vM6AoipKMJMxYLCJu4GHgaKAAmCMibxljljjq9ARuAo4wxuwQkdaJ6k+5fASKoigKkNhdQ4cCK40xqwFE5EXgJGCJo84lwMPGmB0AxpitietOqGqoIs4Z3onJwzolriuKoij1iESqhjoA6x3nBXaZk15ALxH5WkS+E5GJkRoSkWkiMldE5hYWVlOlE4e/wNAuLRiQn1O95yiKojQQEikIIo244fqZFKAncBQwBXhCRMplhTfGPGaMGWqMGdqqVauq9SYO1VC7nIx4qyqKojQaEikICoCOjvN8YGOEOm8aY8qMMb8Cy7EEQwKJviL43VHdARjWpWViu6AogEBiBgAACvNJREFUilKPSKQgmAP0FJGuIpIGTAbeCqvzBjAGQETysFRFqxPTndjT/CN7tWLNXcfRsWWTxHRBURSlHpIwQWCM8QBXALOApcDLxpjFIvJXETnRrjYLKBKRJcCnwA3GmKIEdcj6FGHr7pKIVVI194CiKElIQmMNGWPeA94LK7vVcWyA6+yfWkJ4/MvIiw63SwPPKYqSfCTRFDioGmqVlR6xhgYgVRQlGUkeQeBQDXl85e0F10/oRatmkQWEoihKYyaJwlD7Eco8oYKgSZqbK8YmeLOSoihKPSV5VgQO1VCZ14fbJfzjtIMBKPWUT1qvKIqSLCSPIHCohsq8PlLdwqQBbQEiqooURVGSheQRBAGEUq+PVLeLJmlJqBlTFEUJIylHwlKPjzS3C7dLGNixOecf3rmuu6QoilJnJI8gsFVDf3tvKS//kkpuU2uH0JuXH1GXvVIURalzkk41NHtZIWVeQ2qKOg0oiqJAUgmCUIOwhpNQFEWxSLrR0C8O0lQQKIqiAMkkCIyuCBRFUSKRRKOhsf+1bANtsjPqsjOKoij1hiQSBBZ+QdC9ddM67omiKEr9IHkEQZhqqHurZnXUEUVRlPpF8giCgGoIWjZN45RDOtRtdxRFUeoJSSQILAzClWN7qLFYURTFJnlGQ4dqyKtB5hRFUQIkjyAIeBAIPqOCQFEUxU8SCQILY8Cr6QcURVECJI8gCFENqSRQFEXxkzyCwMYguiJQFEVxkESCILgiUBuBoihKkOQRBCYYYkIFgaIoSpDkEQQ2BtSZTFEUxUESCQJrFdC/Qw7dNLyEoihKgOQRBLY6yO3SzGSKoihOkkcQ2LhcSffKiqIoFZI0o+I3q7YB5YKQKoqiJD1JIwjS7WT1hXtL67gniqIo9YukEQQtmqQBsHn3gTruiaIoSv0iaQRByyapAJR61K1YURTFSdIIguyMFCCYqlJRFEWxSBpB4N812q2V5ipWFEVxklBBICITRWS5iKwUkRsjXL9ARApFZKH9c3Ei+wPwzIWHJvoRiqIoDYqURDUsIm7gYeBooACYIyJvGWOWhFV9yRhzRaL6EU6TtNTaepSiKEqDIJErgkOBlcaY1caYUuBF4KQEPq9i1IFAURQlIokUBB2A9Y7zArssnNNE5CcReVVEOkZqSESmichcEZlbWFhYxe4EU1UqiqIoQRIpCCKNuOHT8reBLsaYg4GPgWcjNWSMecwYM9QYM7RVq1bV7JUKAkVRFCeJFAQFgHOGnw9sdFYwxhQZY/weXo8DQxLWG1UNKYqiRCSRgmAO0FNEuopIGjAZeMtZQUTaOU5PBJYmrjsqCBRFUSKRsF1DxhiPiFwBzALcwFPGmMUi8ldgrjHmLeAqETkR8ADbgQsS1Z8AqhpSFEUJIWGCAMAY8x7wXljZrY7jm4CbEtkHx4Nr5TGKoigNjaTxLNZdQ4qiKJFJIkFgo6ohRVGUEJJHEKhqSFEUJSLJIwhUNaQoihKRJBIENqoaUhRFCSF5BIGqhhRFUSKSPIIggK4IFEVRnCSRINAVgaIoSiSSRxDk9oS+J4MroT50iqIoDY7kGRUPOtb6URRFUUJInhWBoiiKEhEVBIqiKEmOCgJFUZQkRwWBoihKkqOCQFEUJclRQaAoipLkqCBQFEVJclQQKIqiJDliGlgwNhEpBNZW8fY8YFsNdqchoO+cHOg7JwfVeefOxphWkS40OEFQHURkrjFmaF33ozbRd04O9J2Tg0S9s6qGFEVRkhwVBIqiKElOsgmCx+q6A3WAvnNyoO+cHCTknZPKRqAoiqKUJ9lWBIqiKEoYKggURVGSnKQRBCIyUUSWi8hKEbmxrvtTU4hIRxH5VESWishiEbnaLm8pIh+JyAr7s4VdLiLygP17+ElEBtftG1QNEXGLyAIRecc+7yoi39vv+5KIpNnl6fb5Svt6l7rsd1URkeYi8qqILLO/68OT4Du+1v4//bOIzBCRjMb4PYvIUyKyVUR+dpRV+rsVkfPt+itE5PzK9CEpBIGIuIGHgUlAX2CKiPSt217VGB7g98aYPsBhwOX2u90IzDbG9ARm2+dg/Q562j/TgEdqv8s1wtXAUsf53cB99vvuAC6yyy8CdhhjegD32fUaIvcDHxhjDgIGYr17o/2ORaQDcBUw1BjTH3ADk2mc3/MzwMSwskp9tyLSErgNGA4cCtzmFx5xYYxp9D/A4cAsx/lNwE113a8EveubwNHAcqCdXdYOWG4f/x8wxVE/UK+h/AD59h/HWOAdQLC8LVPCv29gFnC4fZxi15O6fodKvm828Gt4vxv5d9wBWA+0tL+3d4BjGuv3DHQBfq7qdwtMAf7PUR5SL9ZPUqwICP6n8lNglzUq7OXwIcD3QBtjzCYA+7O1Xa0x/C7+DfwB8NnnucBOY4zHPne+U+B97eu77PoNiW5AIfC0rQ57QkSa0oi/Y2PMBuAeYB2wCet7m0fj/p6dVPa7rdZ3niyCQCKUNap9syLSDHgNuMYYs7uiqhHKGszvQkSOB7YaY+Y5iyNUNXFcayikAIOBR4wxhwD7CKoKItHg39lWa5wEdAXaA02x1CLhNKbvOR6ivWe13j9ZBEEB0NFxng9srKO+1DgikoolBF4wxrxuF28RkXb29XbAVru8of8ujgBOFJE1wItY6qF/A81FJMWu43ynwPva13OA7bXZ4RqgACgwxnxvn7+KJRga63cMMB741RhTaIwpA14HRtC4v2cnlf1uq/WdJ4sgmAP0tHccpGEZnd6q4z7VCCIiwJPAUmPMvY5LbwH+nQPnY9kO/OXn2bsPDgN2+ZegDQFjzE3GmHxjTBes7/ETY8w5wKfA6Xa18Pf1/x5Ot+s3qJmiMWYzsF5EettF44AlNNLv2GYdcJiINLH/j/vfudF+z2FU9rudBUwQkRb2amrC/7d396BRRFEYht8PlRgQwR+wEQ1BK0FTiIVYiGVaiyBWMVUarcTCSrCxDdooWChiYaGFRVC2EEQxWMQ/EE0knYIpRAQJIRyLe5QhbjQbkkzIfA8Me/fsMNzLFGfu3NkzGVucuhdJVnExph/4AEwCF+vuzzKO6xhlCvgaGM+tn3J/tAV8zM/tub8oT1BNAm8oT2XUPo4ljv048DDbvcAYMAHcA7oyvjm/T+TvvXX3e4lj7QNe5nl+AGxb7+cYuAS8B94Ct4Gu9XiegbuUdZBZypX90FLOLXAmxz8BDHbSB5eYMDNruKbcGjIzswU4EZiZNZwTgZlZwzkRmJk1nBOBmVnDORGYzSNpTtJ4ZVu2arWSeqpVJs3Wgo3/38WscX5GRF/dnTBbLZ4RmC2SpClJVySN5bYv43sltbI+fEvSnozvknRf0qvcjuahNki6kbX2H0nqrm1QZjgRmLXTPe/W0EDlt+8RcQS4SqlxRLZvRcRB4A4wkvER4ElEHKLUBnqX8f3AtYg4AHwDTq7weMz+yf8sNptH0o+I2NImPgWciIhPWejvS0TskDRNqR0/m/HPEbFT0ldgd0TMVI7RAzyO8sIRJF0ANkXE5ZUfmVl7nhGYdSYWaC+0TzszlfYcXquzmjkRmHVmoPL5PNvPKJVQAU4DT7PdAobhzzuWt65WJ8064SsRs791SxqvfB+NiN+PkHZJekG5iDqVsbPATUnnKW8SG8z4OeC6pCHKlf8wpcqk2ZriNQKzRco1gsMRMV13X8yWk28NmZk1nGcEZmYN5xmBmVnDORGYmTWcE4GZWcM5EZiZNZwTgZlZw/0CRKukzdrvF3wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([17.81661,\t16.86976,\t16.53884,\t16.19576,\t16.08668])\n",
    "print(model.predict(test_data.reshape(1,5), batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to load it\n",
    "#from numpy import loadtxt\n",
    "#from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "#model = load_model('model.h5')\n",
    "# summarize model.\n",
    "#model.summary()\n",
    "# load dataset\n",
    "#dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "# evaluate the model\n",
    "#score = model.evaluate(X, Y, verbose=0)\n",
    "#print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
